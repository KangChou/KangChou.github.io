{"meta":{"title":"ovo$^{mc^2}$","subtitle":"ä½œè€…:zhoukang","description":"äº’è”ç½‘äººå·¥æ™ºèƒ½æŠ€æœ¯å¼€å‘è€…$$ä¸–é—´ä¸‡ç‰© e^{ i \\pi}+1=0 äº’è”äº’é€š$$\né‚®ç®±:kangsinx@yeah.net     å¾®ä¿¡å…¬ä¼—å·(AIç§‘æŠ€ä¸ç®—æ³•ç¼–ç¨‹):kangsinx","author":"KangChou","url":"https://www.coomatrix.com"},"pages":[{"title":"AIæŠ€æœ¯ä¸åœºæ™¯åº”ç”¨","date":"2022-11-20T08:05:14.327Z","updated":"2022-11-20T08:05:14.327Z","comments":true,"path":"AI/index.html","permalink":"https://www.coomatrix.com/AI/index.html","excerpt":"","keywords":null,"text":"AIäººä½“å§¿æ€ä¼°è®¡â€”â€”å…³é”®ç‚¹æ£€æµ‹","raw":null,"content":null},{"title":"å…³äºåšå®¢ä¸ä½œè€…","date":"2020-04-05T04:14:54.000Z","updated":"2022-11-24T10:19:43.157Z","comments":true,"path":"about/index.html","permalink":"https://www.coomatrix.com/about/index.html","excerpt":"","keywords":null,"text":"æˆ‘æ˜¯ä¸€åæ•°å­¦ä¸“ä¸šç¡•å£«çš„äººå·¥æ™ºèƒ½ç®—æ³•å¼€å‘è€…(KangChou)ğŸ˜€ï¼Œä¸»è¦ä»äº‹å·¥ä½œé¢†åŸŸ:è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½ç®—æ³•æ–¹å‘ ã€‚ æœ¬åšå®¢è‡´åŠ›äºåˆ†äº«äººå·¥æ™ºèƒ½ç®—æ³•ã€AIç®—æ³•æ¨¡å‹ä¸è®¾è®¡ã€PythonåŸºç¡€çŸ¥è¯†ã€æ•°æ®åˆ†æã€TensorFlowå’Œç¥ç»ç½‘ç»œç­‰å­¦ä¹ èµ„æ–™ï¼Œæ¢è®¨äº’è”ç½‘å‰æ²¿æŠ€æœ¯å’Œç›¸å…³æŠ€æœ¯ç ”å‘ç­‰ã€‚ ä¸‹é¢å±•ç¤ºå¼€å‘è¿‡ç¨‹ä¸­çš„demoæ¡ˆä¾‹ï¼šäººä½“å§¿æ€ä¼°è®¡éª¨éª¼å…³é”®ç‚¹è¯†åˆ« æœ‰è¯—æ‰æœ‰è¿œæ–¹æ–‡ç« å¾ç¨¿ï¼š&#107;&#x61;&#110;&#x67;&#115;&#x69;&#x6e;&#120;&#64;&#x79;&#x65;&#97;&#x68;&#46;&#110;&#x65;&#116; ç‚¹å‡»å›åˆ°åšå®¢ä¸»é¡µï¼š&amp;#34;åšå®¢ä¸»é¡µ&amp;#34;","raw":null,"content":null},{"title":"æ–‡ç« åˆ†ç±»","date":"2020-04-07T13:33:34.000Z","updated":"2022-04-16T03:00:14.331Z","comments":true,"path":"categories/index.html","permalink":"https://www.coomatrix.com/categories/index.html","excerpt":"","keywords":null,"text":"ç”µè„‘PCç«¯æ–‡ç« åˆ†ç±»è¯·çœ‹åšå®¢é¡µé¢å³ä¸‹è§’â‡¨ æ‰‹æœºç«¯è¯·ç›´æ¥å»â€œå½’æ¡£â€é‡ŒæŸ¥çœ‹","raw":null,"content":null},{"title":"è¯„è®ºåŒºç•™è¨€","date":"2022-11-20T08:11:08.634Z","updated":"2022-11-20T08:11:08.634Z","comments":true,"path":"guestbook/index.html","permalink":"https://www.coomatrix.com/guestbook/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"æ ‡ç­¾","date":"2020-04-05T15:26:06.000Z","updated":"2022-04-15T15:19:36.743Z","comments":true,"path":"tags/index.html","permalink":"https://www.coomatrix.com/tags/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null},{"title":"æ‹¾å…‰","date":"2022-11-24T07:03:05.180Z","updated":"2022-11-24T07:03:05.180Z","comments":true,"path":"photography/index.html","permalink":"https://www.coomatrix.com/photography/index.html","excerpt":"","keywords":null,"text":"","raw":null,"content":null}],"posts":[{"title":"äººå·¥æ™ºèƒ½ç§‘æŠ€ä¸æ–‡çŒ®ç½‘","slug":"ai1","date":"2022-11-20T12:57:06.000Z","updated":"2022-11-26T08:54:24.476Z","comments":true,"path":"2022/11/20/ai1/","link":"","permalink":"https://www.coomatrix.com/2022/11/20/ai1/","excerpt":"","keywords":null,"text":"AIæ–°é—»ç½‘ï¼šhttps://www.marktechpost.com/ ç®—æ³•æ ¸å¿ƒåŸºç¡€ä¸AIæ¨¡å‹è®¾è®¡ã€æˆ‘çš„CSDNæŠ€æœ¯åšå®¢ã€‘ï¼šhttps://blog.csdn.net/weixin_41194129/category_11362509.html AIç®—æ³•å­¦ä¹ ç¤¾åŒº: https://github.com/Algorithm-learning-community-for-python YOLOç³»åˆ—èµ„æ–™æ±‡æ€»ï¼šhttps://github.com/KangChou/Cver4s NVIDIA-CUDAç¼–ç¨‹:https://github.com/KangChou/deepcv_project_demo/tree/main/CUDA%E7%BC%96%E7%A8%8B è‡ªåŠ¨é©¾é©¶ç‚¹äº‘æŠ€æœ¯: https://github.com/KangChou/deepcv_project_demo/tree/main/CVPR/point-cloud è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼š https://github.com/KangChou/deepcv_project_demo/tree/main/CVPR/visual ä¸“ä¸šçš„èŠå¤©æœºå™¨äºº: https://github.com/salesforce/Converse åŸºäºå¼€æºGPT2.0çš„åˆä»£åˆ›ä½œå‹äººå·¥æ™ºèƒ½ | å¯æ‰©å±•ã€å¯è¿›åŒ–:https://github.com/EssayKillerBrain/EssayKiller_V2 é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹é›†åˆ:https://github.com/CLUEbenchmark/CLUEPretrainedModels è‡ªç„¶è¯­è¨€åŸºç¡€æ¨¡å‹:https://github.com/lpty/nlp_base BERTæ¨¡å‹ä»è®­ç»ƒåˆ°éƒ¨ç½²å…¨æµç¨‹:https://github.com/xmxoxo/BERT-train2deploy ä¸­æ–‡BERT-wwmç³»åˆ—æ¨¡å‹:https://github.com/ymcui/Chinese-BERT-wwm æ·±åº¦å­¦ä¹ å…¥é—¨æ•™ç¨‹, ä¼˜ç§€æ–‡ç« : https://github.com/Mikoto10032/DeepLearning 3Dè§†è§‰ã€VSLAMã€è®¡ç®—æœºè§†è§‰çš„å¹²è´§èµ„æ–™: https://github.com/qxiaofan/awesome_3d_slam_resources è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå®ç°:https://github.com/sunmiaozju/smartcar èº«ä»½è¯è‡ªåŠ¨è¯†åˆ«,é“¶è¡Œå¡è¯†åˆ«,é©¾é©¶è¯è¯†åˆ«,è¡Œé©¶è¯è¯†åˆ«ï¼šhttps://github.com/wenchaosong/OCR_identify MVision æœºå™¨è§†è§‰ æœºå™¨è§†è§‰ï¼šhttps://github.com/Ewenwan/MVision Computer Vision: Algorithms and Applicationsï¼šhttps://szeliski.org/Book/ è‡ªåŠ¨é©¾é©¶çš„æ¿€å…‰é›·è¾¾ç‚¹äº‘å¤„ç†: https://github.com/beedotkiran/Lidar_For_AD_references åŠ¨æ€è¯­ä¹‰SLAM ç›®æ ‡æ£€æµ‹+VSLAM+å…‰æµ&#x2F;å¤šè§†è§’å‡ ä½•åŠ¨æ€ç‰©ä½“æ£€æµ‹+octomapåœ°å›¾+ç›®æ ‡æ•°æ®åº“:https://github.com/Ewenwan/ORB_SLAM2_SSD_Semantic åŸºäºè§†é¢‘çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ç ”ç©¶:https://github.com/guanfuchen/video_obj TensorRT-7 Network: https://github.com/Syencil/tensorRT C++ TensorRT-CenterNet: https://github.com/CaoWGG/TensorRT-CenterNet yolox-deepsort:https://github.com/Sharpiless/yolox-deepsort BirdNet+ï¼šLiDAR é¸Ÿç°å›¾ä¸­çš„ç«¯åˆ°ç«¯ 3D å¯¹è±¡æ£€æµ‹:https://github.com/AlejandroBarrera/birdnet2 å…³äºnuScenes æ•°æ®é›†çš„å¼€å‘å¥—ä»¶:https://github.com/nutonomy/nuscenes-devkit A robust LiDAR Odometry and Mapping (LOAM) package for Livox-LiDAR:https://github.com/hku-mars/loam_livox æ¿€å…‰é›·è¾¾è®ºæ–‡ï¼šhttps://arxiv.org/search/?query=+LiDAR&amp;searchtype=all&amp;source=header ä½¿ç”¨CUDA PCL åŠ é€ŸJetsonçš„ç‚¹äº‘å¤„ç†ï¼šhttps://developer.nvidia.com/zh-cn/blog/cuda-pcl-1-0-jetson/ PCT: Point Cloud Transformer: https://github.com/MenghaoGuo/PCT","raw":null,"content":null,"categories":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"https://www.coomatrix.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"https://www.coomatrix.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"æ–°ç‰ˆOpenCV5(C++)ç‰ˆæœ¬ç›®æ ‡æ£€æµ‹:YOLOv4æ‰“åŒ…æˆå¯ç”¨AIè½¯ä»¶(ç¦»çº¿æˆ–è€…ä¸Šçº¿ä½¿ç”¨)","slug":"yolocv5","date":"2022-09-20T12:57:06.000Z","updated":"2022-11-20T14:03:01.488Z","comments":true,"path":"2022/09/20/yolocv5/","link":"","permalink":"https://www.coomatrix.com/2022/09/20/yolocv5/","excerpt":"","keywords":null,"text":"ä¸Šä¸€ç¯‡æ–‡ç« :1ã€C++ç‰ˆæœ¬çš„OpenCV 5.xç¼–è¯‘ç”Ÿæˆopencv-python&#x3D;&#x3D;5.x(GPUç‰ˆæœ¬)æ¥å£å¹¶è¿›è¡Œè°ƒç”¨2ã€ã€å¼ºåŠ›æ¨èã€‘åŸºäºNvidia-Docker-Linux(Ubuntu18.04)å¹³å°ï¼šæ–°ç‰ˆOpenCV5.x(C++)è”åˆCUDA11.1(GPU)å®Œç¾é…ç½®è§†è§‰ç®—æ³•å¼€å‘ç¯å¢ƒ3ã€AIæ¨¡å‹C++éƒ¨ç½²:ã€é…ç½®OpenCV4++ç¯å¢ƒã€‘ä¸ã€ä¸‰ç§åœ¨ C++ ä¸­éƒ¨ç½² TensorFlow æ¨¡å‹çš„æ–¹å¼ã€‘ã€å‡†å¤‡é˜¶æ®µã€‘4ã€yolov4è§†é¢‘ç›®æ ‡æ£€æµ‹ï¼šä½¿ç”¨C++ç‰ˆæœ¬è”åˆCUDA11.2çš„OpenCV 5.xç¼–è¯‘ç”Ÿæˆopencv-python&#x3D;&#x3D;5.xè¿›è¡Œæ¨ç† éœ€è¦è½¯ä»¶è¯·åœ¨å¹³è®ºåŒºç•™è¨€ï¼Œæºç ä¼šå¼€æºï¼ŒæŒç»­å…³æ³¨æœ¬åšå®¢ã€‚ 1ã€æ‰“åŒ…æˆlinuxè½¯ä»¶ï¼Œåç»­å¢åŠ QTåŠŸèƒ½ 2ã€è½¯ä»¶å¢åŠ äº†åŠ å¯†åŠŸèƒ½ï¼Œåç»­ä¼šå¼€æºä»£ç ï¼Œæ•¬è¯·æœŸå¾… 3ã€å¢åŠ è®¡ç®—ä½¿ç”¨å‰©ä½™å¤©æ•° 4ã€å¢åŠ ç­‰ç­‰åŠŸèƒ½ç»„ä»¶â€¦ä¸è¯´äº†ï¼Œåé¢ä¼šä¸€ä¸€å±•ç¤º.. æœ¬YOLOç›®æ ‡æ£€æµ‹è½¯ä»¶åªåœ¨ubuntu18.04å¹³å°ä½¿ç”¨å·¥ç¨‹ç›®å½•ï¼š å¯æ‰§è¡Œæ–‡ä»¶ä¸ºï¼šsudo .&#x2F;main.shå…¶ä»–å°±æ˜¯yoloçš„é…ç½®æ–‡ä»¶å’Œæ¨¡å‹äº†ï¼š ä½¿ç”¨æ–¹æ³•æµ‹è¯•å›¾ç‰‡å­˜æ”¾ä½ç½®,æ ¼å¼åªè¦æ˜¯jpg,éšä¾¿å¾€é‡Œä»ï¼š ä¿å­˜çš„ç»“æœåœ¨resultæ–‡ä»¶ç›®å½•ä¸‹ï¼š ç›´æ¥å°†è½¯ä»¶åœ¨æ‹¿èµ°åœ¨UBUNTU18ä½¿ç”¨å³å¯ï¼šsudo .&#x2F;main.sh è§†é¢‘æ“ä½œæ•™ç¨‹: https://live.csdn.net/v/239286?spm=1001.2014.3001.5501","raw":null,"content":null,"categories":[{"name":"AIç›®æ ‡æ£€æµ‹ç®—æ³•","slug":"AIç›®æ ‡æ£€æµ‹ç®—æ³•","permalink":"https://www.coomatrix.com/categories/AI%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"ç›®æ ‡æ£€æµ‹","slug":"ç›®æ ‡æ£€æµ‹","permalink":"https://www.coomatrix.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}]},{"title":"AIæ¨¡å‹C++éƒ¨ç½²:TensorFlow2å›¾åƒåˆ†ç±»æ¨¡å‹ä¹‹é‡‘é’±è±¹å¤§æˆ˜é½å¤©å¤§åœ£ã€OpenCVçº¯C++æ¥å£è°ƒç”¨tensorflowç”Ÿæˆçš„pbæ¨¡å‹ã€‘ã€æºç å·²å¼€æºã€‘","slug":"codemo","date":"2022-04-04T07:07:23.000Z","updated":"2022-11-26T09:23:24.317Z","comments":true,"path":"2022/04/04/codemo/","link":"","permalink":"https://www.coomatrix.com/2022/04/04/codemo/","excerpt":"","keywords":null,"text":"CSDNåŸæ–‡:AIæ¨¡å‹C++éƒ¨ç½²:TensorFlow2å›¾åƒåˆ†ç±»æ¨¡å‹ä¹‹é‡‘é’±è±¹å¤§æˆ˜é½å¤©å¤§åœ£ã€OpenCVçº¯C++æ¥å£è°ƒç”¨tensorflowç”Ÿæˆçš„pbæ¨¡å‹ã€‘ã€æºç å·²å¼€æºã€‘ 1ã€å‡†å¤‡è®­ç»ƒæ•°æ®ã€é‡‘é’±è±¹ä¸é½å¤©å¤§åœ£ã€‘ubuntu16.04å¼€å‘ç¯å¢ƒ1ï¼špython3.6+cuda11+tensoflow-gpu 2.5ubuntu16.04å¼€å‘ç¯å¢ƒ2ï¼špython3.6+cuda10+tensoflow-gpu 1.13 è¿™é‡Œçš„æ•°æ®å¤„ç†åŒ…æ‹¬reshapeã€å»å™ªã€å¯¹æ¯”åº¦å¢å¼ºã€æ‰¹é‡å‰ªåˆ‡ã€å›¾ç‰‡ç°åº¦ã€äºŒå€¼åŒ–ã€ç¼©æ”¾ã€ä¸°å¯Œæ•°æ®ç­‰ç­‰ã€‚ 1.0ã€è·å–æ•°æ®åœ°å€https://github.com/KangChou/classeifier_models/blob/main/deal_datasets/down_datasets/golds_and_monkey.zip 1.1ã€å¤„ç†æ•°æ®é›†100*100å°†æ•°æ®å¤„ç†æˆå°ºå¯¸å¤§å°ä¸€æ ·çš„jpgå›¾ç‰‡ï¼Œå¤„ç†çš„ ä»£ç  # function:change the size of pictures in one folder&quot;import cv2import os# è¯»å–ä¸è§„èŒƒå›¾ç‰‡æ•°æ®ï¼Œå¹¶è§„èŒƒä¸ºç›¸åŒå¤§å°æ ¼å¼image_size = 100 # è®¾å®šå°ºå¯¸source_path = &quot;/home/zkpark/Documents/pcl2022/opencv_cc_tensorflow/golds_and_monkey/train/monkey_king/&quot; # æºæ–‡ä»¶è·¯å¾„# source_path = &quot;/home/zkpark/Documents/pcl2022/opencv_cc_tensorflow/golds_and_monkey/train/gold/&quot; # æºæ–‡ä»¶è·¯å¾„target_path = &quot;./dataset2/monkey_king/&quot; # è¾“å‡ºç›®æ ‡æ–‡ä»¶è·¯å¾„# target_path = &quot;./dataset2/gold/&quot; # è¾“å‡ºç›®æ ‡æ–‡ä»¶è·¯å¾„if not os.path.exists(target_path): os.makedirs(target_path)image_list = os.listdir(source_path) # è·å¾—æ–‡ä»¶åi = 0for file in image_list: i = i + 1 image_source = cv2.imread(source_path + file) # è¯»å–å›¾ç‰‡ print(image_source) image = cv2.resize(image_source, (image_size, image_size), 0, 0, cv2.INTER_LINEAR) # ä¿®æ”¹å°ºå¯¸ cv2.imwrite(target_path + &#x27;1-&#x27; + str(i) + &quot;.jpg&quot;, image) # é‡å‘½åå¹¶ä¸”ä¿å­˜print(&quot;æ‰¹é‡å¤„ç†å®Œæˆ&quot;) 1.2ã€æ•°æ®æ‰¹é‡å¤„ç†# è¯»å–å›¾ç‰‡def read_img(path, w, h): cate = [path + x for x in os.listdir(path) if os.path.isdir(path + x)] # print(cate) imgs = [] labels = [] print(&#x27;Start read the image ...&#x27;) for index, folder in enumerate(cate): # print(index, folder) for im in glob.glob(folder + &#x27;/*.jpg&#x27;): # print(&#x27;Reading The Image: %s&#x27; % im) img = io.imread(im) img = transform.resize(img, (w, h)) imgs.append(img) # print(index) labels.append(index) # æ¯ä¸ªå­æ–‡ä»¶å¤¹æ˜¯ä¸€ä¸ªlabel # print(len(labels)) print(&#x27;Finished ...&#x27;) print(len(imgs)) print(len(labels)) return np.asarray(imgs, np.float32), np.asarray(labels, np.float32)# æ‰“ä¹±é¡ºåº ä¸ºäº†å‡åŒ€å–æ•°æ®def messUpOrder(data, label): num_example = data.shape[0] arr = np.arange(num_example) np.random.shuffle(arr) data = data[arr] label = label[arr] return data, label# å°†æ‰€æœ‰æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†def segmentation(data, label, ratio=0.8): num_example = data.shape[0] s = np.int(num_example * ratio) x_train = data[:s] y_train = label[:s] x_val = data[s:] y_val = label[s:] return x_train, y_train, x_val, y_val 2ã€tensorflow2.xæ¨¡å‹ç”Ÿæˆtensorflow1ä»£ç å‡çº§åˆ°2çš„æ–¹æ³•è¯·å‚è€ƒï¼šhttps://blog.csdn.net/weixin_41194129&#x2F;article&#x2F;details&#x2F;121499555 2.0ã€TF2åˆ†ç±»æ¨¡å‹ç½‘ç»œæ„å»º2.0.1ã€æ¨¡å‹ç½‘ç»œç»“æ„ä¸è®­ç»ƒ# æ„å»ºç½‘ç»œdef buildCNN(w, h, c): # å ä½ç¬¦ x = tf.placeholder(tf.float32, shape=[None, w, h, c], name=&#x27;x&#x27;) y_ = tf.placeholder(tf.int32, shape=[None, ], name=&#x27;y_&#x27;) # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ + æ± åŒ–å±‚ï¼ˆ100â€”â€”&gt;50) conv1 = tf.layers.conv2d( inputs=x, filters=32, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01)) pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) # ç¬¬äºŒä¸ªå·ç§¯å±‚ + æ± åŒ–å±‚ (50-&gt;25) conv2 = tf.layers.conv2d( inputs=pool1, filters=64, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01)) pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) # ç¬¬ä¸‰ä¸ªå·ç§¯å±‚ + æ± åŒ–å±‚ (25-&gt;12) conv3 = tf.layers.conv2d( inputs=pool2, filters=128, kernel_size=[3, 3], padding=&quot;same&quot;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01)) pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2) # ç¬¬å››ä¸ªå·ç§¯å±‚ + æ± åŒ–å±‚ (12-&gt;6) conv4 = tf.layers.conv2d( inputs=pool3, filters=128, kernel_size=[3, 3], padding=&quot;same&quot;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01)) pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2) re1 = tf.reshape(pool4, [-1, 6 * 6 * 128]) # å…¨è¿æ¥å±‚ dense1 = tf.layers.dense(inputs=re1, units=1024, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01), kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003)) dense2 = tf.layers.dense(inputs=dense1, units=512, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01), kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003)) logits = tf.layers.dense(inputs=dense2, units=32, activation=None, kernel_initializer=tf.truncated_normal_initializer(stddev=0.01), kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003)) return logits, x, y_# è¿”å›æŸå¤±å‡½æ•°çš„å€¼ï¼Œå‡†ç¡®å€¼ç­‰å‚æ•°def accCNN(logits, y_): loss = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=logits) train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) correct_prediction = tf.equal(tf.cast(tf.argmax(logits, 1), tf.int32), y_) acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) return loss, train_op, correct_prediction, acc# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼ŒæŒ‰æ‰¹æ¬¡å–æ•°æ®def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False): assert len(inputs) == len(targets), &#x27;len(inputs) != len(targets)&#x27; if shuffle: indices = np.arange(len(inputs)) # [0, 1, 2, ..., 422] np.random.shuffle(indices) # æ‰“ä¹±ä¸‹æ ‡é¡ºåº for start_idx in range(0, len(inputs) - batch_size + 1, batch_size): if shuffle: excerpt = indices[start_idx:start_idx + batch_size] else: excerpt = slice(start_idx, start_idx + batch_size) yield inputs[excerpt], targets[excerpt]# è®­ç»ƒå’Œæµ‹è¯•def runable(x_train, y_train, train_op, loss, acc, x, y_, x_val, y_val): # è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼Œå¯å°†n_epochè®¾ç½®æ›´å¤§ä¸€äº› n_epoch = 100 batch_size = 20 sess = tf.InteractiveSession() sess.run(tf.global_variables_initializer()) for epoch in range(n_epoch): print(&#x27;epoch: &#x27;, epoch) # training train_loss, train_acc, n_batch = 0, 0, 0 for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True): # print(&#x27;x_val_a: &#x27;, x_val_a.shape()) # print(&#x27;y_val_a: &#x27;, y_val_a.shape()) _, err, ac = sess.run([train_op, loss, acc], feed_dict=&#123;x: x_train_a, y_: y_train_a&#125;) train_loss += err train_acc += ac n_batch += 1 print(&quot;train loss: %f&quot; % (train_loss / n_batch)) print(&quot;train acc: %f&quot; % (train_acc / n_batch)) # validation val_loss, val_acc, n_batch = 0, 0, 0 for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False): # print(&#x27;x_val_a: &#x27;, x_val_a) # print(&#x27;y_val_a: &#x27;, y_val_a) err, ac = sess.run([loss, acc], feed_dict=&#123;x: x_val_a, y_: y_val_a&#125;) val_loss += err val_acc += ac n_batch += 1 print(&quot;validation loss: %f&quot; % (val_loss / n_batch)) print(&quot;validation acc: %f&quot; % (val_acc / n_batch)) print(&#x27;*&#x27; * 50) sess.close() 2.0.2ã€è®­ç»ƒè¾“å‡º train loss: 1.939822train acc: 0.526667validation loss: 1.844313validation acc: 0.600000**************************************************epoch: 1train loss: 1.482922train acc: 0.513333validation loss: 0.704169validation acc: 0.600000**************************************************epoch: 2train loss: 1.043171train acc: 0.546667validation loss: 1.278273validation acc: 0.600000**************************************************epoch: 3train loss: 1.165261train acc: 0.546667validation loss: 0.706824validation acc: 0.600000**************************************************epoch: 4train loss: 0.843956train acc: 0.553333validation loss: 0.733591validation acc: 0.600000**************************************************epoch: 5train loss: 0.754458train acc: 0.546667validation loss: 0.714196validation acc: 0.400000**************************************************epoch: 6train loss: 0.726300train acc: 0.446667validation loss: 0.754467validation acc: 0.400000**************************************************epoch: 7train loss: 0.730567train acc: 0.460000validation loss: 0.759676validation acc: 0.400000**************************************************epoch: 8train loss: 0.730799train acc: 0.453333validation loss: 0.739154validation acc: 0.400000**************************************************epoch: 9train loss: 0.712395train acc: 0.440000validation loss: 0.704720validation acc: 0.400000************************************************** 2.0.3ã€vscodeå†…æµè§ˆæ¨¡å‹ç»“æ„ï¼ˆtensorboard â€“logdirï¼‰import tensorflow.compat.v1 as tftf.disable_v2_behavior()sess = tf.Session()tf.train.import_meta_graph(&quot;./model/.meta&quot;)tf.summary.FileWriter(&quot;./summary&quot;, sess.graph) æŸ¥çœ‹å‘½ä»¤ï¼štensorboard â€“logdir&#x3D;.&#x2F;summary&#x2F; 2.0.4ã€ç”Ÿæˆpbæ¨¡å‹è½¬åŒ–çš„æ—¶å€™ä¼šå‡ºç°å¦‚ä¸‹é—®é¢˜ï¼š Traceback (most recent call last): File &quot;dealmodel_pb.py&quot;, line 11, in &lt;module&gt; from tensorflow.framework import graph_utilModuleNotFoundError: No module named &#x27;tensorflow.framework&#x27; è§£å†³æ–¹æ³•ï¼šåœ¨ä»£ç å¼€å¤´è¡¥å……å¦‚ä¸‹å‡ è¡Œ #è½¬æ¢æˆpbæ–‡ä»¶# import tensorflow as tfimport tensorflow.compat.v1 as tftf.disable_v2_behavior()physical_devices = tf.config.experimental.list_physical_devices(&#x27;GPU&#x27;)assert len(physical_devices) &gt; 0, &quot;Not enough GPU hardware devices available&quot;tf.config.experimental.set_memory_growth(physical_devices[0], True) å®Œæ•´ä»£ç ï¼š #è½¬æ¢æˆpbæ–‡ä»¶# import tensorflow as tfimport tensorflow.compat.v1 as tftf.disable_v2_behavior()physical_devices = tf.compat.v1.config.experimental.list_physical_devices(&#x27;GPU&#x27;)assert len(physical_devices) &gt; 0, &quot;Not enough GPU hardware devices available&quot;tf.compat.v1.config.experimental.set_memory_growth(physical_devices[0], True)import os.pathimport argparsefrom tensorflow.python.framework import graph_utildef freeze_graph(output_node_names): #checkpoint = tf.train.get_checkpoint_state(model_folder) #input_checkpoint = checkpoint.model_checkpoint_path saver = tf.compat.v1.train.import_meta_graph(&#x27;./model/.meta&#x27;, clear_devices=True) graph = tf.compat.v1.get_default_graph() input_graph_def = graph.as_graph_def() with tf.compat.v1.Session() as sess: saver.restore(sess, &#x27;./model/&#x27;) for node in input_graph_def.node: if node.op == &#x27;RefSwitch&#x27;: node.op = &#x27;Switch&#x27; for index in range(len(node.input)): if &#x27;moving_&#x27; in node.input[index]: node.input[index] = node.input[index] + &#x27;/read&#x27; elif node.op == &#x27;AssignSub&#x27;: node.op = &#x27;Sub&#x27; if &#x27;use_locking&#x27; in node.attr: del node.attr[&#x27;use_locking&#x27;] output_graph_def = graph_util.convert_variables_to_constants( sess, input_graph_def, output_node_names ) with tf.io.gfile.GFile(&#x27;classify_gold.pb&#x27;, &quot;wb&quot;) as f: f.write(output_graph_def.SerializeToString())if __name__ == &#x27;__main__&#x27;: freeze_graph([&#x27;output&#x27;]) 2.0.5ã€æŸ¥çœ‹pbæ¨¡å‹èŠ‚ç‚¹åç§°ã€äº‹å®ä¸Šï¼Œä¸Šè¿°çš„å¯è§†åŒ–å°±å¯ä»¥æŸ¥çœ‹äº†ï¼Œè¿™é‡Œåªæ˜¯æ‰“å°å‡ºæ¥æ–¹ä¾¿æŸ¥çœ‹ã€‘import tensorflow.compat.v1 as tftf.disable_v2_behavior()import os# model_dir = &#x27;./&#x27;out_path = &#x27;./&#x27;model_name = &#x27;classify_gold.pb&#x27;def create_graph(): with tf.gfile.FastGFile(os.path.join(out_path + model_name), &#x27;rb&#x27;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) tf.import_graph_def(graph_def, name=&#x27;&#x27;)create_graph()tensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]for tensor_name in tensor_name_list: print(tensor_name) ç”Ÿæˆå†…å®¹ï¼šå¾ˆæ˜æ˜¾ï¼Œä»è¾“å…¥åˆ°è¾“å‡ºçš„èŠ‚ç‚¹éƒ½å·²ç»åŒ…æ‹¬åœ¨å…¶å†…äº† Use tf.gfile.GFile.input/x-inputconv2d/kernelconv2d/kernel/readconv2d/biasconv2d/bias/readconv2d-pool-1/conv2d/Conv2Dconv2d-pool-1/conv2d/BiasAddconv2d-pool-1/conv2d/Reluconv2d-pool-1/max_pooling2d/MaxPoolconv2d_1/kernelconv2d_1/kernel/readconv2d_1/biasconv2d_1/bias/readconv2d-pool-2/conv2d/Conv2Dconv2d-pool-2/conv2d/BiasAddconv2d-pool-2/conv2d/Reluconv2d-pool-2/max_pooling2d/MaxPoolconv2d_2/kernelconv2d_2/kernel/readconv2d_2/biasconv2d_2/bias/readconv2d-pool-3/conv2d/Conv2Dconv2d-pool-3/conv2d/BiasAddconv2d-pool-3/conv2d/Reluconv2d-pool-3/max_pooling2d/MaxPoolconv2d_3/kernelconv2d_3/kernel/readconv2d_3/biasconv2d_3/bias/readconv2d-pool-4/conv2d/Conv2Dconv2d-pool-4/conv2d/BiasAddconv2d-pool-4/conv2d/Reluconv2d-pool-4/max_pooling2d/MaxPoolReshape/shapeReshapedense/kerneldense/kernel/readdense/biasdense/bias/readlayer-1/dense/MatMullayer-1/dense/BiasAddlayer-1/dense/Reludense_1/kerneldense_1/kernel/readdense_1/biasdense_1/bias/readlayer-2/dense/MatMullayer-2/dense/BiasAddlayer-2/dense/Reludense_2/kerneldense_2/kernel/readdense_2/biasdense_2/bias/readlayer-3/dense/MatMullayer-3/dense/BiasAdddense_3/kerneldense_3/kernel/readdense_3/biasdense_3/bias/readlayer-4/dense/MatMullayer-4/dense/BiasAddoutput 2.1ã€ä½¿ç”¨OpenCVæ¥å£è°ƒç”¨TF2-PBæ¨¡å‹æ­¤å¤„åŠ è½½ç½‘ç»œå¹¶æœªç”¨åˆ°pbtxtæ–‡ä»¶ï¼Œç½‘ä¸Šä¹Ÿæœ‰å°†pbæ–‡ä»¶å¯¼å‡ºä¸ºpbtxtæ–‡ä»¶çš„ä»£ç ï¼Œä½†å½“å°†pbå¯¼å‡ºä¸ºpbtxtæ—¶ï¼Œæ— æ³•ä¹Ÿå°†pbtxtåŠ è½½åˆ°ç½‘ç»œä¸­ï¼Œå…·ä½“åŸå› æš‚ä¸æ˜ç¡®ã€‚ä¸è¿‡æ­¤å¤„åªåŠ è½½pbæ–‡ä»¶å°±èƒ½å¤Ÿä½¿ç”¨äº†ã€‚ 2.1.0ã€é…ç½®OpenCV(C++)ç¯å¢ƒAIæ¨¡å‹C++éƒ¨ç½²:ã€é…ç½®OpenCV4++ç¯å¢ƒã€‘ä¸ã€ä¸‰ç§åœ¨ C++ ä¸­éƒ¨ç½² TensorFlow æ¨¡å‹çš„æ–¹å¼ã€‘ã€å‡†å¤‡é˜¶æ®µã€‘ï¼šhttps://blog.csdn.net/weixin_41194129&#x2F;article&#x2F;details&#x2F;123951358 2.1.1ã€å®šä¹‰OpenCV(C++)æ¥å£å»è°ƒç”¨TF2-PBæ¨¡å‹main.cc #include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/dnn.hpp&gt; //åŒ…å«dnnæ¨¡å—çš„å¤´æ–‡ä»¶#include &lt;iostream&gt;#include &lt;fstream&gt; //æ–‡ä»¶æµè¿›è¡Œtxtæ–‡ä»¶è¯»å–using namespace cv;using namespace cv::dnn; //åŒ…å«dnnçš„å‘½åç©ºé—´using namespace std;int main() &#123; //è½¦è¾†åˆ†ç±»ï¼Œè¾“å…¥æ¨¡å‹çš„åœ°å€ string bin_model = &quot;./classify_gold.pb&quot;; //åŠ è½½æ¨¡å‹ Net net = readNetFromTensorflow(bin_model); //è·å–å„å±‚ä¿¡æ¯ vector&lt;string&gt; layer_names = net.getLayerNames(); //æ­¤æ—¶æˆ‘ä»¬å°±å¯ä»¥è·å–æ‰€æœ‰å±‚çš„åç§°äº†ï¼Œæœ‰äº†è¿™äº›å¯ä»¥å°†å…¶IDå–å‡º for (int i = 0; i &lt; layer_names.size(); i++) &#123; int id = net.getLayerId(layer_names[i]); //é€šè¿‡nameè·å–å…¶id auto layer = net.getLayer(id); //é€šè¿‡idè·å–layer printf(&quot;layer id:%d,type:%s,name:%s\\n&quot;, id, layer-&gt;type.c_str(), layer-&gt;name.c_str()); //å°†æ¯ä¸€å±‚çš„idï¼Œç±»å‹ï¼Œå§“åæ‰“å°å‡ºæ¥ï¼ˆå¯ä»¥æ˜ç™½æ­¤ç½‘ç»œæœ‰å“ªäº›ç»“æ„ä¿¡æ¯äº†ï¼‰ &#125; waitKey(0); return 0;&#125;// g++ --std=c++11 `pkg-config opencv --cflags` main.cc -o demo `pkg-config opencv --libs` &amp;&amp; ./demo æ‰§è¡Œå‘½ä»¤ï¼š g++ --std=c++11 `pkg-config opencv --cflags` main.cc -o demo `pkg-config opencv --libs` &amp;&amp; ./demo è¾“å‡ºç»“æœï¼š g++ --std=c++11 `pkg-config opencv --cflags` main.cc -o demo `pkg-config opencv --libs` &amp;&amp; ./demo [ INFO:0@0.327] global /data/Documents/pcl2022/opencv_cc_tensorflow/opencv-4.2.0/opencv/modules/dnn/src/tensorflow/tf_importer.cpp (2991) populateNet DNN/TF: parsing model produced by TF v0 (min_consumer=0). Number of nodes = 62layer id:1,type:Convolution,name:conv2d-pool-1/conv2d/Conv2Dlayer id:2,type:ReLU,name:conv2d-pool-1/conv2d/Relulayer id:3,type:Pooling,name:conv2d-pool-1/max_pooling2d/MaxPoollayer id:4,type:Convolution,name:conv2d-pool-2/conv2d/Conv2Dlayer id:5,type:ReLU,name:conv2d-pool-2/conv2d/Relulayer id:6,type:Pooling,name:conv2d-pool-2/max_pooling2d/MaxPoollayer id:7,type:Convolution,name:conv2d-pool-3/conv2d/Conv2Dlayer id:8,type:ReLU,name:conv2d-pool-3/conv2d/Relulayer id:9,type:Pooling,name:conv2d-pool-3/max_pooling2d/MaxPoollayer id:10,type:Convolution,name:conv2d-pool-4/conv2d/Conv2Dlayer id:11,type:ReLU,name:conv2d-pool-4/conv2d/Relulayer id:12,type:Pooling,name:conv2d-pool-4/max_pooling2d/MaxPoollayer id:13,type:Permute,name:Reshape/nhwclayer id:14,type:Reshape,name:Reshapelayer id:15,type:InnerProduct,name:layer-1/dense/MatMullayer id:16,type:ReLU,name:layer-1/dense/Relulayer id:17,type:InnerProduct,name:layer-2/dense/MatMullayer id:18,type:ReLU,name:layer-2/dense/Relulayer id:19,type:InnerProduct,name:layer-3/dense/MatMullayer id:20,type:InnerProduct,name:layer-4/dense/MatMullayer id:21,type:Softmax,name:output[ INFO:0@0.422] global /data/Documents/pcl2022/opencv_cc_tensorflow/opencv-4.2.0/opencv/modules/highgui/src/registry.impl.hpp (114) UIBackendRegistry UI: Enabled backends(2, sorted by priority): GTK(1000); GTK2(990) + BUILTIN(GTK2)[ INFO:0@0.422] global /data/Documents/pcl2022/opencv_cc_tensorflow/opencv-4.2.0/opencv/modules/highgui/src/backend.cpp (90) createUIBackend UI: using backend: GTK (priority=1000) 2.1.2ã€OpenCV(C++)è°ƒç”¨TF2-PBæ¨¡å‹å¹¶è¾“å…¥ä¸€å¼ å›¾ç‰‡è¿›è¡Œåˆ†ç±»é¢„æµ‹ç»“æœæµ‹è¯•å›¾ç‰‡ä¹Ÿè¦ä¿è¯å°ºå¯¸ä¸€æ ·100*100 OPENCV+C++ æ¨ç†ä»£ç #include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/dnn.hpp&gt; //åŒ…å«dnnæ¨¡å—çš„å¤´æ–‡ä»¶#include &lt;iostream&gt;#include &lt;fstream&gt; //æ–‡ä»¶æµè¿›è¡Œtxtæ–‡ä»¶è¯»å–using namespace cv;using namespace cv::dnn; //åŒ…å«dnnçš„å‘½åç©ºé—´using namespace std;//å®šä¹‰åç§°ï¼Œç”¨äºåé¢çš„æ˜¾ç¤ºæ“ä½œString objNames[] = &#123; &quot;glod&quot;,&quot;monkey_king&quot;&#125;;int main() &#123; //æ¨¡å‹çš„pbæ–‡ä»¶ string bin_model = &quot;/data/Documents/pcl2022/opencv_cc_tensorflow/Neural_network/TFCNN/TFV2_MOLDEL/classify_gold.pb&quot;; // load DNN model Net net = readNetFromTensorflow(bin_model); //è·å–å„å±‚ä¿¡æ¯ // vector&lt;string&gt; layer_names = net.getLayerNames(); //æ­¤æ—¶æˆ‘ä»¬å°±å¯ä»¥è·å–æ‰€æœ‰å±‚çš„åç§°äº†ï¼Œæœ‰äº†è¿™äº›å¯ä»¥å°†å…¶IDå–å‡º // for (int i = 0; i &lt; layer_names.size(); i++) &#123; // int id = net.getLayerId(layer_names[i]); //é€šè¿‡nameè·å–å…¶id // auto layer = net.getLayer(id); //é€šè¿‡idè·å–layer // printf(&quot;layer id:%d,type:%s,name:%s\\n&quot;, id, layer-&gt;type.c_str(), layer-&gt;name.c_str()); //å°†æ¯ä¸€å±‚çš„idï¼Œç±»å‹ï¼Œå§“åæ‰“å°å‡ºæ¥ï¼ˆå¯ä»¥æ˜ç™½æ­¤ç½‘ç»œæœ‰å“ªäº›ç»“æ„ä¿¡æ¯äº†ï¼‰ // &#125; Mat src = imread(&quot;/data/Documents/pcl2022/opencv_cc_tensorflow/Neural_network/TFCNN/dataset2/test/1-3.jpg&quot;); //2-20,2-21,2-11,2-1 if (src.empty()) &#123; cout &lt;&lt; &quot;could not load image..&quot; &lt;&lt; endl; getchar(); return -1; &#125; imshow(&quot;src&quot;, src); //æ„å»ºè¾“å…¥(æ ¹æ®å»ºç«‹çš„ç½‘ç»œæ¨¡å‹æ—¶çš„è¾“å…¥) Mat inputBlob = blobFromImage(src, 1.0, Size(100, 100), Scalar(), true, false); //æˆ‘ä»¬è¦å°†å›¾åƒresizeæˆ100*100çš„æ‰æ˜¯æˆ‘ä»¬ç¥ç»ç½‘ç»œå¯ä»¥æ¥å—çš„å®½é«˜ //å‚æ•°1ï¼šè¾“å…¥å›¾åƒï¼Œå‚æ•°2ï¼šé»˜è®¤1.0è¡¨ç¤º0-255èŒƒå›´çš„ï¼Œå‚æ•°3ï¼šè®¾ç½®è¾“å‡ºçš„å¤§å°ï¼Œå‚æ•°4ï¼šå‡å€¼å¯¹æ‰€æœ‰æ•°æ®ä¸­å¿ƒåŒ–é¢„å¤„ç†,å‚æ•°5ï¼šæ˜¯å¦è¿›è¡Œé€šé“è½¬æ¢(éœ€è¦),å‚æ•°6ï¼šï¼Œå‚æ•°7ï¼šé»˜è®¤æ·±åº¦ä¸ºæµ®ç‚¹å‹ //ä¸Šæ–¹å¾—åˆ°çš„inputBlobæ˜¯4ç»´çš„ï¼ˆåœ¨å˜é‡çª—å£çœ‹dimï¼‰ï¼Œæ‰€ä»¥åœ¨imagewatchä¸­æ— æ³•æŸ¥çœ‹ //è®¾ç½®è¾“å…¥ //ç°åœ¨è¦å°†å…¶è¾“å…¥åˆ°åˆ›å»ºçš„ç½‘ç»œä¸­ net.setInput(inputBlob); //è¿›è¡Œæ¨æ–­å¾—åˆ°è¾“å‡º //è®©ç½‘ç»œæ‰§è¡Œå¾—åˆ°output,è°ƒç”¨forwardå¯ä»¥å¾—åˆ°ä¸€ä¸ªç»“æœ //æ­¤å¤„ä¸ç»™å‚æ•°ï¼Œå¾—åˆ°çš„æ˜¯æœ€åä¸€å±‚çš„ç»“æœï¼Œä¹Ÿå¯ä»¥è¾“å…¥å±‚æ•°å¾—åˆ°ä»»ä½•ä¸€å±‚çš„è¾“å‡ºç»“æœ Mat probMat = net.forward(); //é€šè¿‡å‰é¢çš„è¾“å‡ºå±‚çœ‹æœ€åä¸€å±‚ï¼Œå¯ä»¥çŸ¥é“è¾“å‡º7ä¸ªåˆ†ç±» //å¯¹æ•°æ®è¿›è¡Œåºåˆ—åŒ–ï¼ˆå˜æˆ1è¡Œnåˆ—çš„ï¼Œå¯ä»¥åœ¨åé¢è¿›è¡Œæ–¹ä¾¿çš„çŸ¥é“æ˜¯å“ªä¸ªindexäº†ï¼‰ Mat prob = probMat.reshape(1, 1); //reshapeå‡½æ•°å¯ä»¥è¿›è¡Œåºåˆ—åŒ–ï¼Œï¼ˆè¾“å‡ºä¸º1é€šé“1è¡Œçš„æ•°æ®ï¼Œå‚æ•°1:1ä¸ªé€šé“ï¼Œå‚æ•°2:1è¡Œï¼‰å°†è¾“å‡ºç»“æœå˜æˆ1è¡Œnåˆ—çš„ï¼Œä½†å‰é¢probMatæœ¬èº«å°±æ˜¯7*1*1 // //å®é™…ç»“æœprobMatå’Œprobç›¸åŒ // //å½“å…¶ä»–ç½‘ç»œprobMatéœ€è¦åºåˆ—åŒ–çš„æ—¶å€™ï¼Œreshapeå°±å¯ä»¥äº† //æ­¤æ—¶æ‰¾åˆ°æœ€å¤§çš„é‚£ä¸ª Point classNum; double classProb; minMaxLoc(prob, NULL, &amp;classProb, NULL, &amp;classNum);//æ­¤æ—¶åªè·å–æœ€å¤§å€¼åŠæœ€å¤§å€¼ä½ç½®ï¼Œæœ€å°å€¼ä¸ç®¡ä»– int index = classNum.x; //æ­¤æ—¶å¾—åˆ°çš„æ˜¯æœ€å¤§å€¼çš„åˆ—åæ ‡ã€‚å°±æ˜¯å…¶ç±»çš„ç´¢å¼•å€¼ï¼Œå°±å¯ä»¥çŸ¥é“å…¶ç±»åäº† printf(&quot;\\n current index=%d,possible:%2f,name=%s\\n&quot;, index, classProb, objNames[index].c_str()); //æ­¤æ—¶å¯ä»¥å°†åç§°æ‰“å°åˆ°å›¾ç‰‡ä¸Šå» putText(src, objNames[index].c_str(), Point(50, 50), FONT_HERSHEY_SIMPLEX, 0.75, Scalar(0, 0, 255), 2, 8); imshow(&quot;result&quot;, src); waitKey(50000); return 0;&#125;// g++ --std=c++11 `pkg-config opencv --cflags` inference_cv.cc -o result `pkg-config opencv --libs` &amp;&amp; ./result æ¨ç†ç»“æœè¾“å‡ºç¼–è¯‘å‘½ä»¤ï¼š g++ --std=c++11 `pkg-config opencv --cflags` inference_cv.cc -o result `pkg-config opencv --libs` &amp;&amp; ./result è¾“å‡ºæ¦‚ç‡ï¼š current index=0,possible:0.999974,name=glod è¾“å‡ºæ¦‚ç‡ï¼š current index=1,possible:0.617289,name=monkey_king 3ã€tensorflow1.xæ¨¡å‹ç”Ÿæˆtensorflow1.xè®­ç»ƒç”Ÿæˆçš„æ¨¡å‹OPENCV(C++)è°ƒç”¨æ–¹æ³•åŒä¸Šã€ä»£ç å·²ç»å¼€æºã€‘åœ°å€å¦‚ä¸‹https://github.com/KangChou/gold_monkey_king å‚è€ƒæ–‡çŒ®https://blog.csdn.net/qq_44870829/article/details/108592530?spm=1001.2014.3001.5506https://blog.csdn.net/weixin_39928773&#x2F;article&#x2F;details&#x2F;103910850m","raw":null,"content":null,"categories":[{"name":"å›¾åƒåˆ†ç±»æ¨¡å‹","slug":"å›¾åƒåˆ†ç±»æ¨¡å‹","permalink":"https://www.coomatrix.com/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"https://www.coomatrix.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"å¼€æºä¹¦ç±ä¸æºç ","slug":"books","date":"2021-04-05T14:57:06.000Z","updated":"2022-04-16T14:19:30.262Z","comments":true,"path":"2021/04/05/books/","link":"","permalink":"https://www.coomatrix.com/2021/04/05/books/","excerpt":"ä¹¦ç±ä¸‹è½½é“¾æ¥ï¼šhttps://github.com/KangChou/AI-Technology-and-Algorithm-Programming","keywords":null,"text":"ä¹¦ç±ä¸‹è½½é“¾æ¥ï¼šhttps://github.com/KangChou/AI-Technology-and-Algorithm-Programming æ•°å­¦åˆ†æä¸Šä¸‹å†Œ pythonè‡ªåŠ¨åŒ–æ“ä½œ pythonä»å…¥é—¨è®©åˆ°å®è·µ æ•°å­—ä¿¡å·å¤„ç† ã€Šæ™ºèƒ½é—®ç­”ä¸æ·±åº¦å­¦ä¹ ã€‹ https://github.com/l11x0m7/book-of-qna-code äººå·¥æ™ºèƒ½å®è·µï¼šTensorflowç¬”è®° https://github.com/jlff/tf2_notes æºç ä¸‹è½½é“¾æ¥ï¼šhttps://pan.baidu.com/s/19XC28Hz_TwnSQeuVifg1UQ æå–ç ï¼šmocm æ•°æ®ç§‘å­¦&#x2F;äººå·¥æ™ºèƒ½æ¯”èµ›è§£å†³æ–¹æ¡ˆèšåˆ:https://github.com/apachecn/awesome-data-comp-solution ã€Šå­¦ä¹ å­¦ä¹ ä¸è®¡ç®—æœºè§†è§‰ã€‹é…å¥—ä»£ç : https://github.com/frombeijingwithlove/dlcv_for_beginners ã€Šç®—æ³•å¯¼è®ºã€‹çš„C++å®ç°â€ä»£ç ï¼šhttps://github.com/huaxz1986/cplusplus-_Implementation_Of_Introduction_to_Algorithms http://www.huaxiaozhuan.com/ ã€ŠUnix ç¯å¢ƒé«˜çº§ç¼–ç¨‹ç¬¬ä¸‰ç‰ˆã€‹ç¬”è®°ï¼šhttps://github.com/huaxz1986/APUE_notes ç®—æ³•å·¥ç¨‹å¸ˆ(äººå·¥æ™ºèƒ½cvæ–¹å‘)é¢è¯•é—®é¢˜åŠç›¸å…³èµ„æ–™çš„ç½‘ç«™æ”¶é›†:https://github.com/lcylmhlcy/Awesome-algorithm-interview","raw":null,"content":null,"categories":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"https://www.coomatrix.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"æ ¸å¿ƒç®—æ³•","slug":"æ ¸å¿ƒç®—æ³•","permalink":"https://www.coomatrix.com/tags/%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95/"}]},{"title":"NLPæŠ€æœ¯æ±‡æ€»","slug":"nlp","date":"2021-04-05T14:57:06.000Z","updated":"2022-04-16T14:27:18.937Z","comments":true,"path":"2021/04/05/nlp/","link":"","permalink":"https://www.coomatrix.com/2021/04/05/nlp/","excerpt":"Deep learning speech learning library","keywords":null,"text":"Deep learning speech learning library ä¸€ä¸ªè½»é‡çº§ã€ç®€å•æ˜“ç”¨çš„ RNN å”¤é†’è¯ç›‘å¬å™¨: https://github.com/MycroftAI/mycroft-precise zh:http://fancyerii.github.io/books/mycroft-precise/ åŸºäºæ ‘è“æ´¾çš„äººå·¥æ™ºèƒ½å°è½¦ï¼Œå®ç°è¯†åˆ«ã€æç¤ºã€æ™ºèƒ½æ—…æ¸¸çº¿è·¯ã€ç¦»çº¿å›¾åƒ:https://github.com/dalinzhangzdl/AI_Car_Raspberry-pi ä¸­æ–‡NLPæ•°æ®é›†:https://github.com/CLUEbenchmark/CLUEDatasetSearch æ¨¡å‹ï¼šhttps://github.com/CLUEbenchmark/CLUE ä¸­æ–‡ NLP èµ„æºç²¾é€‰åˆ—è¡¨ ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³èµ„æ–™:https://github.com/crownpku/Awesome-Chinese-NLP è§†è§‰èŠå¤©æœºå™¨äºº:https://paperswithcode.com/paper/visual-dialog Bert&#x2F;Transformeræ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ–åŠ é€Ÿ: https://blog.csdn.net/nature553863/article/details/120292394ï¼š å¯ä»¥å‹ç¼© BERT çš„æ‰€æœ‰æ–¹å¼ï¼šhttp://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.htmlhttps://www.leiphone.com/category/academic/MkV1j604LvPt1wcx.html BERTè½»é‡åŒ–æ¢ç´¢â€”æ¨¡å‹å‰ªæï¼ˆBERT Pruningï¼‰â€”Rasaç»´åº¦å‰ªæ:https://blog.csdn.net/ai_1046067944/article/details/103609152 å‹ç¼© BERT ä»¥åŠ å¿«é¢„æµ‹é€Ÿåº¦:https://rasa.com/blog/compressing-bert-for-faster-prediction-2/ è®ºæ–‡ç»¼è¿°ä¸BERTç›¸å…³æœ€æ–°è®ºæ–‡:https://github.com/tomohideshibata/BERT-related-papers ä¸­æ–‡è‡ªç„¶è¯­è¨€æ’è¡Œæ¦œåŠè®ºæ–‡æŸ¥è¯¢:https://www.cluebenchmarks.com/index.html è®¡ç®—è¯­è¨€å­¦å›½é™…ä¼šè®®è®ºæ–‡é›†:https://aclanthology.org/volumes/2020.coling-main/ è®¡ç®—è¯­è¨€å­¦åä¼šç¬¬ 58 å±Šå¹´ä¼šè®ºæ–‡é›†:https://aclanthology.org/volumes/2020.acl-main/ è®¡ç®—è¯­è¨€å­¦2åä¼š2021å¹´ä¼šè®ºæ–‡æœé›†ï¼šhttps://aclanthology.org/events/acl-2021/ ä¸­æ–‡BERTå…¨è¯æ©è”½é¢„è®­ç»ƒï¼ˆä¸­æ–‡BERT-wwmç³»åˆ—æ¨¡å‹ï¼‰https://github.com/ymcui/Chinese-BERT-wwm ä¸€ä¸ªå¤§è§„æ¨¡çš„ä¸­æ–‡è·¨é¢†åŸŸé¢å‘ä»»åŠ¡çš„å¯¹è¯æ•°æ®é›†:https://github.com/thu-coai/CrossWOZ å…³äºConvLab-2ï¼šç”¨äºæ„å»ºã€è¯„ä¼°å’Œè¯Šæ–­å¯¹è¯ç³»ç»Ÿçš„å¼€æºå·¥å…·åŒ…ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰ï¼šhttps://github.com/thu-coai/ConvLab-2 è§†è§‰å’Œè¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ (VL-PTM) çš„æœ€æ–°è¿›å±•(è¯­éŸ³è§†è§‰èåˆ):https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†é˜…è¯»æ¸…å•:https://github.com/IsaacChanghau/DL-NLP-Readings è§†è§‰é—®ç­” (VQA)ï¼ˆå›¾åƒ&#x2F;è§†é¢‘é—®ç­”ï¼‰ã€è§†è§‰é—®é¢˜ç”Ÿæˆã€è§†è§‰å¯¹è¯ã€è§†è§‰å¸¸è¯†æ¨ç†å’Œç›¸å…³é¢†åŸŸçš„ç²¾é€‰åˆ—è¡¨ï¼šhttps://github.com/jokieleung/awesome-visual-question-answering","raw":null,"content":null,"categories":[{"name":"äººå·¥æ™ºèƒ½","slug":"äººå·¥æ™ºèƒ½","permalink":"https://www.coomatrix.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"æ ¸å¿ƒç®—æ³•","slug":"æ ¸å¿ƒç®—æ³•","permalink":"https://www.coomatrix.com/tags/%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95/"}]},{"title":"å€¼å¾—ä½ é˜…è¯»çš„Hexoä¸ªäººåšå®¢æ­å»ºï¼šä¸ç”¨è´­ä¹°æœåŠ¡å™¨ï¼Œä¸ç”¨è´­ä¹°åŸŸåï¼Œä¸è¦é’±ï¼Œä¸ç”¨æ•²ä»£ç ç­‰ç­‰ï¼Œæ˜¯çš„ï¼Œä½ æ²¡æœ‰çœ‹é”™ï¼Œå¿«æ¥è½¬è½½å­¦ä¹ å§ï¼","slug":"blog","date":"2020-04-05T14:57:06.000Z","updated":"2022-04-16T14:44:47.494Z","comments":true,"path":"2020/04/05/blog/","link":"","permalink":"https://www.coomatrix.com/2020/04/05/blog/","excerpt":"æœ¬æ–‡çš„åŸæ–‡åœ¨æˆ‘çš„å¾®ä¿¡å…¬ä¼—å·ï¼Œæ¬¢è¿ç‚¹å‡»ä¸‹é¢è“è‰²å­—ä½“é“¾æ¥è¿›å…¥ä¸»é¡µ å€¼å¾—ä½ é˜…è¯»çš„Hexoä¸ªäººåšå®¢æ­å»º Hexoå¿«é€Ÿæ­å»ºä¸ªäººåšå®¢ï¼ˆ2019&#x2F;10&#x2F;22æ›´æ–°ï¼‰ ä½¿ç”¨åˆ°çš„å·¥å…· ï¼ˆæœ¬æ•™ç¨‹ç»Ÿä¸€åœ¨Windowsç³»ç»Ÿä¸‹æ­å»ºï¼‰ Node.jsã€Hexoã€Gitã€Githubè´¦å·ã€Sublime Text3 è¯·è‡ªè¡Œæ³¨å†Œä¸€ä¸ªGithubè´¦å· æœ€åçš„éƒ¨ç½²åˆ°ç½‘ä¸Šçš„åšå®¢å±•ç¤º æ–‡ç« ç›®å½•ï¼š å‰è¨€ å€¼å¾—ä½ çŸ¥é“çš„è¯ ä¸€ã€ä»åˆ›å»ºåˆ°éƒ¨ç½²åšå®¢ äºŒã€åšå®¢çš„ç½‘é¡µä¸»é¢˜ ä¸‰ã€æ›´æ¢åŸŸå+åšå®¢æµ‹è¯•æˆåŠŸ","keywords":null,"text":"æœ¬æ–‡çš„åŸæ–‡åœ¨æˆ‘çš„å¾®ä¿¡å…¬ä¼—å·ï¼Œæ¬¢è¿ç‚¹å‡»ä¸‹é¢è“è‰²å­—ä½“é“¾æ¥è¿›å…¥ä¸»é¡µ å€¼å¾—ä½ é˜…è¯»çš„Hexoä¸ªäººåšå®¢æ­å»º Hexoå¿«é€Ÿæ­å»ºä¸ªäººåšå®¢ï¼ˆ2019&#x2F;10&#x2F;22æ›´æ–°ï¼‰ ä½¿ç”¨åˆ°çš„å·¥å…· ï¼ˆæœ¬æ•™ç¨‹ç»Ÿä¸€åœ¨Windowsç³»ç»Ÿä¸‹æ­å»ºï¼‰ Node.jsã€Hexoã€Gitã€Githubè´¦å·ã€Sublime Text3 è¯·è‡ªè¡Œæ³¨å†Œä¸€ä¸ªGithubè´¦å· æœ€åçš„éƒ¨ç½²åˆ°ç½‘ä¸Šçš„åšå®¢å±•ç¤º æ–‡ç« ç›®å½•ï¼š å‰è¨€ å€¼å¾—ä½ çŸ¥é“çš„è¯ ä¸€ã€ä»åˆ›å»ºåˆ°éƒ¨ç½²åšå®¢ äºŒã€åšå®¢çš„ç½‘é¡µä¸»é¢˜ ä¸‰ã€æ›´æ¢åŸŸå+åšå®¢æµ‹è¯•æˆåŠŸ å‰è¨€ä»Šå¤©ä¸€ç›´åœ¨é’»ç ”è¿™ä¸ªåšå®¢ï¼Œå¹¶æœç´¢äº†å¤§é‡æœ‰å…³hexoæ­å»ºåšå®¢çš„æ•™ç¨‹è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä½œä¸ºä¸€ä¸ªç¬¬ä¸€æ¬¡ä½¿ç”¨Hexoæ­å»ºä¸ªäººåšå®¢çš„èœé¸Ÿï¼Œæˆ‘å‘ç°æˆ‘è¸©äº†ä¸å°‘å‘ï¼Œå“ˆå“ˆï¼Œåœ¨è¿™é‡Œæˆ‘ä¸å¾—ä¸åæ§½ä¸€ä¸‹æŸäº›æ’°å†™Hexoæ­å»ºä¸ªäººåšå®¢çš„æŠ€æœ¯äººå‘˜ï¼Œç”¨ä¸€ä¸ªå­—æ¥å½¢å®¹ä»–ä»¬çš„åšå®¢å°±æ˜¯â€œä¹±â€ï¼Œä¹±æ˜¯å› ä¸ºæˆ‘è¯»å®Œä»–ä»¬çš„åšå®¢å†™çš„å†…å®¹å‘ç°é€»è¾‘é¡ºåºç®€ç›´çœ‹å¾—æˆ‘ä¸€å¤´é›¾æ°´ã€ç»†èŠ‚å†…å®¹å¯¹äºä»–ä»¬æ¥è¯´å°±æ˜¯ä¸€ä¸ªæ‘†è®¾ï¼Œéš¾æ€ªæœ‰å¥½å¤šäººçœ‹ä¸æ‡‚ä¹Ÿæ˜¯åº”è¯¥çš„ã€‚å½“ç„¶ï¼Œå¯èƒ½æ˜¯æˆ‘çš„æ°´å¹³ä¸å¤Ÿï¼Œä¹Ÿæˆ–è®¸æ˜¯åœ¨æ‹œè¯»ä»–ä»¬çš„å¤§ä½œæ—¶å€™ä¸å¤Ÿè®¤çœŸå’Œä¸¥è°¨ã€‚ ä½†æˆ‘è¿˜æ˜¯è¦å‘Šè¯«ä¸€ä¸‹ä¸€äº›æŠ€æœ¯ç¼–è¾‘è€…ï¼š å¦‚æœæ˜¯æ€•åˆ«äººå·å­¦ä½ çš„å†…å®¹ï¼Œé‚£å°±ä¸è¦å‘åœ¨ç½‘ä¸Šï¼›å¦‚æœä½ å‘åœ¨ç½‘ä¸Šï¼Œè¯·è€ƒè™‘æˆ‘ä»¬è¯»è€…çš„æ„Ÿå—ï¼Œè¦å¯¹è‡ªå·±èŠ±è´¹é‚£ä¹ˆå¤šæ—¶é—´æ’°å†™çš„å†…å®¹è´Ÿè´£ï¼Œè¦è®©åˆ«äººçœ‹æ‡‚ä½ çš„æ–‡ç« ï¼Œè®©åˆ«äººæ¬£èµä½ çš„ä½œå“ã€‚å…¶å®ï¼Œæœ‰æ—¶å€™è¿˜èƒ½çœ‹å‡ºä¸€ä¸ªäººçš„å“æ€§ã€‚ åæ§½åˆ°æ­¤ç»“æŸ~ä¸‹é¢å¼€å§‹è¿›å…¥åšå®¢æ­å»ºç¯èŠ‚ å€¼å¾—ä½ çŸ¥é“åˆ°è¯ï¼š æ˜¯çš„ï¼Œä½ æ²¡æœ‰çœ‹é”™ï¼ ä¸ç”¨æœåŠ¡å™¨ï¼Œä¸ç”¨æ³¨å†ŒåŸŸåï¼Œä¸ç”¨èŠ±é’±ï¼Œä¸ç”¨æ•²å¤§ä»£ç ç­‰ç­‰ ä¸€ä¸ªåšå®¢å°±å€¼å¾—ä½ æ‹¥æœ‰ ä¸€ã€ä»åˆ›å»ºåˆ°éƒ¨ç½²åšå®¢**1ã€å®‰è£…å¥½Node.js åˆ«å¿˜äº†ç”¨å‘½ä»¤npmæ£€éªŒNode.jså®‰è£…æ˜¯å¦å®Œæˆï¼Œ å…³äºhexoçš„å®‰è£…æ•™ç¨‹æ¯”è¾ƒç®€å•ï¼Œç½‘ä¸Šæœ‰å¾ˆå¤šå®Œæ•´çš„æ•™ç¨‹ï¼Œåœ¨è¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚**** å®‰è£…Hexo å‘½ä»¤ï¼š npm install -g hexo-cliè¡¥å……:å®‰è£…hexo-helper-live2d çœ‹é—¨åŠ¨ç”»æ’ä»¶ npm install â€“save hexo-helper-live2d \\ ä¸€å®šè¦åœ¨ä½ åšå®¢ç›®å½•çš„æŒ‡å®šè·¯å¾„ä¸‹ï¼ˆE:\\hexo\\KangChouï¼‰æ‰§è¡Œï¼Œå¦åˆ™åœ¨node_modulesä¹‹ä¸­å®‰è£…ä¸äº†npm uninstall hexo-helper-live2d npm install --save hexo-helper-live2dnpm install live2d-widget-model-hibiki npm install npm install --save live2d-widget-model-xxxæ¥å®‰è£…ä½ å–œæ¬¢çš„æ¨¡å‹å‚è€ƒï¼šhttps://zhuanlan.zhihu.com/p/349278862 å‚è€ƒæ–‡çŒ®: https://blog.csdn.net/qq_36239569/article/details/104104894https://zhuanlan.zhihu.com/p/350654582 è§£å†³åŠæ³•ï¼šé¦–å…ˆnpm config set proxy null ä»£ç†ç½®ä¸ºç©ºè¿è¡Œnpm cache clean --forceæ¸…ç†ç¼“å­˜ç„¶åå°è¯•æ‰§è¡Œnpm config set registry http://registry.npmjs.org/å¦‚æœå«Œå®‰è£…ä¾èµ–æ…¢çš„è¯ å¯ä»¥ä½¿ç”¨å›½å†…æ·˜å®é•œåƒnpm config set registry https://registry.npm.taobao.org å›½å†…é•œåƒä¸‹è½½å°±æ˜¯å¿«ï¼š åšå®Œäº†è¿™ä¸€æ­¥ä¹‹åï¼Œæ­å–œä½ ï¼Œå‰æœŸçš„å‡†å¤‡å·¥ä½œå·²ç»å®Œæˆï¼Œç¯å¢ƒè¿™ä¸€æ­¥ç»“æŸäº†ã€‚ 2ã€å®‰è£…å¥½Git 3ã€åœ¨Cç›˜ä¸‹åˆ›å»ºhexoæ–‡ä»¶å¤¹ 4ã€æ‰“å¼€Hexoæ–‡ä»¶å¤¹ä¸‹ï¼Œå³é”®ç‚¹å‡»Git bash ä¸‹æ‰§è¡Œå‘½ä»¤ å·¥ç¨‹æ–‡ä»¶ç›®å½•ï¼š å†ä½¿ç”¨ä¸€æ¬¡è¿™ä¸ªå‘½ä»¤ï¼šnpm install hexo-cli -gåœ¨ç»ˆç«¯ä½¿ç”¨npmå®‰è£…hexo åˆ›å»ºåšå®¢KangChouï¼šhexo init KangChou cd KangChou npm install 5ã€å‘½ä»¤hexo serverå¯åŠ¨githubæœåŠ¡å™¨ 6ã€æµè§ˆåšå®¢ å®‰ç…§5ä¸­æç¤ºçš„ç½‘å€http://localhost:4000/ å¤åˆ¶è¯¥ç½‘å€åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼šè¿™æ ·ä¸€ä¸ªåšå®¢çš„æ¶å­å°±å‡ºæ¥äº†ã€‚ 7ã€éƒ¨ç½²å‰å“¨ï¼ˆä¸€ï¼‰ï¼šæ·»åŠ Githubä»“åº“åœ°å€ åœ¨éƒ¨ç½²ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆçŸ¥é“åšå®¢çš„éƒ¨ç½²åœ°å€ï¼Œå®ƒéœ€è¦å¯¹åº” GitHub çš„ä¸€ä¸ª Repository çš„åœ°å€ï¼Œè¿™ä¸ªä¿¡æ¯éœ€è¦æˆ‘ä»¬æ¥é…ç½®ä¸€ä¸‹ã€‚(è¿™é‡Œæˆ‘å°±çœç•¥äº†ï¼Œè‡ªå·±å»å¸ƒç½®)ï¼Œè¿™æ˜¯æˆ‘çš„è¿™ä¸ªGithubä»“åº“ https://github.com/KangChou/KangChou.github.io.git æ‰“å¼€æ–‡ä»¶Hexoä¸‹çš„KangChouæ–‡ä»¶æ ¹ç›®å½•ä¸‹çš„ _config.yml æ–‡ä»¶ï¼Œæˆ‘ä½¿ç”¨ç¼–è¾‘å™¨Sublime Text3æ‰“å¼€çš„ï¼ˆæˆ–è€…ä½ ä½¿ç”¨å…¶ä»–ä»£ç ç¼–è¾‘å™¨æ‰“å¼€ï¼Œåƒä¸‡åˆ«ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ï¼‰ï¼Œæ‰¾åˆ° Deployment è¿™ä¸ªåœ°æ–¹(æç¤ºï¼šæ–‡ä»¶æœ€å)ï¼ŒæŠŠåˆšæ‰æ–°å»ºçš„ Repository çš„åœ°å€è´´è¿‡æ¥ 8ã€éƒ¨ç½²å‰å“¨ï¼ˆäºŒï¼‰ï¼š****éƒ¨ç½²æ’ä»¶ éœ€è¦å®‰è£…ä¸€ä¸ªæ”¯æŒ Git çš„éƒ¨ç½²æ’ä»¶ï¼š hexo-deployer-gitï¼Œæœ‰äº†å®ƒæˆ‘ä»¬æ‰å¯ä»¥é¡ºåˆ©å°†å…¶éƒ¨ç½²åˆ° GitHub ä¸Šé¢(å¦‚æœä¸å®‰è£…çš„è¯ï¼Œåœ¨æ‰§è¡Œéƒ¨ç½²å‘½ä»¤æ—¶ä¼šæŠ¥é”™). 9ã€ä¸‹é¢å¼€å§‹éƒ¨ç½²åˆ°Github å¦‚æœ8çš„æ’ä»¶éƒ¨ç½²æ²¡æœ‰é—®é¢˜å°±å¼€å§‹è¿›è¡Œéƒ¨ç½²ï¼Œé¦–å…ˆè¾“å…¥éƒ¨ç½²å‘½ä»¤å¦‚ä¸‹ï¼šhexo deploy ç»“å°¾â€¦. å¯ä»¥å‘ç°å‡ºç°äº†ä¸Šé¢çš„æŠ¥é”™æç¤ºï¼š Error: Spawn failed è§£å†³æ–¹æ³•ç¬¬ä¸€æ¬¡ï¼š ç»æœç´¢å¤§é‡èµ„æ–™å‘ç°äº†ä¸‹é¢çš„è¿™ä¸ªåšå®¢å‡ºç°ç±»ä¼¼ä¸Šè¿°çš„ä¸€æ ·é—®é¢˜ï¼Œçœ‹äº†è¿™ä¸ªè§£å†³åŠæ³•ï¼Œæˆ‘å°±æ–—èƒ†è¯•ä¸€è¯•ï¼š https://blog.csdn.net/njc_sec/article/details/89021083 å¯æƒœæˆ‘å†é‡æ–°å®‰è£…ä¸Šè¿°çš„ä¸‰ä¸ªå‘½ä»¤è¾“å…¥ä¹‹åè¿˜æ˜¯å‡ºå…ˆä¸€æ ·çš„é”™è¯¯ã€‚ è§£å†³æ–¹æ³•ç¬¬äºŒæ¬¡ï¼š å› æ­¤æˆ‘æ€€ç–‘å¯èƒ½æ˜¯ä»“åº“çš„åœ°å€å‡ºé”™ï¼Œå› æ­¤å»çœ‹çœ‹äº†çœ‹åœ°å€ è¿™æ˜¯åŸæ¥çš„åœ°å€ï¼š deploy: æˆ‘æŒ‰ç…§å‡ºç°é”™è¯¯æç¤ºä¸­çš„ç½‘å€å»æ‰“å¼€å®ƒï¼š https://hexo.io/docs/troubleshooting.html å¹¶æ‰¾åˆ°äº†éƒ¨ç½²åˆ°Githubç›®å‰çš„è¯­æ³•è§„å®šçš„ç½‘é¡µä¸‹ https://hexo.io/docs/github-pages æŒ‰ç…§ä¸Šé¢å¯¹éƒ¨ç½²ä»“åº“çš„åœ°å€ï¼Œæˆ‘å°†ä¸Šè¿°çš„Deployçš„æºç ä¿®æ”¹ä¸º deploy: äºæ˜¯æˆ‘å†è¯•äº†ä¸Šè¿°çš„ä¸‰ä¸ªå‘½ä»¤ï¼š hexo clean hexo g hexo d æœ€ç»ˆå‡ºç°ä¸‹é¢çš„ç»“æœ:è¯´æ˜å‡ºç°çš„é—®é¢˜è§£å†³äº† ç”±äºæˆ‘èµ·åˆæ²¡æœ‰éƒ¨ç½²ä»“åº“çš„å¯†é’¥ï¼Œæ‰€ä»¥è¦å»ä»“åº“éƒ¨ç½²ã€‚ 10ã€åˆ›å»ºçš„ ssh å¯†é’¥çš„å¯†ç  (1)ã€æˆ‘æ‰“å¼€äº†æˆ‘å¾—ä»“åº“ï¼Œå¹¶æ‰¾åˆ°äº†è®¾ç½® ï¼ˆ2ï¼‰æŸ¥çœ‹éƒ¨ç½²å¯†é’¥æŒ‡å—ä»¥äº†è§£æ›´å¤šä¿¡æ¯ https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys æ‰¾åˆ°äº†è®¾ç½®å¯†ç çš„æ­¥éª¤ï¼ˆç»è¿‡ç¿»è¯‘ä»¥åï¼Œç›®å‰æˆ‘ä»¬è¿›è¡Œåˆ°ä¸‹é¢çš„5ï¼‰ ï¼ˆ3ï¼‰æ€ä¹ˆåˆ›å»ºSSHå¯†é’¥? æ­¥éª¤ï¼š æ‰¾åˆ°æœ¬åœ°ç¯å¢ƒï¼šC:\\Users\\admin.ssh è¿™ä¸ªè·¯å¾„ä¸‹çš„ç”¨æˆ·&#x2F;åç§°&#x2F;.ssh åœ¨è¿™è·¯å¾„ä¸‹ï¼Œæ‰“å¼€gitbubçš„å‘½ä»¤æ§åˆ¶å° (I): git init &#x2F;&#x2F;åˆå§‹åŒ–ä¸€ä¸‹ï¼Œçœ‹çœ‹è·¯å¾„å¯¹ä¸å¯¹ (II):ssh-keygen -t rsa -C â€œä½ çš„é‚®ç®±â€ åˆ°æœ¬åœ°ç¯å¢ƒ.sshè·¯å¾„ä¸‹æŸ¥çœ‹ï¼Œæ˜¯å¦ç”Ÿæˆid_rsa,id_rsa.pubè¿™ä¸ªä¸¤ä¸ªæ–‡ä»¶ ç”Ÿæˆåï¼Œç°åœ¨æŠŠid_rsa.pubé‡Œé¢çš„å†…å®¹å¤åˆ¶åˆ°githubd çš„add github key çš„keyé‡Œé¢ï¼ˆä¹Ÿå°±æ˜¯åˆšåˆšä»“åº“çš„å¯†é’¥æ·»åŠ çš„åœ°æ–¹ï¼‰ ç‚¹å‡»Add SSH keyè·å¾—ä¸‹é¢ç»“æœ æ³¨æ„ï¼šç¬¬ä¸€æ¬¡æäº¤ï¼Œé…ç½®å¯†é’¥ï¼Œéœ€è¦è¾“å…¥githubçš„å¯†ç ï¼Œå¦‚ä¸‹å°±æ˜¯æ·»åŠ ç§˜é’¥æˆåŠŸ å¯†é’¥é…ç½®æˆåŠŸåï¼Œè¦éªŒè¯ä¸€ä¸‹æ˜¯å¦é…ç½®æˆåŠŸ å‘½ä»¤ï¼šssh -T &#103;&#x69;&#x74;&#x40;&#x67;&#x69;&#116;&#x68;&#x75;&#x62;&#x2e;&#99;&#111;&#x6d; å‡ºç°ä¸‹é¢æç¤ºï¼Œè¯´æ˜é…ç½®æˆåŠŸã€‚ Hi KangChou&#x2F;KangChou.github.io! Youâ€™ve successfully authenticated, but GitHub does not provide shell access 11ã€å†æ¬¡ä½¿ç”¨å¯†é’¥éƒ¨ç½² ä»ç„¶ä½¿ç”¨å‘½ä»¤ï¼š hexo clean hexo g hexo d å¦‚æœéƒ½æ²¡æœ‰é—®é¢˜å°±ä¼šå‡ºç°ä¸‹é¢çš„ç»“æœï¼Œè¾“å…¥ä½ åˆšåˆšè®¾ç½®çš„åå’ŒSSHçš„å¯†ç  ä½†æ˜¯è¿™é‡Œåˆå‡ºé”™äº† è¿½æ ¹æº¯æºï¼Œæˆ‘æ€€ç–‘è¿˜æ˜¯éƒ¨ç½²çš„ä»“åº“å‡ºç°äº†é—®é¢˜ï¼šå› æ­¤æˆ‘å†æ¬¡æ‰“å¼€ï¼Œå¹¶åšäº†ä¿®æ”¹ å‘½ä»¤hexo dæ‰§è¡Œåˆå‡ºé”™ ä¸‹é¢ç»ˆäºæ‰¾åˆ°äº†ç­”æ¡ˆã€‚è¿™é‡Œè¦ç‰¹åˆ«æ„Ÿè°¢**@æå…¸é‡‘ @å´”åº†æ‰ä¸¤ä½ç½‘ç»œå¼€å‘å¤§ä½¬çš„ç»†èŠ‚**ç‚¹æ‹¨æ‰é€šè¿‡äº†ä¸Šé¢çš„ä¸€ä¸ªå°ç¯èŠ‚ï¼Œä»è€Œæˆ‘åŠ›æŒ½ç‹‚æ¾œï¼Œä¸€æ°”å‘µæˆï¼Œæ­å»ºäº†åé¢çš„æ‰€æœ‰æ¡†æ¶ã€‚ å¤‡æ³¨ï¼šssh-keygen -t rsa -C â€œ&#107;&#x61;&#110;&#103;&#99;&#104;&#x6f;&#x75;&#x36;&#54;&#x36;&#64;&#x67;&#109;&#x61;&#x69;&#108;&#46;&#99;&#111;&#109;â€œä¸ç”¨è¾“å…¥å¯†ç ï¼Œå›è½¦å°±å¯ä»¥ç”Ÿæˆã€‚å¦‚æœéœ€è¦ä¸¥å¯†ä¸€ç‚¹ï¼Œå¯ä»¥è¿›è¡ŒåŠ å¯†åŠŸèƒ½çš„éƒ¨ç½²ã€‚ 12ã€ç»ˆäºéƒ¨ç½²æˆåŠŸ æœ€åç»ˆäºæ‰¾åˆ°äº†é”™è¯¯çš„åŸå› ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘åˆ›å»ºçš„ä»“åº“ä¸‹Githubçš„SSHé”™è¯¯ å› æ­¤ï¼Œæˆ‘å»ä»“åº“æ‰¾åˆ°äº† å°†çº¢è‰²çš„éƒ¨åˆ†å¤åˆ¶åˆ°hexoæ–‡ä»¶ç›®å½•ä¸‹ä¹Ÿå°±æ˜¯ä½ çš„åšå®¢æ–‡ä»¶æœ«å°¾ï¼Œæ‰“å¼€ä¿®æ”¹å¦‚ä¸‹ å†æ¬¡è¾“å…¥å‘½ä»¤hexo dæ‰§è¡Œä»¥åå‡ºç°ä¸‹é¢çš„ç»“æœï¼Œ å‡ºç°Deploy done :gitè¯´æ˜å·²ç»éƒ¨ç½²æˆåŠŸ è¿™æ—¶å€™æˆ‘ä»¬è®¿é—®ä¸€ä¸‹ GitHub Repository åŒåçš„é“¾æ¥ï¼Œ æ¯”å¦‚æˆ‘çš„ KangChou åšå®¢çš„ Repository åç§°å–çš„æ˜¯ KangChou.github.ioï¼Œ é‚£æˆ‘å°±è®¿é—® http://KangChou.github.io è¿™æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°è·Ÿæœ¬åœ°ä¸€æ¨¡ä¸€æ ·çš„åšå®¢å†…å®¹äº†ã€‚ ï¼ˆæ­¤æ—¶ä½ ç”¨æ‰‹æœºåŒæ ·å¯ä»¥æ‰“å¼€è¯¥ç½‘ç«™ï¼‰ äºŒã€åšå®¢çš„ç½‘é¡µä¸»é¢˜**ä¸»é¢˜çš„è®¾ç½®åŒ…æ‹¬ä¸­æ–‡é¡µé¢ã€æ•´ä¸ªé¡µé¢çš„æ ·å¼ã€é¡µé¢é£æ ¼ç­‰ç­‰ï¼Œ ç›®å‰ Hexo é‡Œé¢åº”ç”¨æœ€å¤šçš„ä¸»é¢˜åŸºæœ¬å°±æ˜¯ Next ä¸»é¢˜ï¼Œ è¿™ä¸ªä¸»é¢˜è¿˜æ˜¯æŒºå¥½çœ‹çš„ï¼Œå¹¶ä¸”å®ƒæ”¯æŒçš„ä¸€äº›æ’ä»¶å’ŒåŠŸèƒ½éƒ½æä¸ºä¸°å¯Œï¼Œ é…ç½®äº†è¿™ä¸ªä¸»é¢˜ï¼Œæˆ‘ä»¬çš„åšå®¢å¯ä»¥æ”¯æŒæ›´å¤šçš„æ‰©å±•åŠŸèƒ½ï¼Œæ¯”å¦‚é˜…è§ˆè¿›åº¦æ¡ã€ä¸­è‹±æ–‡ç©ºæ ¼æ’ç‰ˆã€å›¾ç‰‡æ‡’åŠ è½½ç­‰ç­‰ã€‚ 13ã€ä¸‹è½½ä¸»é¢˜ æ‰“å¼€æˆ‘çš„ç”µè„‘åˆ›å»ºçš„Hexoæ–‡ä»¶å¤¹ä¸‹çš„KangChouç›®å½•ï¼Œ å•å‡»å³é”®Git bushè¾“å…¥ä¸‹é¢çš„å‘½ä»¤ï¼Œæ‰§è¡Œç»“æœå¦‚ä¸‹ï¼š git clone https://github.com/theme-next/hexo-theme-next themes&#x2F;next å°†ä¸‹è½½åçš„themesä¸»é¢˜æ›¿æ¢åŸæ–‡ä»¶landscapeä¸­é‡Œæ‰€æœ‰çš„æ–‡ä»¶ï¼Œå¹¶è¾“å…¥å¯åŠ¨æœåŠ¡å™¨å‘½ä»¤ hexo server æ‰§è¡Œç»“æœå¦‚ä¸‹ å¤‡æ³¨ï¼šä½¿ç”¨æ•°å­¦å…¬å¼éœ€è¦å®‰è£…è¿™ä¸ªå·¥å…·ï¼šnpm install hexo-math 14ã€é…ç½®ä¸­æ–‡ç¯å¢ƒ åœ¨åšå®¢kangchouç›®å½•ä¸‹æ‰“å¼€_config.ymlä¿®æ”¹è¯­è¨€ä¸ºä¸­æ–‡æ±‰è¯­zh-Hans æ‰§è¡Œçš„ç»“æœå¦‚ä¸‹ ç”±äºè¿™åªæ˜¯éƒ¨åˆ†ä¸ºä¸­æ–‡ï¼Œè€Œæˆ‘çš„ç›®çš„æ˜¯å¤§éƒ¨åˆ†æ˜¯ä¸­æ–‡çš„ï¼Œ ä¸ºäº†æ–¹ä¾¿è¿˜è¦åœ¨ç½‘é¡µä¸Šæ‰‹åŠ¨æ·»åŠ æ›´å¤šä¸­æ–‡æè¿° 15ã€é…ç½®ä¸­æ–‡èœå•æ  æ‰“å¼€C:\\Hexo\\KangChou\\themes\\landscape\\languages å‘æœ‰ä¸‰ç§æ±‰è¯­:ç®€ä½“ä¸­æ–‡ã€é¦™æ¸¯ç¹ä½“ã€å°æ¹¾ç¹ä½“ ç„¶åç‚¹å¼€zh-Hans.ymlå…¶ä¸­çš„é…ç½®é¡¹å°±æ˜¯å·²ç»ç¿»è¯‘çš„æ–‡æœ¬ ç½‘ç«™ä¼šæ ¹æ®ä½ ç«™ç‚¹é…ç½®``ymlä¸­çš„è¯­è¨€é…ç½®æ¥å»è¯»å–å¯¹åº”çš„è¯­è¨€æ–‡ä»¶ æ‰“å¼€ä½ languages``çš®è‚¤é…ç½®``ymlä½ ä¼šçœ‹åˆ°èœå•æ åŸºç¡€é…ç½®ï¼š å‘ç°homeå’Œarchivesèœå•æ˜¯å¼€å¯çš„ï¼Œ ç°åœ¨æˆ‘ä»¬å…¨éƒ¨å¼€****å¯ï¼Œåªéœ€è¦å»æ‰å‰é¢çš„#ï¼Œåˆ·æ–°æµè§ˆå™¨ å°è¯•ä¿®æ”¹ç«™ç‚¹é…ç½®ymlè¯­è¨€ï¼Œé‡å¯æœåŠ¡ååˆ·æ–°æµè§ˆå™¨ æ˜¾ç„¶ç»“æœå¾ˆæˆåŠŸï¼Œ****ä¸‹é¢å…³é—­git,å°†ç»“æœä¸Šä¼ åˆ°Githubé¡µé¢ï¼š é‡æ–°æ‰“å¼€è¾“å…¥éƒ¨ç½²çš„ä¸‰ä¸ªå‘½ä»¤ï¼š hexo clean hexo g hexo d ç»“æœå’Œä¸Šé¢ä¸€æ ·ï¼Œæ­¤æ—¶å°±å¯ä»¥è®¿é—®äº†. è®¿é—®ç½‘ç«™****https://kangchou.github.io/ å®é™…ä¸Šæ–‡ç« åˆ°è¿™é‡Œå°±å·²ç»ç»“æŸåšå®¢çš„æ­å»ºäº†ï¼Œè‡³äºå…¶ä»–çš„ æ¯”å¦‚ä¸Šä¼ æ–‡ç« ã€ä¸Šä¼ å›¾ç‰‡ï¼Œæ·»åŠ logoç­‰è¿™äº›æˆ‘è¿™é‡Œå°±ä¸è¯´äº†ï¼Œ hexoå®˜ç½‘ä»¥åŠå…¶ä»–ç½‘ç«™éƒ½èƒ½æœç´¢åˆ°å…·ä½“çš„æ•™ç¨‹ï¼Œ æƒ³ç»§ç»­å®Œå–„åšå®¢ç½‘ç«™éƒ¨ç½²çš„æœ‹å‹å¯ä»¥å»æœç´¢ç›¸å…³æ–‡çŒ®å­¦ä¹ ã€‚ ä¸‰ã€æ›´æ¢åŸŸå**ç›¸ä¿¡æ‰€æœ‰åšäº’è”ç½‘å¼€å‘çš„ç§‘æŠ€å·¥ä½œè€…éƒ½çŸ¥é“ï¼Œå¦‚æœæ‹¥æœ‰å±äºè‡ªå·±çš„ç½‘ç«™ä¸€å®šå¾—çœ‹èµ·æ¥å¾ˆä¸“ä¸šã€å¾ˆå®˜æ–¹ã€å¾ˆå¤§æ°”ã€‚å› æ­¤ï¼Œæœ‰äº›ç§‘æŠ€å·¥ä½œè€…å°±æƒ³æ›´æ¢è‡ªå·±ç½‘ç«™çš„åŸŸåï¼Œè®©è‡ªå·±çš„åŸŸåçœ‹èµ·æ¥å®˜æ–¹æ ‡å‡†ã€‚ä¹Ÿè¿˜æœ‰å¦ä¸€ä¸ªåŸå› ï¼Œå› ä¸ºGithubæ¯•ç«Ÿæ˜¯å¤–å›½ç½‘ç«™ï¼Œå›½å†…ç”¨æˆ·è®¿é—®ç›¸å¯¹è¾ƒæ…¢ï¼Œå› æ­¤ï¼Œå¦‚æœæœ‰å›½å†…çš„åŸŸåä½œä¸ºè¾…åŠ©ä¼šäº‹åŠåŠŸå€ã€‚äº‹å®ä¸Šï¼Œæˆ‘ä¸ªäººè§‰å¾—åªè¦å¯ä»¥æ­å»ºç½‘ç«™ï¼Œå³ä¾¿æ˜¯ä¸æ¢åŸŸåä¹Ÿæ²¡ä»€ä¹ˆåŒºåˆ«ã€‚ä¸è¿‡ï¼Œæ—¢ç„¶æˆ‘ç»™å¤§å®¶å†™è¿™ä¸ªæ•™ç¨‹ï¼Œæˆ‘è¿˜æ˜¯æœ‰å¿…è¦è¯´ä¸€ä¸‹ï¼Œæ¯•ç«Ÿæœ‰å¾ˆå¤šäººè¿˜æ˜¯æ„¿æ„æ¢åŸŸåçš„ã€‚å¦‚æœä¸æƒ³èŠ±é’±ä¹°åŸŸåçš„ï¼Œè¿™ä¸€å°èŠ‚å¯ä»¥è·³è¿‡ã€‚******16ã€è´­ä¹°åŸŸå+æ³¨å†Œé˜¿é‡Œç½‘+å®åè®¤è¯*è‡ªè¡Œæ³¨å†Œï¼Œå¦‚æœä½ æ˜¯åœ¨æ ¡å¤§å­¦ç”Ÿï¼ŒåŒ…æ‹¬ç¡•å£«ã€åšå£«è´­ä¹°åŸŸåéƒ½æ˜¯æœ‰å­¦ç”Ÿä»·ä¼˜æƒ çš„ï¼Œä½†æ˜¯ä¸€å®šè¦ä½¿ç”¨è‡ªå·±åœ¨å­¦æ ¡æ³¨å†Œçš„ç”µå­é‚®ç®±ï¼Œå› ä¸ºé˜¿é‡Œäº‘å®˜ç½‘æ•°æ®åº“å¯ä»¥è¯†åˆ«ä½ çš„å­¦ç”Ÿä¿¡æ¯çš„å­¦å¹´æœŸé™ã€‚æ­¤å¤–ï¼Œæ³¨å†Œä»¥åä¸€å®šè¦è¿›è¡Œå­¦ç”Ÿè®¤è¯ã€å®åè®¤è¯ã€‚ ç„¶åå»ä¹°åŸŸåï¼ŒåŸŸåçš„å½¢å¼æœ‰å¾ˆå¤šï¼ŒæŒ‰ç…§è‡ªå·±çš„éœ€æ±‚è¿›è¡Œè®¾ç½®åŸŸååç§°å’ŒåŸŸååç¼€ã€‚ï¼ˆå®åè®¤è¯æœ€å¿«æ˜¯ä¸¤å¤©çš„æ—¶é—´ï¼‰https://www.aliyun.com/* 17ã€åœ¨é˜¿é‡Œäº‘æ·»åŠ åŸŸåè§£æ cmd+pingä½ çš„http://github.ioåŸŸåï¼Œå¾—åˆ°ä¸€ä¸ªIP ä¿®æ”¹ä½ çš„åŸŸåè§£æè®°å½• æ·»åŠ ä¸¤ä¸ªAè®°å½•ï¼Œç”¨å¾—åˆ°çš„IPï¼Œä¸€ä¸ªä¸»æœºè®°å½•ä¸ºï¼šâ€œwwwâ€ï¼Œä¸€ä¸ªä¸ºâ€œ@â€ï¼Œ è¿™æ ·é€šè¿‡https://coomatrix.com/å°±èƒ½è®¿é—®åˆ°ä½ çš„åšå®¢äº† 18ã€å¡«å†™ç»‘å®šçš„åŸŸååœ¨ä½ çš„æœ¬åœ°æ–‡ä»¶ä¸‹ä¹Ÿå°±æ˜¯hexoâ€”&gt;ä½ çš„åšå®¢ï¼ˆæˆ‘çš„æ˜¯KangChouï¼‰æœ¬åœ°ç›®å½•ä¸‹æ‰¾åˆ° æ–‡ä»¶å¤¹source ï¼Œå¹¶åœ¨è¯¥æ–‡ä»¶ç›®å½•ä¸‹é¢æ–°å»ºä¸€ä¸ªæ–‡ä»¶CNAMEæ–‡ä»¶ï¼Œé‚£ä¹ˆä¸€å®šè¦æ³¨æ„åˆ›å»ºçš„CNAMEæ–‡ä»¶æ²¡æœ‰ä»»ä½•æ‰©å±•åï¼ˆåˆ‡è®°ï¼‰ å†ä¸€æ¬¡ä½¿ç”¨éƒ¨ç½²ä¸‰å‘½ä»¤hexo cleanhexo ghexo d****å®Œæˆä»¥åï¼Œè¿›å…¥Githubè®¾ç½®ï¼Œæ‰¾åˆ° Custom domainæ·»åŠ åŸŸååä¿å­˜å³å¯ 19ã€åˆ·æ–°ç½‘é¡µ+æ›´æ”¹åŸŸåæˆåŠŸ å¦‚æœä¸Šé¢çš„17æ²¡æœ‰å‡ºé”™çš„è¯ï¼Œé‚£ä¹ˆä½ å¡«å®ŒåŸŸåä¿å­˜ä»¥åä¼šå‡ºç°ä¸‹é¢çš„ç»“æœ é‚£ä¹ˆå°±æ˜¯æ›´æ”¹åŸŸåæˆåŠŸäº†ï¼Œæ­¤æ—¶ä½ åªéœ€è¦ç‚¹å‡»ä¸Šå›¾çš„åŸŸåå°±å¯ä»¥è®¿é—®å•¦ã€‚ â€¦â€¦åˆ°æ­¤å®Œæˆäº†æœ¬åšå®¢çš„æ­å»ºâ€¦â€¦ æŠ•ç¨¿â€”&gt;å±•ç¤ºä½ çš„æ‰å è¯·å‘é‚®ä»¶åˆ° &#107;&#97;&#x6e;&#x67;&#x73;&#105;&#110;&#x78;&#x40;&#x79;&#101;&#97;&#x68;&#x2e;&#110;&#101;&#116; æ ‡é¢˜æ³¨æ˜ã€æŠ•ç¨¿ã€‘ å‘Šè¯‰æˆ‘ä»¬ ä½ æ˜¯è°ï¼Œä»å“ªæ¥ï¼ŒæŠ•ä»€ä¹ˆ æˆ‘ä»¬ä¼šåŠæ—¶å›å¤ä½ ","raw":null,"content":null,"categories":[{"name":"æ•™ç¨‹å­¦ä¹ ","slug":"æ•™ç¨‹å­¦ä¹ ","permalink":"https://www.coomatrix.com/categories/%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"åšå®¢","slug":"åšå®¢","permalink":"https://www.coomatrix.com/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½è®ºæ–‡æ±‡é›†","slug":"papers","date":"2019-07-05T12:57:06.000Z","updated":"2022-11-20T14:48:38.090Z","comments":true,"path":"2019/07/05/papers/","link":"","permalink":"https://www.coomatrix.com/2019/07/05/papers/","excerpt":"","keywords":null,"text":"è®¡ç®—æœºç§‘å­¦æŠ€æœ¯ä¹¦ç±GOã€é»‘å®¢ã€Androidã€è®¡ç®—æœºåŸç†ã€äººå·¥æ™ºèƒ½ã€å¤§æ•°æ®ã€æœºå™¨å­¦ä¹ ã€æ•°æ®åº“ã€PHPã€javaã€æ¶æ„ã€æ¶ˆæ¯é˜Ÿåˆ—ã€ç®—æ³•ã€pythonã€çˆ¬è™«ã€æ“ä½œç³»ç»Ÿã€linuxã€Cè¯­è¨€ï¼š https://github.com/TIM168/technical_books è®¡ç®—æœºç§‘å­¦ï¼Œè½¯ä»¶æŠ€æœ¯ï¼Œåˆ›ä¸šï¼Œæ€æƒ³ç±»ï¼Œæ•°å­¦ç±»ï¼Œäººç‰©ä¼ è®°ä¹¦ç±ï¼šhttps://github.com/0voice/expert_readed_books å›½å†…å‡ æ‰€å¤§å­¦ä¸“ä¸šè¯¾ç¨‹èµ„æ–™æ•´ç†ï¼šhttps://github.com/lib-pku/libpku NLPè‡ªç„¶è¯­è¨€å¤„ç†èµ„æ–™æ±‡æ€»ï¼š ä¸­è‹±æ–‡æ•æ„Ÿè¯ã€è¯­è¨€æ£€æµ‹ã€ä¸­å¤–æ‰‹æœº/ç”µè¯å½’å±åœ°/è¿è¥å•†æŸ¥è¯¢ã€åå­—æ¨æ–­æ€§åˆ«ã€æ‰‹æœºå·æŠ½å–ã€èº«ä»½è¯æŠ½å–ã€é‚®ç®±æŠ½å–ã€ä¸­æ—¥æ–‡äººååº“ã€ä¸­æ–‡ç¼©å†™åº“ã€æ‹†å­—è¯å…¸ã€è¯æ±‡æƒ…æ„Ÿå€¼ã€åœç”¨è¯ã€ååŠ¨è¯è¡¨ã€æš´æè¯è¡¨ã€ç¹ç®€ä½“è½¬æ¢ã€è‹±æ–‡æ¨¡æ‹Ÿä¸­æ–‡å‘éŸ³ã€æ±ªå³°æ­Œè¯ç”Ÿæˆå™¨ã€èŒä¸šåç§°è¯åº“ã€åŒä¹‰è¯åº“ã€åä¹‰è¯åº“ã€å¦å®šè¯åº“ã€æ±½è½¦å“ç‰Œè¯åº“ã€æ±½è½¦é›¶ä»¶è¯åº“ã€è¿ç»­è‹±æ–‡åˆ‡å‰²ã€å„ç§ä¸­æ–‡è¯å‘é‡ã€å…¬å¸åå­—å¤§å…¨ã€å¤è¯—è¯åº“ã€ITè¯åº“ã€è´¢ç»è¯åº“ã€æˆè¯­è¯åº“ã€åœ°åè¯åº“ã€å†å²åäººè¯åº“ã€è¯—è¯è¯åº“ã€åŒ»å­¦è¯åº“ã€é¥®é£Ÿè¯åº“ã€æ³•å¾‹è¯åº“ã€æ±½è½¦è¯åº“ã€åŠ¨ç‰©è¯åº“ã€ä¸­æ–‡èŠå¤©è¯­æ–™ã€ä¸­æ–‡è°£è¨€æ•°æ®ã€ç™¾åº¦ä¸­æ–‡é—®ç­”æ•°æ®é›†ã€å¥å­ç›¸ä¼¼åº¦åŒ¹é…ç®—æ³•é›†åˆã€bertèµ„æºã€æ–‡æœ¬ç”Ÿæˆ&amp;æ‘˜è¦ç›¸å…³å·¥å…·ã€cocoNLPä¿¡æ¯æŠ½å–å·¥å…·ã€å›½å†…ç”µè¯å·ç æ­£åˆ™åŒ¹é…ã€æ¸…åå¤§å­¦XLORE:ä¸­è‹±æ–‡è·¨è¯­è¨€ç™¾ç§‘çŸ¥è¯†å›¾è°±ã€æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼š https://github.com/fighting41love/funNLP AIä¹¦ç±ä¸ç®—æ³•æºç ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ :https://nndl.github.io/ ç»Ÿè®¡å­¦æ–¹æ³•ï¼šhttps://github.com/SmirkCao/Lihang ç»Ÿè®¡å­¦æ–¹æ³•ä¹ é¢˜ç­”æ¡ˆ:https://datawhalechina.github.io/statistical-learning-method-solutions-manual/#/ https://github.com/SuperCV/Book æœºå™¨å­¦ä¹ ï¼š https://github.com/MorvanZhou/tutorials https://github.com/lawlite19/MachineLearning_Python è¥¿ç“œä¹¦ https://github.com/datawhalechina/pumpkin-book æœºå™¨è§†è§‰:https://github.com/Ewenwan/MVision è§†è§‰ç®—æ³•æ’å:https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark æœºå™¨å­¦ä¹ èµ„æºå¤§å…¨ä¸­æ–‡ç‰ˆ:https://github.com/jobbole/awesome-machine-learning-cn æœºå™¨æ•°å­¦ä¸ä»£ç å®ç°:https://ailearning.apachecn.org/#/ https://github.com/fengdu78/lihang-code https://github.com/Dod-o/Statistical-Learning-Method_Code https://github.com/WenDesi/lihang_book_algorithm https://github.com/zslucky/awesome-AI-books https://github.com/dsgiitr/d2l-pytorch https://github.com/1033020837/Basic4AI https://github.com/xmj-ai/deeplearning_ai_books https://github.com/lllhhh/BooksKeeper https://github.com/cosen1024/awesome-cs-books https://github.com/wugenqiang/NoteBook https://github.com/bat67/awesome-ai-books-and-code https://github.com/china-testing/python-api-tesing https://github.com/iamshuaidi/CS-Book https://github.com/itdevbooks/pdf https://github.com/getsources/CS-Growing-book https://github.com/861664308/Tensorflow-Keras-- https://github.com/jlgulu/PythonAIPath-Geek https://github.com/zhangziliang04/aipm https://github.com/Baiyuetribe/paper2gui https://github.com/Robinwho/Deep-Learning æ„å»ºå¼€æºå¯¹è¯æœºå™¨äºº:https://github.com/Chinese-NLP-book/rasa_chinese_book_code http://lnbook.wenqujingdian.com/Public/editor/attached/file/3/018/017/18581.pdf http://home.ustc.edu.cn/~yang96/Elements_of_Information_Theory-second_edition.pdf ã€ŠNavin Sabharwal - Hands-on Question Answering Systems with BERT_ Applications in Neural Networks and Natural Language Processing-Apress (2021)ã€‹ ã€ŠSudharsan Ravichandiran - Getting Started with Google BERT_ Build and train state-of-the-art natural language processing models using BERT-Packt Publishing Ltd (2021)ã€‹ https://github.com/datawhalechina/statistical-learning-method-solutions-manual https://github.com/fengdu78/deeplearning_ai_books https://github.com/Microstrong0305/Python2AI https://github.com/chatopera/Synonyms https://github.com/cj0012/AI-Practice-Tensorflow-Notes https://github.com/YeonwooSung/ai_book https://github.com/jikexueyuanwiki/tensorflow-zh https://github.com/JDHHH/AI-Books https://github.com/lihanghang/Deep-learning-And-Paper https://github.com/koryako/FundamentalsOfAI_book_code https://github.com/zhangbincheng1997/chatbot-aiml-webqa https://github.com/qqqil/books https://github.com/KeKe-Li/books https://github.com/KeKe-Li/tutorial https://github.com/search?q=%E7%BB%9F%E8%AE%A1%E5%AD%A6%E6%96%B9%E6%B3%95 https://github.com/Dujltqzv/Some-Many-Books è®¡ç®—æœºè§†è§‰å®æ—¶åŠ¨æ€https://openaccess.thecvf.com/menu 3D å¯¹è±¡æ£€æµ‹ å‚è€ƒæ¥è‡ªï¼š https://github.com/Tom-Hardy-3D-Vision-Workshop/awesome-3D-object-detection https://github.com/TianhaoFu/Awesome-3D-Object-Detection æ•°æ®é›† KITTI æ•°æ®é›† 3,712 ä¸ªè®­ç»ƒæ ·æœ¬ 3,769 ä¸ªéªŒè¯æ ·æœ¬ 7,518ä¸ªæµ‹è¯•æ ·æœ¬ nuScenes æ•°æ®é›† 28k è®­ç»ƒæ ·æœ¬ 6k éªŒè¯æ ·æœ¬ 6k æµ‹è¯•æ ·æœ¬ Lyft æ•°æ®é›† Waymo å¼€æ”¾æ•°æ®é›† 798 ä¸ªè®­ç»ƒåºåˆ—ï¼Œå¤§çº¦ 158ã€361 ä¸ª LiDAR æ ·æœ¬ 202 ä¸ªéªŒè¯åºåˆ—ï¼ŒåŒ…å« 40ã€077 ä¸ª LiDAR æ ·æœ¬ã€‚ é¡¶çº§ä¼šè®®å’Œç ”è®¨ä¼šä¼šè®® è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®ï¼ˆCVPRï¼‰ è®¡ç®—æœºè§†è§‰å›½é™…ä¼šè®®ï¼ˆICCVï¼‰ æ¬§æ´²è®¡ç®—æœºè§†è§‰ä¼šè®®ï¼ˆECCVï¼‰ ä½œåŠ CVPR 2019 è‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼šï¼ˆnuScenes 3D detectionï¼‰ CVPR 2020 è‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼šï¼ˆBDD1k 3D trackingï¼‰ CVPR 2021 è‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼šï¼ˆwaymo 3Dæ£€æµ‹ï¼‰ CVPR 2022 è‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼šï¼ˆwaymo 3Dæ£€æµ‹ï¼‰ CVPR 2021 3D è§†è§‰å’Œæœºå™¨äººç ”è®¨ä¼š CVPR 2021 è§†è§‰ã€å›¾å½¢å’Œæœºå™¨äºº 3D åœºæ™¯ç†è§£ç ”è®¨ä¼š ICCV 2019 è‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼š ICCV 2021 è‡ªåŠ¨é©¾é©¶æ±½è½¦è§†è§‰ç ”è®¨ä¼šï¼ˆAVVisionï¼‰ï¼Œæ³¨ ICCV 2021 ç ”è®¨ä¼š SSLAD Track 2â€“3D å¯¹è±¡æ£€æµ‹ ECCV 2020 è‡ªåŠ¨é©¾é©¶æ±½è½¦æŒ‡ä»¤ç ”è®¨ä¼š ECCV 2020 è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç ”è®¨ä¼š è®ºæ–‡ï¼ˆåŸºäºæ¿€å…‰é›·è¾¾çš„æ–¹æ³•ï¼‰ ç”¨äº LiDAR ç‚¹äº‘ä¸­ 3D å¯¹è±¡æ£€æµ‹çš„ç«¯åˆ°ç«¯å¤šè§†å›¾èåˆè®ºæ–‡ ä½¿ç”¨å…¨å·ç§¯ç½‘ç»œï¼ˆç™¾åº¦ï¼‰è®ºæ–‡ä» 3D æ¿€å…‰é›·è¾¾è¿›è¡Œè½¦è¾†æ£€æµ‹ VoxelNetï¼šåŸºäºç‚¹äº‘çš„ 3D å¯¹è±¡æ£€æµ‹è®ºæ–‡çš„ç«¯åˆ°ç«¯å­¦ä¹  ä½¿ç”¨æ·±åº¦å·ç§¯ç½‘ç»œè®ºæ–‡åœ¨å ç”¨ç½‘æ ¼åœ°å›¾ä¸­è¿›è¡Œå¯¹è±¡æ£€æµ‹å’Œåˆ†ç±» RT3Dï¼šç”¨äºè‡ªåŠ¨é©¾é©¶çš„ LiDAR ç‚¹äº‘ä¸­çš„å®æ—¶ 3-D è½¦è¾†æ£€æµ‹è®ºæ–‡ BirdNetï¼šæ¥è‡ª LiDAR ä¿¡æ¯è®ºæ–‡çš„ 3D å¯¹è±¡æ£€æµ‹æ¡†æ¶ LMNetï¼šä½¿ç”¨ 3D LiDARè®ºæ–‡åœ¨ CPU ä¸Šè¿›è¡Œå®æ—¶å¤šç±»ç›®æ ‡æ£€æµ‹ HDNET: Exploit HD Maps for 3D Object Detectionè®ºæ–‡ PointNetï¼šç”¨äº 3D åˆ†ç±»å’Œåˆ†å‰²çš„ç‚¹é›†çš„æ·±åº¦å­¦ä¹ è®ºæ–‡ PointNet++ï¼šåº¦é‡ç©ºé—´ä¸­ç‚¹é›†çš„æ·±åº¦åˆ†å±‚ç‰¹å¾å­¦ä¹ è®ºæ–‡ IPOD: Intensive Point-based Object Detector for Point Cloudè®ºæ–‡ PIXORï¼šæ¥è‡ªç‚¹äº‘çš„å®æ—¶ 3D å¯¹è±¡æ£€æµ‹è®ºæ–‡ DepthCNï¼šè½¦è¾†æ£€æµ‹ä½¿ç”¨ 3D-LIDAR å’Œ ConvNetè®ºæ–‡ Voxel-FPNï¼šç‚¹äº‘ 3D å¯¹è±¡æ£€æµ‹ä¸­çš„å¤šå°ºåº¦ä½“ç´ ç‰¹å¾èšåˆè®ºæ–‡ STDï¼šç‚¹äº‘çº¸çš„ç¨€ç–åˆ°å¯†é›† 3D å¯¹è±¡æ£€æµ‹å™¨ å¿«é€Ÿç‚¹ R-CNNè®ºæ–‡ StarNetï¼šç‚¹äº‘ä¸­ç›®æ ‡æ£€æµ‹çš„ç›®æ ‡è®¡ç®—è®ºæ–‡ ç‚¹äº‘ 3D å¯¹è±¡æ£€æµ‹è®ºæ–‡çš„ç±»å¹³è¡¡åˆ†ç»„å’Œé‡‡æ · LaserNetï¼šä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶è®ºæ–‡çš„é«˜æ•ˆæ¦‚ç‡ 3D å¯¹è±¡æ£€æµ‹å™¨ FVNetï¼š3D Front-View Proposal Generation for Real-Time Object Detection from Point Cloudsè®ºæ–‡ Part-AÂ² Netï¼š3D Part-Aware and Aggregation Neural Network for Object Detection from Point Cloudè®ºæ–‡ PointRCNNï¼š3D Object Proposal Generation and Detection from Point Cloudè®ºæ–‡ Complex-YOLOï¼šç‚¹äº‘ä¸Šçš„å®æ—¶ 3D å¯¹è±¡æ£€æµ‹è®ºæ–‡ YOLO4D: A ST Approach for RT Multi-object Detection and Classification from LiDAR Point Cloudsè®ºæ–‡ YOLO3Dï¼šæ¥è‡ª LiDAR ç‚¹äº‘è®ºæ–‡çš„ç«¯åˆ°ç«¯å®æ—¶ 3D é¢å‘å¯¹è±¡è¾¹ç•Œæ¡†æ£€æµ‹ ä½¿ç”¨ Pseudo-LiDAR ç‚¹äº‘è®ºæ–‡è¿›è¡Œå•ç›® 3D å¯¹è±¡æ£€æµ‹ Structure Aware Single-stage 3D Object Detection from Point Cloudï¼ˆCVPR2020ï¼‰è®ºæ–‡ ä»£ç  MLCVNet: Multi-Level Context VoteNet for 3D Object Detectionï¼ˆCVPR2020ï¼‰è®ºæ–‡ ä»£ç  3DSSD: Point-based 3D Single Stage Object Detectorï¼ˆCVPR2020ï¼‰è®ºæ–‡ ä»£ç  LiDAR-based Online 3D Video Object Detection with Graph-based Message Passing and Spatiotemporal Transformer Attentionï¼ˆCVPR2020ï¼‰è®ºæ–‡ ä»£ç  PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection(CVPR2020)è®ºæ–‡ ä»£ç  Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloudï¼ˆCVPR2020ï¼‰è®ºæ–‡ ä»£ç  MLCVNet: Multi-Level Context VoteNet for 3D Object Detectionï¼ˆCVPR2020ï¼‰è®ºæ–‡ Density Based Clustering for 3D Object Detection in Point Cloudsï¼ˆCVPR2020ï¼‰è®ºæ–‡ æ‰€è§å³æ‰€å¾—ï¼šExploiting Visibility for 3D Object Detectionï¼ˆCVPR2020ï¼‰è®ºæ–‡ PointPainting: Sequential Fusion for 3D Object Detection (CVPR2020)è®ºæ–‡ HVNet: Hybrid Voxel Network for LiDAR Based 3D Object Detectionï¼ˆCVPR2020ï¼‰è®ºæ–‡ LiDAR R-CNN: An Efficient and Universal 3D Object Detectorï¼ˆCVPR2021ï¼‰è®ºæ–‡ Center-based 3D Object Detection and Tracking (CVPR2021)è®ºæ–‡ 3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection (CVPR2021)è®ºæ–‡ Embracing Single Stride 3D Object Detector with Sparse Transformerï¼ˆCVPR2022ï¼‰è®ºæ–‡ï¼Œä»£ç  Point Density-Aware Voxels for LiDAR 3D Object Detection (CVPR2022)è®ºæ–‡ï¼Œä»£ç  A Unified Query-based Paradigm for Point Cloud Understanding (CVPR2022)è®ºæ–‡ Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds (CVPR2022)è®ºæ–‡ï¼Œä»£ç  å¹¶éæ‰€æœ‰çš„ç‚¹éƒ½æ˜¯å¹³ç­‰çš„ï¼šLearning High Efficient Point-based Detectors for 3D LiDAR Point Clouds (CVPR2022)è®ºæ–‡ï¼Œä»£ç  å›åˆ°ç°å®ï¼šWeakly-supervised 3D Object Detection with Shape-guided Label Enhancementï¼ˆCVPR2022ï¼‰è®ºæ–‡ï¼Œä»£ç  Voxel Set Transformer: A Set-to-Set Approach to 3D Object Detection from Point Clouds (CVPR2022)è®ºæ–‡ï¼Œä»£ç  BoxeR: Box-Attention for 2D and 3D Transformers(CVPR2022)è®ºæ–‡,ä»£ç ,ä¸­æ–‡ä»‹ç» è§„èŒƒæŠ•ç¥¨ï¼šTowards Robust Oriented Bounding Box Detection in 3D Scenes (CVPR2022)è®ºæ–‡ï¼Œä»£ç  DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection(CVPR2022)è®ºæ–‡ï¼Œä»£ç  TransFusionï¼šä½¿ç”¨ Transformers è¿›è¡Œ 3D å¯¹è±¡æ£€æµ‹çš„ç¨³å¥ LiDAR-Camera Fusionã€‚(CVPR2022)è®ºæ–‡ï¼Œä»£ç  Point2Seqï¼šå°† 3D å¯¹è±¡æ£€æµ‹ä¸ºåºåˆ—ã€‚(CVPR2022)è®ºæ–‡ï¼Œä»£ç  CAT-Detï¼šç”¨äºå¤šæ¨¡æ€ 3D å¯¹è±¡æ£€æµ‹çš„å¯¹æ¯”å¢å¼ºå˜å‹å™¨ï¼ˆCVPR2022ï¼‰è®ºæ–‡ LiDAR Snowfall Simulation for Robust 3D Object Detection (CVPR2022)è®ºæ–‡ï¼Œä»£ç  Unified Transformer Tracker for Object Tracking (CVPR2022)è®ºæ–‡ï¼Œä»£ç  Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion (CVPR2022)è®ºæ–‡ Unified Transformer Tracker for Object Tracking (CVPR2022)è®ºæ–‡ï¼Œä»£ç  ç«èµ›è§£å†³æ–¹æ¡ˆå·¥ç¨‹è°ƒæŸ¥ 2021.04 ç”¨äºè‡ªåŠ¨é©¾é©¶åº”ç”¨çš„åŸºäºç‚¹äº‘çš„ 3D å¯¹è±¡æ£€æµ‹å’Œåˆ†ç±»æ–¹æ³•ï¼šè°ƒæŸ¥å’Œåˆ†ç±»è®ºæ–‡ 2021.07 ç”¨äºè‡ªåŠ¨é©¾é©¶çš„ 3D å¯¹è±¡æ£€æµ‹ï¼šè°ƒæŸ¥è®ºæ–‡ 2021.07 è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šæ¨¡æ€ 3D å¯¹è±¡æ£€æµ‹ï¼šè°ƒæŸ¥è®ºæ–‡ 2021.10 åŸºäºæ¿€å…‰é›·è¾¾çš„ 3D ç‰©ä½“æ£€æµ‹æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨é©¾é©¶è®ºæ–‡ç»¼åˆè°ƒæŸ¥ 2021.12 3D ç‚¹äº‘çš„æ·±åº¦å­¦ä¹ ï¼šè°ƒæŸ¥è®ºæ–‡ ä¹¦ åŸºäºæ¿€å…‰é›·è¾¾å’Œæ‘„åƒå¤´çš„ 3D å¯¹è±¡æ£€æµ‹ç®—æ³•ï¼šè®¾è®¡ä¸ä»¿çœŸä¹¦ è§†é¢‘ Aivia åœ¨çº¿ç ”è®¨ä¼šï¼š3D å¯¹è±¡æ£€æµ‹å’Œè·Ÿè¸ªè§†é¢‘ 3D å¯¹è±¡æ£€ç´¢ 2021 ç ”è®¨ä¼šè§†é¢‘ æ¥è‡ª UCSDè§†é¢‘çš„ SU å®éªŒå®¤çš„ 3D æ·±åº¦å­¦ä¹ æ•™ç¨‹ è®²åº§ï¼šè‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆå›¾å®¾æ ¹å¤§å­¦ Andreas Geiger æ•™æˆï¼‰è§†é¢‘ ç‚¹äº‘å¯¹è±¡çš„å½“å‰æ–¹æ³•å’Œæœªæ¥æ–¹å‘ (2021.04)è§†é¢‘ CPU ä¸Š 30+ FPS çš„æœ€æ–° 3D å¯¹è±¡æ£€æµ‹ â€” MediaPipe å’Œ OpenCV Python (2021.05)è§†é¢‘ MITè‡ªåŠ¨é©¾é©¶ç ”è®¨ä¼šï¼ˆ2019.11ï¼‰è§†é¢‘ sensetime ç ”è®¨ä¼š1è§†é¢‘ sensetime ç ”è®¨ä¼š 2å¼ å¹»ç¯ç‰‡ è¯¾ç¨‹ å¤šä¼¦å¤šå¤§å­¦ï¼Œcsc2541 å›¾å®¾æ ¹å¤§å­¦ï¼Œè‡ªåŠ¨é©¾é©¶æ±½è½¦ ï¼ˆå¼ºçƒˆæ¨èï¼‰ ç™¾åº¦-Udacity ç™¾åº¦-é˜¿æ³¢ç½— å¤šä¼¦å¤šå¤§å­¦ï¼Œè¯¾ç¨‹ åšå®¢ Waymo åšå®¢ apolloä»‹ç»ä¹‹æ„ŸçŸ¥æ¨¡å— Apollo ç¬”è®°ï¼ˆApollo å­¦ä¹ ç¬”è®°ï¼‰â€” Apollo åˆå­¦è€…å­¦ä¹ ç¬”è®°ã€‚ PointNetç³»åˆ—è®ºæ–‡è§£è¯» Deep3dBoxï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ å’Œå‡ ä½•è¿›è¡Œ 3D è¾¹ç•Œæ¡†ä¼°è®¡ SECONDç®—æ³•è§£æ PointRCNNæ·±åº¦è§£æ Fast PointRCNNè®ºæ–‡è§£è¯» PointPillarsè®ºæ–‡å’Œä»£ç è§£æ VoxelNetè®ºæ–‡å’Œä»£ç è§£æ CenterPointåˆ†æ PV-RCNNï¼š3Dç›®æ ‡æ£€æµ‹Waymoæ¨¡æ€æŒ‘æˆ˜èµ›+KITTIæ¦œå•æ¨¡æ€ç¬¬ä¸€æ¨¡æŒ‘æˆ˜èµ› LiDAR R-CNNï¼šä¸€ç§å¿«é€Ÿã€é€šç”¨çš„äºŒç±»3Dæ£€æµ‹å™¨ æ··åˆä½“ç´ ç½‘ç»œï¼ˆHVNetï¼‰ è‡ªåŠ¨é©¾é©¶æ±½è½¦| èŒƒå›´å›¾åƒçº¸åˆ†äº« SSTï¼šå•æ­¥æ”¾å¤§è£…ç½®Transformer 3Dæ¢æµ‹ä»ª è‘—åç ”ç©¶ç»„&#x2F;å­¦è€… ç‹ä¹ƒç‡•@Tusimple ææ´ªç”Ÿ@CUHK ä¸€æ¬¡ Tuzel@Apple å¥¥æ–¯å¡Beijbom@nuTonomy Raquel Urtasun@å¤šä¼¦å¤šå¤§å­¦ Philipp KrÃ¤henbÃ¼hl@UT Austin å¾·ç“¦æ‹‰é©¬å—@CMU è´¾å®¶äºš@CUHK Thomas Funkhouser@princeton åˆ—å¥¥å°¼è¾¾æ–¯Â·å‰å·´æ–¯@æ–¯å¦ç¦ å²è’‚æ–‡Â·ç“¦æ–¯å…°å¾·@å¤šä¼¦å¤šå¤§å­¦ Ouais Alsharif@Google å¤§è„‘ æŸ´è‚²å®ï¼ˆå‰ï¼‰@waymo éƒ­ç‰å…°@NUDT å¼ ç£Š@é¦™æ¸¯ç†å·¥å¤§å­¦ ææ´ªæ´‹@sensetime è‘—åçš„ä»£ç åº“ ç‚¹äº‘åº“ (PCL) Spconv Det3D æ¯«ç±³æ£€æµ‹3d å¼€æ”¾PCDet ä¸­å¿ƒç‚¹ Apollo Autoâ€”â€”ç™¾åº¦å¼€æ”¾è‡ªåŠ¨é©¾é©¶å¹³å° AutoWareâ€”â€”ä¸œäº¬å¤§å­¦è‡ªåŠ¨é©¾é©¶å¹³å° Openpilot â€” ä¸€ç§å¼€æºè½¯ä»¶ï¼Œæ—¨åœ¨æ”¹è¿›å½“ä»Šé“è·¯ä¸Šå¤§å¤šæ•°æ–°è½¦çš„ç°æœ‰é©¾é©¶å‘˜è¾…åŠ© æ·±åº¦å­¦ä¹ ç‚¹äº‘å‚è€ƒè®ºæ–‡æ¥æº - Recent papers (from 2017) Keywords dat.: dataset &amp;emsp; | &amp;emsp; cls.: classification &amp;emsp; | &amp;emsp; rel.: retrieval &amp;emsp; | &amp;emsp; seg.: segmentationdet.: detection &amp;emsp; | &amp;emsp; tra.: tracking &amp;emsp; | &amp;emsp; pos.: pose &amp;emsp; | &amp;emsp; dep.: depthreg.: registration &amp;emsp; | &amp;emsp; rec.: reconstruction &amp;emsp; | &amp;emsp; aut.: autonomous drivingoth.: other, including normal-related, correspondence, mapping, matching, alignment, compression, generative modelâ€¦ Statistics: ğŸ”¥ code is available &amp; stars &gt;&#x3D; 100 &amp;emsp;|&amp;emsp; â­ï¸ citation &gt;&#x3D; 50 2017 [CVPR] PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. [tensorflow][pytorch] [cls. seg. det.] ğŸ”¥ â­ï¸ [CVPR] Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs. [cls.] â­ï¸ [CVPR] SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation. [torch] [seg. oth.] â­ï¸ [CVPR] ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes. [project][git] [dat. cls. rel. seg. oth.] ğŸ”¥ â­ï¸ [CVPR] Scalable Surface Reconstruction from Point Clouds with Extreme Scale and Density Diversity. [oth.] [CVPR] Efficient Global Point Cloud Alignment using Bayesian Nonparametric Mixtures. [code] [oth.] [CVPR] Discriminative Optimization: Theory and Applications to Point Cloud Registration. [reg.] [CVPR] 3D Point Cloud Registration for Localization using a Deep Neural Network Auto-Encoder. [git] [reg.] [CVPR] Multi-View 3D Object Detection Network for Autonomous Driving. [tensorflow] [det. aut.] ğŸ”¥ â­ï¸ [CVPR] 3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions. [code] [dat. pos. reg. rec. oth.] ğŸ”¥ â­ï¸ [CVPR] OctNet: Learning Deep 3D Representations at High Resolutions. [torch] [cls. seg. oth.] ğŸ”¥ â­ï¸ [ICCV] Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models. [pytorch] [cls. rel. seg.] â­ï¸ [ICCV] 3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds. [code] [seg.] [ICCV] Colored Point Cloud Registration Revisited. [reg.] [ICCV] PolyFit: Polygonal Surface Reconstruction from Point Clouds. [code] [rec.] ğŸ”¥ [ICCV] From Point Clouds to Mesh using Regression. [rec.] [ICCV] 3D Graph Neural Networks for RGBD Semantic Segmentation. [pytorch] [seg.] [NeurIPS] PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space. [tensorflow][pytorch] [cls. seg.] ğŸ”¥ â­ï¸ [NeurIPS] Deep Sets. [pytorch] [cls.] â­ï¸ [ICRA] Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks. [code] [det. aut.] â­ï¸ [ICRA] Fast segmentation of 3D point clouds: A paradigm on LiDAR data for autonomous vehicle applications. [code] [seg. aut.] [ICRA] SegMatch: Segment based place recognition in 3D point clouds. [seg. oth.] [ICRA] Using 2 point+normal sets for fast registration of point clouds with small overlap. [reg.] [IROS] Car detection for autonomous vehicle: LIDAR and vision fusion approach through deep learning framework. [det. aut.] [IROS] 3D object classification with point convolution network. [cls.] [IROS] 3D fully convolutional network for vehicle detection in point cloud. [tensorflow] [det. aut.] ğŸ”¥ â­ï¸ [IROS] Deep learning of directional truncated signed distance function for robust 3D object recognition. [det. pos.] [IROS] Analyzing the quality of matched 3D point clouds of objects. [oth.] [3DV] SEGCloud: Semantic Segmentation of 3D Point Clouds. [project] [seg. aut.] â­ï¸ [TPAMI] Structure-aware Data Consolidation. [oth.] 2018 [CVPR] SPLATNet: Sparse Lattice Networks for Point Cloud Processing. [caffe] [seg.] ğŸ”¥ [CVPR] Attentional ShapeContextNet for Point Cloud Recognition. [cls. seg.] [CVPR] Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling. [code] [cls. seg.] [CVPR] FoldingNet: Point Cloud Auto-encoder via Deep Grid Deformation. [code] [cls.] [CVPR] Pointwise Convolutional Neural Networks. [tensorflow] [cls. seg.] [CVPR] PU-Net: Point Cloud Upsampling Network. [tensorflow] [rec. oth.] ğŸ”¥ [CVPR] SO-Net: Self-Organizing Network for Point Cloud Analysis. [pytorch] [cls. seg.] ğŸ”¥ â­ï¸ [CVPR] Recurrent Slice Networks for 3D Segmentation of Point Clouds. [pytorch] [seg.] [CVPR] 3D Semantic Segmentation with Submanifold Sparse Convolutional Networks. [pytorch] [seg.] ğŸ”¥ [CVPR] Deep Parametric Continuous Convolutional Neural Networks. [seg. aut.] [CVPR] PIXOR: Real-time 3D Object Detection from Point Clouds. [pytorch] [det. aut.] [CVPR] SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation. [tensorflow] [seg.] ğŸ”¥ [CVPR] Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs. [pytorch] [seg.] ğŸ”¥ [CVPR] VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. [tensorflow] [det. aut.] ğŸ”¥ â­ï¸ [CVPR] Reflection Removal for Large-Scale 3D Point Clouds. [oth.] [CVPR] Hand PointNet: 3D Hand Pose Estimation using Point Sets. [pytorch] [pos.] [CVPR] PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition. [tensorflow] [rel.] ğŸ”¥ [CVPR] A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation. [cls.] [CVPR] Density Adaptive Point Set Registration. [code] [reg.] [CVPR] A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds. [seg.] [CVPR] Inverse Composition Discriminative Optimization for Point Cloud Registration. [reg.] [CVPR] CarFusion: Combining Point Tracking and Part Detection for Dynamic 3D Reconstruction of Vehicles. [tra. det. rec.] [CVPR] PPFNet: Global Context Aware Local Features for Robust 3D Point Matching. [oth.] [CVPR] PointGrid: A Deep Network for 3D Shape Understanding. [tensorflow] [cls. seg.] [CVPR] PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation. [code] [det. aut.] [CVPR] Frustum PointNets for 3D Object Detection from RGB-D Data. [tensorflow] [det. aut.] ğŸ”¥ â­ï¸ [CVPR] Tangent Convolutions for Dense Prediction in 3D. [tensorflow] [seg. aut.] [ECCV] Multiresolution Tree Networks for 3D Point Cloud Processing. [pytorch] [cls.] [ECCV] EC-Net: an Edge-aware Point set Consolidation Network. [tensorflow] [oth.] [ECCV] 3D Recurrent Neural Networks with Context Fusion for Point Cloud Semantic Segmentation. [seg.] [ECCV] Learning and Matching Multi-View Descriptors for Registration of Point Clouds. [reg.] [ECCV] 3DFeat-Net: Weakly Supervised Local 3D Features for Point Cloud Registration. [tensorflow] [reg.] [ECCV] Local Spectral Graph Convolution for Point Set Feature Learning. [tensorflow] [cls. seg.] [ECCV] SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters. [tensorflow] [cls. seg.] [ECCV] Efficient Global Point Cloud Registration by Matching Rotation Invariant Features Through Translation Search. [reg.] [ECCV] Efficient Dense Point Cloud Object Reconstruction using Deformation Vector Fields. [rec.] [ECCV] Fully-Convolutional Point Networks for Large-Scale Point Clouds. [tensorflow] [seg. oth.] [ECCV] Deep Continuous Fusion for Multi-Sensor 3D Object Detection. [det.] [ECCV] HGMR: Hierarchical Gaussian Mixtures for Adaptive 3D Registration. [reg.] [ECCV] Point-to-Point Regression PointNet for 3D Hand Pose Estimation. [pos.] [ECCV] PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors. [oth.] [ECCVW] 3DContextNet: K-d Tree Guided Hierarchical Learning of Point Clouds Using Local and Global Contextual Cues. [cls. seg.] [ECCVW] YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud. [det. aut.] [AAAI] Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction. [tensorflow] [rec.] ğŸ”¥ [AAAI] Adaptive Graph Convolutional Neural Networks. [cls.] [NeurIPS] Unsupervised Learning of Shape and Pose with Differentiable Point Clouds. [tensorflow] [pos.] [NeurIPS] PointCNN: Convolution On X-Transformed Points. [tensorflow][pytorch] [cls. seg.] ğŸ”¥ [ICML] Learning Representations and Generative Models for 3D Point Clouds. [code] [oth.] ğŸ”¥ [TOG] Point Convolutional Neural Networks by Extension Operators. [tensorflow] [cls. seg.] [SIGGRAPH] P2P-NET: Bidirectional Point Displacement Net for Shape Transform. [tensorflow] [oth.] [SIGGRAPH Asia] Monte Carlo Convolution for Learning on Non-Uniformly Sampled Point Clouds. [tensorflow] [cls. seg. oth.] [SIGGRAPH] Learning local shape descriptors from part correspondences with multi-view convolutional networks. [project] [seg. oth.] [MM] PVNet: A Joint Convolutional Network of Point Cloud and Multi-View for 3D Shape Recognition. [cls. rel.] [MM] RGCNN: Regularized Graph CNN for Point Cloud Segmentation. [tensorflow] [seg.] [MM] Hybrid Point Cloud Attribute Compression Using Slice-based Layered Structure and Block-based Intra Prediction. [oth.] [ICRA] End-to-end Learning of Multi-sensor 3D Tracking by Detection. [det. tra. aut.] [ICRA] Multi-View 3D Entangled Forest for Semantic Segmentation and Mapping. [seg. oth.] [ICRA] SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud. [tensorflow] [seg. aut.] [ICRA] Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications. [det.] [ICRA] High-Precision Depth Estimation with the 3D LiDAR and Stereo Fusion. [dep. aut.] [ICRA] Sampled-Point Network for Classification of Deformed Building Element Point Clouds. [cls.] [ICRA] Gemsketch: Interactive Image-Guided Geometry Extraction from Point Clouds. [oth.] [ICRA] Signature of Topologically Persistent Points for 3D Point Cloud Description. [oth.] [ICRA] A General Pipeline for 3D Detection of Vehicles. [det. aut.] [ICRA] Robust and Fast 3D Scan Alignment Using Mutual Information. [oth.] [ICRA] Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities. [oth.] [ICRA] Surface-Based Exploration for Autonomous 3D Modeling. [oth. aut.] [ICRA] Deep Lidar CNN to Understand the Dynamics of Moving Vehicles. [oth. aut.] [ICRA] Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning. [oth.] [ICRA] Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation. [tra.] [ICRA] Robust Generalized Point Cloud Registration Using Hybrid Mixture Model. [reg.] [ICRA] A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration. [reg.] [ICRA] Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping. [oth.] [ICRA] Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System. [oth.] [ICRA] Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data. [cls.] [ICRA] Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization. [oth.] [ICRA] Complex Urban LiDAR Data Set. [video] [dat. oth.] [IROS] CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial Transformer Networks.[tensorflow] [oth. aut.] [IROS] Dynamic Scaling Factors of Covariances for Accurate 3D Normal Distributions Transform Registration. [reg.] [IROS] A 3D Laparoscopic Imaging System Based on Stereo-Photogrammetry with Random Patterns. [rec. oth.] [IROS] Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties. [reg.] [IROS] Octree map based on sparse point cloud and heuristic probability distribution for labeled images. [oth. aut.] [IROS] PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization. [oth.] [IROS] Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map. [oth.] [IROS] LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain.[code] [pos. oth.] ğŸ”¥ [IROS] Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds. [cls.] [IROS] Stereo Camera Localization in 3D LiDAR Maps. [pos. oth.] [IROS] Joint 3D Proposal Generation and Object Detection from View Aggregation. [det.] â­ï¸ [IROS] Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality. [oth.] [IROS] Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding. [det. oth.] [IROS] NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor. [code][oth.] [IROS] A 3D Convolutional Neural Network Towards Real-Time Amodal 3D Object Detection. [det. pos.] [IROS] Extracting Phenotypic Characteristics of Corn Crops Through the Use of Reconstructed 3D Models. [seg. rec.] [IROS] PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap. [reg.] [IROS] [Tensorflow]3DmFV: Point Cloud Classification and segmentation for unstructured 3D point clouds. [cls. ] [IROS] Seeing the Wood for the Trees: Reliable Localization in Urban and Natural Environments. [oth. ] [SENSORS] SECOND: Sparsely Embedded Convolutional Detection. [pytorch] [det. aut.] ğŸ”¥ [ACCV] Flex-Convolution (Million-Scale Point-Cloud Learning Beyond Grid-Worlds). [tensorflow] [seg.] [3DV] PCN: Point Completion Network. [tensorflow] [reg. oth. aut.] ğŸ”¥ [ICASSP] A Graph-CNN for 3D Point Cloud Classification. [tensorflow] [cls.] ğŸ”¥ [ITSC] BirdNet: a 3D Object Detection Framework from LiDAR information. [det. aut.] [arXiv] PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation. [tensorflow] [seg.] ğŸ”¥ [arXiv] Spherical Convolutional Neural Network for 3D Point Clouds. [cls.] [arXiv] Adversarial Autoencoders for Generating 3D Point Clouds. [oth.] [arXiv] Iterative Transformer Network for 3D Point Cloud. [cls. seg. pos.] [arXiv] Topology-Aware Surface Reconstruction for Point Clouds. [rec.] [arXiv] Inferring Point Clouds from Single Monocular Images by Depth Intermediation. [oth.] [arXiv] Deep RBFNet: Point Cloud Feature Learning using Radial Basis Functions. [cls.] [arXiv] IPOD: Intensive Point-based Object Detector for Point Cloud. [det.] [arXiv] Feature Preserving and Uniformity-controllable Point Cloud Simplification on Graph. [oth.] [arXiv] POINTCLEANNET: Learning to Denoise and Remove Outliers from Dense Point Clouds. [pytorch] [oth.] [arXiv] Complex-YOLO: Real-time 3D Object Detection on Point Clouds. [pytorch] [det. aut.] ğŸ”¥ [arxiv] RoarNet: A Robust 3D Object Detection based on RegiOn Approximation Refinement. [tensorflow] [det. aut.] [arXiv] Multi-column Point-CNN for Sketch Segmentation. [seg.] [arXiv] PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention. [project] [oth.] [arXiv] Point Cloud GAN. [pytorch] [oth.] 2019 [CVPR] Relation-Shape Convolutional Neural Network for Point Cloud Analysis. [pytorch] [cls. seg. oth.] ğŸ”¥ [CVPR] Spherical Fractal Convolutional Neural Networks for Point Cloud Recognition. [cls. seg.] [CVPR] DeepMapping: Unsupervised Map Estimation From Multiple Point Clouds. [code] [reg.] [CVPR] Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving. [code] [det. dep. aut.] [CVPR] PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud. [pytorch] [det. aut.] ğŸ”¥ [CVPR] Generating 3D Adversarial Point Clouds. [code] [oth.] [CVPR] Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling. [cls. seg.] [CVPR] A-CNN: Annularly Convolutional Neural Networks on Point Clouds. [tensorflow][cls. seg.] [CVPR] PointConv: Deep Convolutional Networks on 3D Point Clouds. [tensorflow] [cls. seg.] ğŸ”¥ [CVPR] Path-Invariant Map Networks. [tensorflow] [seg. oth.] [CVPR] PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding. [code] [dat. seg.] [CVPR] GeoNet: Deep Geodesic Networks for Point Cloud Analysis. [cls. rec. oth.] [CVPR] Associatively Segmenting Instances and Semantics in Point Clouds. [tensorflow] [seg.] ğŸ”¥ [CVPR] Supervised Fitting of Geometric Primitives to 3D Point Clouds. [tensorflow] [oth.] [CVPR] Octree guided CNN with Spherical Kernels for 3D Point Clouds. [extension] [code] [cls. seg.] [CVPR] PointNetLK: Point Cloud Registration using PointNet. [pytorch] [reg.] [CVPR] JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds with Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields. [pytorch] [seg.] [CVPR] Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning. [seg.] [CVPR] PointPillars: Fast Encoders for Object Detection from Point Clouds. [pytorch] [det.] ğŸ”¥ [CVPR] Patch-based Progressive 3D Point Set Upsampling. [tensorflow] [oth.] [CVPR] PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval. [code] [rel.] [CVPR] PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation. [pytorch] [dat. seg.] [CVPR] PointFlowNet: Learning Representations for Rigid Motion Estimation from Point Clouds. [code] [det. dat. oth.] [CVPR] SDRSAC: Semidefinite-Based Randomized Approach for Robust Point Cloud Registration without Correspondences. [matlab] [reg.] [CVPR] Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image. [rec. oth.] [CVPR] Embodied Question Answering in Photorealistic Environments with Point Cloud Perception. [oth.] [CVPR] 3D Point-Capsule Networks. [pytorch] [cls. rec. oth.] [CVPR] 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks. [pytorch] [seg.] ğŸ”¥ [CVPR] The Perfect Match: 3D Point Cloud Matching with Smoothed Densities. [tensorflow] [oth.] [CVPR] FilterReg: Robust and Efficient Probabilistic Point-Set Registration using Gaussian Filter and Twist Parameterization. [code] [reg.] [CVPR] FlowNet3D: Learning Scene Flow in 3D Point Clouds. [oth.] [CVPR] Modeling Local Geometric Structure of 3D Point Clouds using Geo-CNN. [cls. det.] [CVPR] ClusterNet: Deep Hierarchical Cluster Network with Rigorously Rotation-Invariant Representation for Point Cloud Analysis. [cls.] [CVPR] PointWeb: Enhancing Local Neighborhood Features for Point Cloud Processing. [pytorch] [cls. seg.] [CVPR] RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion. [code] [oth.] [CVPR] PointNetLK: Robust &amp; Efficient Point Cloud Registration using PointNet. [pytorch] [reg.] [CVPR] Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes. [code] [rec.] [CVPR] Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds using Convolutional Neural Networks. [tensorflow] [oth.] [CVPR] GSPN: Generative Shape Proposal Network for 3D Instance Segmentation in Point Cloud. [seg.] [CVPR] Graph Attention Convolution for Point Cloud Semantic Segmentation. [seg.] [CVPR] Point-to-Pose Voting based Hand Pose Estimation using Residual Permutation Equivariant Layer. [pos.] [CVPR] LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving. [det. aut.] [CVPR] LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks. [project] [cls. seg.] [CVPR] Structural Relational Reasoning of Point Clouds. [cls. seg.] [CVPR] 3DN: 3D Deformation Network. [tensorflow] [rec. oth.] [CVPR] Privacy Preserving Image-Based Localization. [pos. oth.] [CVPR] Argoverse: 3D Tracking and Forecasting With Rich Maps.[tra. aut.] [CVPR] Leveraging Shape Completion for 3D Siamese Tracking. [pytorch] [tra. ] [CVPRW] Attentional PointNet for 3D-Object Detection in Point Clouds. [pytorch] [cls. det. aut.] [CVPR] 3D Local Features for Direct Pairwise Registration. [reg.] [CVPR] Learning to Sample. [tensorflow] [cls. rec.] [CVPR] Revealing Scenes by Inverting Structure from Motion Reconstructions. [code] [rec.] [CVPR] DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image. [pytorch] [dep.] [CVPR] HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-scale Point Clouds. [pytorch] [oth.] [ICCV] Deep Hough Voting for 3D Object Detection in Point Clouds. [pytorch] [tensorflow] [det.] ğŸ”¥ [ICCV] DeepGCNs: Can GCNs Go as Deep as CNNs? [tensorflow] [pytorch] [seg.] ğŸ”¥ [ICCV] PU-GAN: a Point Cloud Upsampling Adversarial Network. [tensorflow] [oth.] [ICCV] 3D Point Cloud Learning for Large-scale Environment Analysis and Place Recognition. [rel. oth.] [ICCV] PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows. [pytorch] [oth.] [ICCV] Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction. [oth.] [ICCV] SO-HandNet: Self-Organizing Network for 3D Hand Pose Estimation with Semi-supervised Learning. [code] [pos.] [ICCV] DUP-Net: Denoiser and Upsampler Network for 3D Adversarial Point Clouds Defense. [oth.] [ICCV] Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data. [cls. dat.] [code] [dataset] [ICCV] KPConv: Flexible and Deformable Convolution for Point Clouds. [tensorflow] [cls. seg.] ğŸ”¥ [ICCV] ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics. [project] [seg.] [ICCV] Point-Based Multi-View Stereo Network. [pytorch] [rec.] [ICCV] DensePoint: Learning Densely Contextual Representation for Efficient Point Cloud Processing. [pytorch] [cls. seg. oth.] [ICCV] DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration. [reg.] [ICCV] 3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions. [pytorch] [oth.] [ICCV] Hierarchical Point-Edge Interaction Network for Point Cloud Semantic Segmentation. [seg.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] Fully Convolutional Geometric Features. [pytorch] [reg.] [ICCV] LPD-Net: 3D Point Cloud Learning for Large-Scale Place Recognition and Environment Analysis. [oth. aut.] [ICCV] Total Denoising: Unsupervised Learning of 3D Point Cloud Cleaning. [tensorflow] [oth.] [ICCV] USIP: Unsupervised Stable Interest Point Detection from 3D Point Clouds. [pytorch] [oth.] [ICCV] Interpolated Convolutional Networks for 3D Point Cloud Understanding. [cls. seg.] [ICCV] PointCloud Saliency Maps. [code] [oth.] [ICCV] STD: Sparse-to-Dense 3D Object Detector for Point Cloud. [det. oth.] [ICCV] Accelerated Gravitational Point Set Alignment with Altered Physical Laws. [reg.] [ICCV] Deep Closest Point: Learning Representations for Point Cloud Registration. [reg.] [ICCV] Efficient Learning on Point Clouds with Basis Point Sets. [code] [cls. reg.] [ICCV] PointAE: Point Auto-encoder for 3D Statistical Shape and Texture Modelling. [rec.] [ICCV] Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds. [rec.] [ICCV] Dynamic Points Agglomeration for Hierarchical Point Sets Learning. [pytorch] [cls. seg.] [ICCV] Unsupervised Multi-Task Feature Learning on Point Clouds. [cls. seg.] [ICCV] VV-NET: Voxel VAE Net with Group Convolutions for Point Cloud Segmentation. [tensorflow] [seg.] [ICCV] GraphX-Convolution for Point Cloud Deformation in 2D-to-3D Conversion. [pytorch] [rec.] [ICCV] MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences. [code] [cls. seg. oth.] [ICCV] Fast Point R-CNN. [det. aut.] [ICCV] Robust Variational Bayesian Point Set Registration. [reg.] [ICCV] DiscoNet: Shapes Learning on Disconnected Manifolds for 3D Editing. [rec. oth.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] 3D Instance Segmentation via Multi-Task Metric Learning. [code] [seg.] [ICCV] 3D Face Modeling From Diverse Raw Scan Data. [rec.] [ICCVW] Range Adaptation for 3D Object Detection in LiDAR. [det. aut.] [NeurIPS] Self-Supervised Deep Learning on Point Clouds by Reconstructing Space. [cls. oth.] [NeurIPS] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [NeurIPS] Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representations. [tensorflow] [seg.] [NeurIPS] Point-Voxel CNN for Efficient 3D Deep Learning. [det. seg. aut.] [NeurIPS] PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation. [code] [cls. oth.] [ICLR] Learning Localized Generative Models for 3D Point Clouds via Graph Convolution. [oth.] [ICMLW] LiDAR Sensor modeling and Data augmentation with GANs for Autonomous driving. [det. oth. aut.] [AAAI] CAPNet: Continuous Approximation Projection For 3D Point Cloud Reconstruction Using 2D Supervision. [code] [rec.] [AAAI] Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network. [tensorflow] [cls. seg.] [AAAI] Point Cloud Processing via Recurrent Set Encoding. [cls.] [AAAI] PVRNet: Point-View Relation Neural Network for 3D Shape Recognition. [pytorch] [cls. rel.] [AAAI] Hypergraph Neural Networks. [pytorch] [cls.] [TOG] Dynamic Graph CNN for Learning on Point Clouds. [tensorflow][pytorch] [cls. seg.] ğŸ”¥ â­ï¸ [TOG] LOGAN: Unpaired Shape Transform in Latent Overcomplete Space. [tensorflow] [oth.] [SIGGRAPH Asia] RPM-Net: recurrent prediction of motion and parts from point cloud. [tensorflow] [seg.] [SIGGRAPH Asia] StructureNet: Hierarchical Graph Networks for 3D Shape Generation. [seg. oth.] [MM] MMJN: Multi-Modal Joint Networks for 3D Shape Recognition. [cls. rel.] [MM] 3D Point Cloud Geometry Compression on Deep Learning. [oth.] [MM] SRINet: Learning Strictly Rotation-Invariant Representations for Point Cloud Classification and Segmentation. [tensorflow] [cls. seg.] [MM] L2G Auto-encoder: Understanding Point Clouds by Local-to-Global Reconstruction with Hierarchical Self-Attention. [cls. rel.] [MM] Ground-Aware Point Cloud Semantic Segmentation for Autonomous Driving. [code] [seg. aut.] [ICME] Justlookup: One Millisecond Deep Feature Extraction for Point Clouds By Lookup Tables. [cls. rel.] [ICASSP] 3D Point Cloud Denoising via Deep Neural Network based Local Surface Estimation. [code] [oth.] [BMVC] Mitigating the Hubness Problem for Zero-Shot Learning of 3D Objects. [cls.] [ICRA] Discrete Rotation Equivariance for Point Cloud Recognition. [pytorch] [cls.] [ICRA] SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud. [tensorflow] [seg. aut.] [ICRA] Detection and Tracking of Small Objects in Sparse 3D Laser Range Data. [det. tra. aut.] [ICRA] Oriented Point Sampling for Plane Detection in Unorganized Point Clouds. [det. seg.] [ICRA] Point Cloud Compression for 3D LiDAR Sensor Using Recurrent Neural Network with Residual Blocks. [pytorch] [oth.] [ICRA] Focal Loss in 3D Object Detection. [code] [det. aut.] [ICRA] PointNetGPD: Detecting Grasp Configurations from Point Sets. [pytorch] [det. seg.] [ICRA] 2D3D-MatchNet: Learning to Match Keypoints across 2D Image and 3D Point Cloud. [oth.] [ICRA] Speeding up Iterative Closest Point Using Stochastic Gradient Descent. [oth.] [ICRA] Uncertainty Estimation for Projecting Lidar Points Onto Camera Images for Moving Platforms. [oth.] [ICRA] SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data. [det. aut.] [ICRA] BLVD: Building A Large-scale 5D Semantics Benchmark for Autonomous Driving. [project] [dat. det. tra. aut. oth.] [ICRA] A Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications. [det.] [ICRA] Robust low-overlap 3-D point cloud registration for outlier rejection. [matlab] [reg.] [ICRA] Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution. [cls. seg.] [ICRA] Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds. [seg.] [ICRA] Robust Generalized Point Set Registration Using Inhomogeneous Hybrid Mixture Models Via Expectation. [reg.] [ICRA] Dense 3D Visual Mapping via Semantic Simplification. [oth.] [ICRA] MVX-Net: Multimodal VoxelNet for 3D Object Detection. [det. aut.] [ICRA] CELLO-3D: Estimating the Covariance of ICP in the Real World. [reg.] [IROS] EPN: Edge-Aware PointNet for Object Recognition from Multi-View 2.5D Point Clouds. [tensorflow] [cls. det.] [IROS] SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles. [oth.] [aut.] [IROS] PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud. [seg. aut.] [IV] End-to-End 3D-PointCloud Semantic Segmentation for Autonomous Driving. [seg.] [aut.] [Eurographics Workshop] Generalizing Discrete Convolutions for Unstructured Point Clouds. [pytorch] [cls. seg.] [WACV] 3DCapsule: Extending the Capsule Architecture to Classify 3D Point Clouds. [cls.] [3DV] Rotation Invariant Convolutions for 3D Point Clouds Deep Learning. [project] [cls. seg.] [3DV] Effective Rotation-invariant Point CNN with Spherical Harmonics kernels. [tensorflow] [cls. seg. oth.] [TVCG] LassoNet: Deep Lasso-Selection of 3D Point Clouds. [project] [oth.] [arXiv] Fast 3D Line Segment Detection From Unorganized Point Cloud. [det.] [arXiv] Point-Cloud Saliency Maps. [tensorflow] [cls. oth.] [arXiv] Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud Classifiers. [code] [oth.] [arxiv] Context Prediction for Unsupervised Deep Learning on Point Clouds. [cls. seg.] [arXiv] Points2Pix: 3D Point-Cloud to Image Translation using conditional Generative Adversarial Networks. [oth.] [arXiv] NeuralSampler: Euclidean Point Cloud Auto-Encoder and Sampler. [cls. oth.] [arXiv] 3D Graph Embedding Learning with a Structure-aware Loss Function for Point Cloud Semantic Instance Segmentation. [seg.] [arXiv] Zero-shot Learning of 3D Point Cloud Objects. [code] [cls.] [arXiv] Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud. [det. aut.] [arXiv] Real-time Multiple People Hand Localization in 4D Point Clouds. [det. oth.] [arXiv] Variational Graph Methods for Efficient Point Cloud Sparsification. [oth.] [arXiv] Neural Style Transfer for Point Clouds. [oth.] [arXiv] OREOS: Oriented Recognition of 3D Point Clouds in Outdoor Scenarios. [pos. oth.] [arXiv] FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds. [code] [det. aut.] [arXiv] Unpaired Point Cloud Completion on Real Scans using Adversarial Training. [oth.] [arXiv] MortonNet: Self-Supervised Learning of Local Features in 3D Point Clouds. [cls. seg.] [arXiv] DeepPoint3D: Learning Discriminative Local Descriptors using Deep Metric Learning on 3D Point Clouds. [cls. rel. oth.] [arXiv] Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds. [pytorch] [det. tra. aut.] ğŸ”¥ [arXiv] Graph-based Inpainting for 3D Dynamic Point Clouds. [oth.] [arXiv] nuScenes: A multimodal dataset for autonomous driving. [link] [dat. det. tra. aut.] [arXiv] 3D Backbone Network for 3D Object Detection. [code] [det. aut.] [arXiv] Adversarial Autoencoders for Compact Representations of 3D Point Clouds. [pytorch] [rel. oth.] [arXiv] Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Features. [cls. seg.] [arXiv] GAPNet: Graph Attention based Point Neural Network for Exploiting Local Feature of Point Cloud. [tensorflow] [cls. seg.] [arXiv] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [arXiv] Differentiable Surface Splatting for Point-based Geometry Processing. [pytorch] [oth.] [arXiv] Spatial Transformer for 3D Points. [seg.] [arXiv] Point-Voxel CNN for Efficient 3D Deep Learning. [seg. det. aut.] [arXiv] Neural Point-Based Graphics. [project] [oth.] [arXiv] Point Cloud Super Resolution with Adversarial Residual Graph Networks. [oth.] [tensorflow] [arXiv] Blended Convolution and Synthesis for Efficient Discrimination of 3D Shapes. [cls. rel.] [arXiv] StarNet: Targeted Computation for Object Detection in Point Clouds. [tensorflow] [det.] [arXiv] Efficient Tracking Proposals using 2D-3D Siamese Networks on LIDAR. [tra.] [arXiv] SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing. [tensorflow] [cls. seg.] [arXiv] Part-A^2 Net: 3D Part-Aware and Aggregation Neural Network for Object Detection from Point Cloud. [det. aut.] [arXiv] PyramNet: Point Cloud Pyramid Attention Network and Graph Embedding Module for Classification and Segmentation. [cls. seg.] [arXiv] PointRNN: Point Recurrent Neural Network for Moving Point Cloud Processing. [tensorflow] [tra. oth. aut.] [arXiv] PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points. [tensorflow] [cls. seg.] [arXiv] Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds. [oth.] [arXiv] 3D-Rotation-Equivariant Quaternion Neural Networks. [cls. rec.] [arXiv] Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds using Spatial-aware Capsules. [cls. rel. seg.] [arXiv] Geometric Feedback Network for Point Cloud Classification. [cls.] [arXiv] Relation Graph Network for 3D Object Detection in Point Clouds. [det.] [arXiv] Deformable Filter Convolution for Point Cloud Reasoning. [seg. det. aut.] [arXiv] PU-GCN: Point Cloud Upsampling via Graph Convolutional Network. [project] [oth.] [arXiv] StructEdit: Learning Structural Shape Variations. [project] [rec.] [arXiv] Grid-GCN for Fast and Scalable Point Cloud Learning. [seg. cls.] [arXiv] PointPainting: Sequential Fusion for 3D Object Detection. [seg. det.] [arXiv] Transductive Zero-Shot Learning for 3D Point Cloud Classification. [cls.] [arXiv] Geometry Sharing Network for 3D Point Cloud Classification and Segmentation. [pytorch] [cls. seg.] [arvix] Deep Learning for 3D Point Clouds: A Survey. [code] [cls. det. tra. seg.] [arXiv] Spectral-GANs for High-Resolution 3D Point-cloud Generation. [rec. oth.] [arXiv] Point Attention Network for Semantic Segmentation of 3D Point Clouds. [seg.] [arXiv] PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation. [oth.] [arXiv] 3D Object Recognition with Ensemble Learning â€” A Study of Point Cloud-Based Deep Learning Models. [cls. det.] 2020 [AAAI] Morphing and Sampling Network for Dense Point Cloud Completion. [pytorch] [oth.] [AAAI] TANet: Robust 3D Object Detection from Point Clouds with Triple Attention. [code] [det. aut.] [AAAI] Point2Node: Correlation Learning of Dynamic-Node for Point Cloud Feature Modeling. [seg. cls.] [AAAI] PRIN: Pointwise Rotation-Invariant Network. [seg. cls.] [CVPR] Just Go with the Flow: Self-Supervised Scene Flow Estimation. [code][aut. oth.] [CVPR] SGAS: Sequential Greedy Architecture Search. [code] [cls. oth.] [CVPR] RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds. [tensorflow] [seg.] [CVPR] Learning multiview 3D point cloud registration. [code] [reg.] [CVPR] PF-Net: Point Fractal Network for 3D Point Cloud Completion. [pytorch] [oth.] [CVPR] MLCVNet: Multi-Level Context VoteNet for 3D Object Detection. [code] [det.] [CVPR] SampleNet: Differentiable Point Cloud Sampling. [code] [cls. reg. rec. oth.] [CVPR] MINA: Convex Mixed-Integer Programming for Non-Rigid Shape Alignment. [reg. oth.] [CVPR] Feature-metric Registration: A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences. [code] [reg.] [CVPR] Attentive Context Normalization for Robust Permutation-Equivariant Learning. [code] [cls.] [CVPR] Implicit Functions in Feature Space for Shape Reconstruction and Completion. [code] [oth.] [CVPR] PointAugment: an Auto-Augmentation Framework for Point Cloud Classification. [cls.] [WACV] FuseSeg: LiDAR Point Cloud Segmentation Fusing Multi-Modal Data. [seg. aut.] [arXiv] ImVoteNet: Boosting 3D Object Detection in Point Clouds with Image Votes. [det.] [ECCV] Quaternion Equivariant Capsule Networks for 3D Point Clouds. [cls.] [ECCV] PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding. [cls. seg. det.] [ECCV] DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares. [code] [oth.] [ECCV] DPDist: Comparing Point Clouds Using Deep Point Cloud Distance. [code] [oth.] [IROS] GndNet: Fast Ground Plane Estimation and Point Cloud Segmentation for Autonomous Vehicles. [code] [seg. aut.] [ICLR] AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing. [code][cls. seg.] [arXiv] Parameter-Efficient Person Re-identification in the 3D Space. [code][rel.] ğŸ”¥ 2021 [ICLR] PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences. [cls. seg.] [CVPR] Point 4D Transformer Networks for Spatio-Temporal Modeling in Point Cloud Videos. [code][cls. seg.] [CVPR] PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of Point Clouds. [code][oth.] [ICRA] FGR: Frustum-Aware Geometric Reasoning for Weakly Supervised 3D Vehicle Detection. [code][det. seg.] [ICCV] MVTN: Multi-View Transformation Network for 3D Shape Recognition. [code][det. rel.] - Datasets [KITTI] The KITTI Vision Benchmark Suite. [det.] [ModelNet] The Princeton ModelNet . [cls.] [ShapeNet] A collaborative dataset between researchers at Princeton, Stanford and TTIC. [seg.] [PartNet] The PartNet dataset provides fine grained part annotation of objects in ShapeNetCore. [seg.] [PartNet] PartNet benchmark from Nanjing University and National University of Defense Technology. [seg.] [S3DIS] The Stanford Large-Scale 3D Indoor Spaces Dataset. [seg.] [ScanNet] Richly-annotated 3D Reconstructions of Indoor Scenes. [cls. seg.] [Stanford 3D] The Stanford 3D Scanning Repository. [reg.] [UWA Dataset] . [cls. seg. reg.] [Princeton Shape Benchmark] The Princeton Shape Benchmark. [SYDNEY URBAN OBJECTS DATASET] This dataset contains a variety of common urban road objects scanned with a Velodyne HDL-64E LIDAR, collected in the CBD of Sydney, Australia. There are 631 individual scans of objects across classes of vehicles, pedestrians, signs and trees. [cls. match.] [ASL Datasets Repository(ETH)] This site is dedicated to provide datasets for the Robotics community with the aim to facilitate result evaluations and comparisons. [cls. match. reg. det] [Large-Scale Point Cloud Classification Benchmark(ETH)] This benchmark closes the gap and provides a large labelled 3D point cloud data set of natural scenes with over 4 billion points in total. [cls.] [Robotic 3D Scan Repository] The Canadian Planetary Emulation Terrain 3D Mapping Dataset is a collection of three-dimensional laser scans gathered at two unique planetary analogue rover test facilities in Canada. [Radish] The Robotics Data Set Repository (Radish for short) provides a collection of standard robotics data sets. [IQmulus &amp; TerraMobilita Contest] The database contains 3D MLS data from a dense urban environment in Paris (France), composed of 300 million points. The acquisition was made in January 2013. [cls. seg. det.] [Oakland 3-D Point Cloud Dataset] This repository contains labeled 3-D point cloud laser data collected from a moving platform in a urban environment. [Robotic 3D Scan Repository] This repository provides 3D point clouds from robotic experimentsï¼Œlog files of robot runs and standard 3D data sets for the robotics community. [Ford Campus Vision and Lidar Data Set] The dataset is collected by an autonomous ground vehicle testbed, based upon a modified Ford F-250 pickup truck. [The Stanford Track Collection] This dataset contains about 14,000 labeled tracks of objects as observed in natural street scenes by a Velodyne HDL-64E S2 LIDAR. [PASCAL3D+] Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild. [pos. det.] [3D MNIST] The aim of this dataset is to provide a simple way to get started with 3D computer vision problems such as 3D shape recognition. [cls.] [WAD] [ApolloScape] The datasets are provided by Baidu Inc. [tra. seg. det.] [nuScenes] The nuScenes dataset is a large-scale autonomous driving dataset. [PreSIL] Depth information, semantic segmentation (images), point-wise segmentation (point clouds), ground point labels (point clouds), and detailed annotations for all vehicles and people. [paper] [det. aut.] [3D Match] Keypoint Matching Benchmark, Geometric Registration Benchmark, RGB-D Reconstruction Datasets. [reg. rec. oth.] [BLVD] (a) 3D detection, (b) 4D tracking, (c) 5D interactive event recognition and (d) 5D intention prediction. [ICRA 2019 paper] [det. tra. aut. oth.] [PedX] 3D Pose Estimation of Pedestrians, more than 5,000 pairs of high-resolution (12MP) stereo images and LiDAR data along with providing 2D and 3D labels of pedestrians. [ICRA 2019 paper] [pos. aut.] [H3D] Full-surround 3D multi-object detection and tracking dataset. [ICRA 2019 paper] [det. tra. aut.] [Argoverse BY ARGO AI] Two public datasets (3D Tracking and Motion Forecasting) supported by highly detailed maps to test, experiment, and teach self-driving vehicles how to understand the world around them.[CVPR 2019 paper][tra. aut.] [Matterport3D] RGB-D: 10,800 panoramic views from 194,400 RGB-D images. Annotations: surface reconstructions, camera poses, and 2D and 3D semantic segmentations. Keypoint matching, view overlap prediction, normal prediction from color, semantic segmentation, and scene classification. [3DV 2017 paper] [code] [blog] [SynthCity] SynthCity is a 367.9M point synthetic full colour Mobile Laser Scanning point cloud. Nine categories. [seg. aut.] [Lyft Level 5] Include high quality, human-labelled 3D bounding boxes of traffic agents, an underlying HD spatial semantic map. [det. seg. aut.] [SemanticKITTI] Sequential Semantic Segmentation, 28 classes, for autonomous driving. All sequences of KITTI odometry labeled. [ICCV 2019 paper] [seg. oth. aut.] [NPM3D] The Paris-Lille-3D has been produced by a Mobile Laser System (MLS) in two different cities in France (Paris and Lille). [seg.] [The Waymo Open Dataset] The Waymo Open Dataset is comprised of high resolution sensor data collected by Waymo self-driving cars in a wide variety of conditions. [det.] [A*3D: An Autonomous Driving Dataset in Challeging Environments] A*3D: An Autonomous Driving Dataset in Challeging Environments. [det.] [PointDA-10 Dataset] Domain Adaptation for point clouds. [Oxford Robotcar] The dataset captures many different combinations of weather, traffic and pedestrians. [cls. det. rec.] [PandaSet] Public large-scale dataset for autonomous driving provided by Hesai &amp; Scale. It enables researchers to study challenging urban driving situations using the full sensor suit of a real self-driving-car. [det. seg.] [3D-FRONT 3D-FUTURE] [Alibaba] 3D-FRONT contains 10,000 houses (or apartments) and ~70,000 rooms with layout information. 3D-FUTURE contains 20,000+ clean and realistic synthetic scenes in 5,000+ diverse rooms which contain 10,000+ unique high quality 3D instances of furniture. [Campus3D] The Campus3D contains a photogrametry point cloud which has 931.7 million points, covering 1.58 km2 of 6 connected campus regions of NUS. The dataset are point-wisely annotated with a hierarchical structure of 24 semantic labels and contains 2,530 instances based on the labels. [MM 2020 paper][code][ det. cls. seg.] å‚è€ƒæ¥æºhttps://cvpr2021.thecvf.com/https://cvpr2022.thecvf.com/ è®ºæ–‡ä¸codeæŸ¥è¯¢ç½‘ç«™ï¼šhttps://paperswithcode.com/AIè®ºæ–‡æŸ¥è¯¢åœ°å€ï¼šhttps://arxiv.org/list/cs.AI/recent è®ºæ–‡ï¼šhttps://github.com/extreme-assistant/CVPR2021-Paper-Code-Interpretationç»¼è¿°ï¼šhttps://github.com/extreme-assistant/survey-computer-vision-2020\\ æ¨èé˜…è¯»ï¼š&lt;br&gt; ICCV2021&#x2F;2019&#x2F;2017 è®ºæ–‡&#x2F;ä»£ç &#x2F;è§£è¯»&#x2F;ç›´æ’­åˆé›† 2020-2021å¹´è®¡ç®—æœºè§†è§‰ç»¼è¿°è®ºæ–‡æ±‡æ€»&lt;br&gt; å›½å†…å¤–ä¼˜ç§€çš„è®¡ç®—æœºè§†è§‰å›¢é˜Ÿæ±‡æ€» cvpr2021&#x2F;cvpr2020&#x2F;cvpr2019&#x2F;cvpr2018&#x2F;cvpr2017ï¼ˆPapers&#x2F;Codes&#x2F;Project&#x2F;Paper readingï¼‰è®ºæ–‡è§£è¯»æ±‡æ€»ï¼šhttps://bbs.cvmart.net/articles/3031 &lt;br&gt;è®ºæ–‡åˆ†ç±»æ±‡æ€»ï¼šhttps://bbs.cvmart.net/articles/4267` 2000~2020å¹´å†å±ŠCVPRæœ€ä½³è®ºæ–‡ä»£ç ï¼Œè§£è¯»ç­‰æ±‡æ€»ï¼šhttp://bbs.cvmart.net/topics/665/CVPR-Best-Paper &#96; ç›®å½•8. CVPR2021æœ€æ–°ä¿¡æ¯åŠè®ºæ–‡ä¸‹è½½&lt;br&gt;7. CVPR2021è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt;6. CVPR2020è®ºæ–‡ä¸‹è½½&#x2F;ä»£ç &#x2F;è§£è¯»&#x2F;ç›´æ’­&lt;br&gt;5. CVPR2020è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt;4. CVPR2019å…¨éƒ¨è®ºæ–‡ä¸‹è½½&#x2F;å¼€æºä»£ç &lt;br&gt;3. CVPR2019è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt;2. CVPR2019è®ºæ–‡ç›´æ’­åˆ†äº«&lt;br&gt;1. CVPR2018&#x2F;CVPR2017&lt;br&gt; 8.CVPR2021æœ€æ–°è®ºæ–‡åˆ†ç±»æ±‡æ€»(æŒç»­æ›´æ–°) Papers&#x2F;Codes&#x2F;Project&#x2F;PaperReadingï¼Demos&#x2F;ç›´æ’­åˆ†äº«ï¼è®ºæ–‡åˆ†äº«ä¼šç­‰&lt;br&gt; CVPR2021å…¨éƒ¨è®ºæ–‡ä¸‹è½½ï¼ˆå…±1661ç¯‡ï¼‰ æå–ç ï¼šsu7e CVPR2021 è®ºæ–‡è§£è¯»æ±‡æ€» + æŠ€æœ¯ç›´æ’­æ±‡æ€»&lt;br&gt; CVPR2021 Oralè®ºæ–‡æ±‡æ€»&#x2F;è§£è¯»&lt;br&gt; 7.CVPR2021è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt; ä¸€æ–‡çœ‹å°½CVPR2021 2D ç›®æ ‡æ£€æµ‹è®ºæ–‡ï¼ˆ27ç¯‡ï¼‰ ä¸€æ–‡çœ‹å°½CVPR2021 å›¾åƒå¼‚å¸¸æ£€æµ‹è®ºæ–‡ï¼ˆ6ç¯‡ï¼‰ ä¸€æ–‡çœ‹å°½CVPR2021 ä¼ªè£…ç›®æ ‡æ£€æµ‹+æ—‹è½¬ç›®æ ‡æ£€æµ‹è®ºæ–‡ï¼ˆ6ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå…¨æ™¯åˆ†å‰²è®ºæ–‡æ±‡æ€»ï¼ˆå…±15ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šäººå‘˜é‡è¯†åˆ«æ±‡æ€»ï¼ˆå…±26ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šè¡ŒäººæŠ€æœ¯æ±‡æ€»ï¼ˆå…±7ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šåŒ»å­¦å½±åƒæ±‡æ€»ï¼ˆå…±22ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šè¶…åˆ†è¾¨ç‡æ±‡æ€»ï¼ˆå…±32ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå›¾åƒä¿®å¤æ±‡æ€»ï¼ˆå…±20ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå›¾åƒå»å™ªæ±‡æ€»ï¼ˆå…±14ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå»é›¾å»æ¨¡ç³Šæ±‡æ€»ï¼ˆå…±14ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå›¾åƒè§†é¢‘å»é›¨æ±‡æ€»ï¼ˆå…±10ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šæ–‡æœ¬å›¾åƒæ±‡æ€»ï¼ˆå…±17ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šäººè„¸è¯†åˆ«æ±‡æ€»ï¼ˆå…±15ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šäººè„¸é€ å‡æ£€æµ‹æ±‡æ€»ï¼ˆå…±9ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šå›¾åƒå‹ç¼©æ±‡æ€»ï¼ˆå…±5ç¯‡ï¼‰ CVPR2021 è®ºæ–‡å¤§ç›˜ç‚¹ï¼šé¥æ„Ÿä¸èˆªæ‹å½±åƒæ±‡æ€»ï¼ˆå…±7ç¯‡ï¼‰ 6.CVPR2020è®ºæ–‡ä¸‹è½½&#x2F;ä»£ç &#x2F;è§£è¯»&#x2F;ç›´æ’­ Papers&#x2F;Codes&#x2F;Project&#x2F;PaperReadingï¼Demos&#x2F;ç›´æ’­åˆ†äº«ï¼è®ºæ–‡åˆ†äº«ä¼šç­‰&lt;br&gt; CVPR2020å…¨éƒ¨è®ºæ–‡ä¸‹è½½ï¼ˆå…±1467ç¯‡ï¼‰&lt;br&gt;æå–ç ï¼špun7&lt;br&gt;&lt;br&gt; CVPR2020 è®ºæ–‡è§£è¯»æ±‡æ€» + æŠ€æœ¯ç›´æ’­æ±‡æ€»&lt;br&gt; 5.CVPR2020è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt; 20.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-åŠ¨ä½œæ£€æµ‹ä¸åŠ¨ä½œåˆ†å‰²ï¼ˆ13ç¯‡ï¼‰&lt;br&gt; 19.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-åŠ¨ä½œè¯†åˆ«ï¼ˆ21ç¯‡ï¼‰&lt;br&gt; 18.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å…‰æµï¼ˆ12ç¯‡ï¼‰&lt;br&gt; 17.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å›¾åƒä¸è§†é¢‘æ£€ç´¢ï¼ˆ16ç¯‡ï¼‰&lt;br&gt; 16.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-é¥æ„Ÿä¸èˆªæ‹å½±åƒå¤„ç†è¯†åˆ«ï¼ˆ18ç¯‡ï¼‰&lt;br&gt; 15.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å›¾åƒè´¨é‡è¯„ä»·ï¼ˆ7ç¯‡ï¼‰&lt;br&gt; 14.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å›¾åƒä¿®å¤ Inpainting ï¼ˆ7ç¯‡ï¼‰ &lt;br&gt; 13.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å›¾åƒå¢å¼ºä¸å›¾åƒæ¢å¤ï¼ˆ22ç¯‡ï¼‰&lt;br&gt; 12.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å»é›¨å»é›¾å»æ¨¡ç³Šï¼ˆ8ç¯‡ï¼‰&lt;br&gt; 11.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-åŒ»å­¦å½±åƒå¤„ç†è¯†åˆ«ï¼ˆ19ç¯‡ï¼‰&lt;br&gt; 10.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-æŠ å›¾ Matting ï¼ˆ3ç¯‡ï¼‰&lt;br&gt; 9.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å›¾åƒåˆ†å‰²ï¼ˆ25ç¯‡ï¼‰&lt;br&gt; 8.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å…¨æ™¯åˆ†å‰²ä¸è§†é¢‘ç›®æ ‡åˆ†å‰²ï¼ˆ8ç¯‡ï¼‰&lt;br&gt; 7.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-è¶…åˆ†è¾¨ï¼ˆ21ç¯‡ï¼‰&lt;br&gt; 6.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-ç›®æ ‡æ£€æµ‹ï¼ˆ64ç¯‡ï¼‰&lt;br&gt; 5.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-äººè„¸æŠ€æœ¯ï¼ˆ64ç¯‡&lt;br&gt; 4.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-ç›®æ ‡è·Ÿè¸ªï¼ˆ33ç¯‡ï¼‰&lt;br&gt; 3.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-æ–‡æœ¬å›¾åƒï¼ˆ16ç¯‡ï¼‰&lt;br&gt; 2.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-è¡Œäººæ£€æµ‹ä¸é‡è¯†åˆ«ï¼ˆ33ç¯‡ï¼‰&lt;br&gt; 1.CVPR 2020 è®ºæ–‡å¤§ç›˜ç‚¹-å®ä¾‹åˆ†å‰²ï¼ˆ18ç¯‡ï¼‰&lt;br&gt;&lt;br&gt; &lt;br&gt;&lt;br&gt; 4.CVPR2019å…¨éƒ¨è®ºä¸‹è½½&#x2F;å¼€æºä»£ç &lt;br&gt;å…¨éƒ¨1294ç¯‡&lt;br&gt; å…¨éƒ¨é“¾æ¥ï¼šhttp://openaccess.thecvf.com/CVPR2019.py &lt;br&gt; ä¸‹è½½é“¾æ¥:&lt;br&gt;é“¾æ¥:https://pan.baidu.com/s/1dhXrWFHeKeJ1kFsKBxQzVg å¯†ç :f53l CVPR 2019å…¨éƒ¨è®ºæ–‡å¼€æºæºç æ±‡æ€»Excelç‚¹è¿™é‡Œ &lt;br&gt;&lt;br&gt; 3.CVPR2019è®ºæ–‡åˆ†æ–¹å‘ç›˜ç‚¹&lt;br&gt; CVPR 2019 è®ºæ–‡å¤§ç›˜ç‚¹-ç›®æ ‡è·Ÿè¸ªç¯‡&lt;br&gt; CVPR 2019 è®ºæ–‡å¤§ç›˜ç‚¹-è¶…åˆ†è¾¨ç‡ç¯‡&lt;br&gt; CVPR 2019 è®ºæ–‡å¤§ç›˜ç‚¹-äººè„¸æŠ€æœ¯ç¯‡&lt;br&gt; CVPR 2019 è®ºæ–‡å¤§ç›˜ç‚¹â€”ç›®æ ‡æ£€æµ‹ç¯‡&lt;br&gt; CVPR 2019 è®ºæ–‡å¤§ç›˜ç‚¹â€”æ–‡æœ¬å›¾åƒç¯‡&lt;br&gt; CVPR2019æ¨¡å‹å‰ªæè®ºæ–‡æ±‡æ€»&lt;br&gt;&lt;br&gt; 2.CVPR2019è®ºæ–‡ç›´æ’­åˆ†äº«&lt;br&gt; å¾®è½¯äºšç ”é™¢CVPR2019çº¿ä¸‹åˆ†äº«ä¼šè§†é¢‘å›æ”¾åŠPPTä¸‹è½½ 3&#x2F;28æ™šç‚¹äº‘åˆ†å‰²åˆ†äº«å›æ”¾&lt;br&gt;ç‹é‘«é¾™ï¼šè”åˆåˆ†å‰²ç‚¹äº‘ä¸­çš„å®ä¾‹å’Œè¯­ä¹‰ï¼ˆå¼€æºï¼Œåˆ—è¡¨id 27)&lt;br&gt; 4æœˆ18æ—¥æ™šç›®æ ‡æ£€æµ‹åˆ†äº«å›æ”¾&lt;br&gt;CMUè¯¸å®¸è¾°:åŸºäºAnchor-freeç‰¹å¾é€‰æ‹©æ¨¡å—çš„å•é˜¶ç›®æ ‡æ£€æµ‹(CVPR2019ï¼Œåˆ—è¡¨id 88) &lt;br&gt; 5æœˆ9æ—¥æ™šå•ç›®æ ‡è·Ÿè¸ªåˆ†äº«å›æ”¾&lt;br&gt;å¼ å¿—é¹:åŸºäºsiameseç½‘ç»œçš„å•ç›®æ ‡è·Ÿè¸ª(CVPR2019 Oralï¼Œåˆ—è¡¨id 65)&lt;br&gt; [5æœˆ30æ—¥æ™šäººè„¸è¯†åˆ«åˆ†äº«å›æ”¾&lt;br&gt;é‚“å¥åº·-CVPR2019:ArcFace æ„å»ºé«˜æ•ˆçš„äººè„¸è¯†åˆ«ç³»ç»Ÿ(CVPR2019ï¼Œåˆ—è¡¨id 243)ï¼š&lt;br&gt; 6æœˆ13æ—¥æ™šä¸‰ç»´å¤šäººå¤šè§†è§’å§¿æ€è¯†åˆ«åˆ†äº«å›æ”¾&lt;br&gt;è‘£å³»å»·ï¼šå¤šè§†è§’ä¸‹å¤šäººä¸‰ç»´å§¿æ€ä¼°è®¡ CVPR2019ï¼Œåˆ—è¡¨id 106&lt;br&gt; 1.CVPR2018&#x2F;CVPR2017&lt;br&gt; CVPR 2018å…¨éƒ¨è®ºæ–‡ä¸‹è½½ç™¾åº¦äº‘é“¾æ¥ï¼šhttps://pan.baidu.com/s/1bhYzNz2TGijUdfPIdyEGtg &lt;br&gt; å¯†ç :gyk2 CVPR 2018è®ºæ–‡è§£è¯»æ±‡æ€» CVPR 2017å…¨éƒ¨è®ºæ–‡ä¸‹è½½ç™¾åº¦äº‘é“¾æ¥ï¼šhttps://pan.baidu.com/s/1p_If8S_AAgnTlZxfzBya2w &lt;br&gt; å¯†ç :o6tu CVPR 2017è®ºæ–‡è§£è¯»é›†é”¦ å‚è€ƒé“¾æ¥&lt;br&gt; https://mp.weixin.qq.com/s/YRcajgSTJq_evwtn7ZFo4A &lt;br&gt; https://github.com/hoya012/CVPR-2019-Paper-Statistics &lt;br&gt; https://github.com/jonahthelion/cvpr_with_code &lt;br&gt; https://github.com/amusi/daily-paper-computer-vision &lt;br&gt;&lt;br&gt; NLPsDeep learning speech learning library Py2neo æ‰‹å†ŒPy2neoæ˜¯ä¸€ä¸ªå®¢æˆ·ç«¯åº“å’Œå·¥å…·åŒ…ï¼Œç”¨äºä»Pythonåº”ç”¨ç¨‹åºå’Œå‘½ä»¤è¡Œä¸­ä½¿ç”¨Neo4j ã€‚è¯¥åº“æ”¯æŒ Bolt å’Œ HTTPï¼Œå¹¶æä¾›é«˜çº§ APIã€OGMã€ç®¡ç†å·¥å…·ã€äº¤äº’å¼æ§åˆ¶å°ã€Pygments çš„ Cypher è¯æ³•åˆ†æå™¨ä»¥åŠè®¸å¤šå…¶ä»–èŠ±é‡Œèƒ¡å“¨ã€‚ä»ç‰ˆæœ¬ 2021.1 å¼€å§‹ï¼ŒPy2neo åŒ…å«å¯¹è·¯ç”±çš„å®Œå…¨æ”¯æŒï¼Œæ­£å¦‚ Neo4j é›†ç¾¤æ‰€å…¬å¼€çš„é‚£æ ·ã€‚è¿™å¯ä»¥ä½¿ç”¨neo4j:&#x2F;&#x2F;â€¦URI æˆ–ä¼ é€’routing&#x3D;Trueç»™Graphæ„é€ å‡½æ•°æ¥å¯ç”¨ã€‚https://py2neo.org/2021.1/ æ•°æ®é›†ä¸­æ–‡ã€è‹±æ–‡NERã€è‹±æ±‰æœºå™¨ç¿»è¯‘æ•°æ®é›†ã€‚ä¸­è‹±æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†ï¼Œä¸­è‹±æ–‡æœºå™¨ç¿»è¯‘æ•°æ®é›†ï¼Œä¸­æ–‡åˆ†è¯æ•°æ®é›†ï¼šhttps://github.com/quincyliang/nlp-public-dataset CTBè¯æ€§æ ‡æ³¨é›† ck: https://help.aliyun.com/document_detail/179146.html?scm=20140722.184.2.173 æ ‡æ³¨æ ‡ç­¾è¯´æ˜ï¼šhttps://verbs.colorado.edu/chinese/segguide.3rd.ch.pdf https://blog.csdn.net/qq_40332976/article/details/120331450 èµ„æ–™æ±‡æ€»ä¸€ä¸ªè½»é‡çº§ã€ç®€å•æ˜“ç”¨çš„ RNN å”¤é†’è¯ç›‘å¬å™¨: https://github.com/MycroftAI/mycroft-precise zh:http://fancyerii.github.io/books/mycroft-precise/ åŸºäºæ ‘è“æ´¾çš„äººå·¥æ™ºèƒ½å°è½¦ï¼Œå®ç°è¯†åˆ«ã€æç¤ºã€æ™ºèƒ½æ—…æ¸¸çº¿è·¯ã€ç¦»çº¿å›¾åƒ:https://github.com/dalinzhangzdl/AI_Car_Raspberry-pi ä¸­æ–‡NLPæ•°æ®é›†:https://github.com/CLUEbenchmark/CLUEDatasetSearch æ¨¡å‹ï¼šhttps://github.com/CLUEbenchmark/CLUE ä¸­æ–‡ NLP èµ„æºç²¾é€‰åˆ—è¡¨ ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³èµ„æ–™:https://github.com/crownpku/Awesome-Chinese-NLP è§†è§‰èŠå¤©æœºå™¨äºº:https://paperswithcode.com/paper/visual-dialog Bert&#x2F;Transformeræ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ–åŠ é€Ÿ: https://blog.csdn.net/nature553863/article/details/120292394ï¼š å¯ä»¥å‹ç¼© BERT çš„æ‰€æœ‰æ–¹å¼ï¼šhttp://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.htmlhttps://www.leiphone.com/category/academic/MkV1j604LvPt1wcx.html BERTè½»é‡åŒ–æ¢ç´¢â€”æ¨¡å‹å‰ªæï¼ˆBERT Pruningï¼‰â€”Rasaç»´åº¦å‰ªæ:https://blog.csdn.net/ai_1046067944/article/details/103609152 å‹ç¼© BERT ä»¥åŠ å¿«é¢„æµ‹é€Ÿåº¦:https://rasa.com/blog/compressing-bert-for-faster-prediction-2/ è®ºæ–‡ç»¼è¿°ä¸BERTç›¸å…³æœ€æ–°è®ºæ–‡:https://github.com/tomohideshibata/BERT-related-papers ä¸­æ–‡è‡ªç„¶è¯­è¨€æ’è¡Œæ¦œåŠè®ºæ–‡æŸ¥è¯¢:https://www.cluebenchmarks.com/index.html è®¡ç®—è¯­è¨€å­¦å›½é™…ä¼šè®®è®ºæ–‡é›†:https://aclanthology.org/volumes/2020.coling-main/ è®¡ç®—è¯­è¨€å­¦åä¼šç¬¬ 58 å±Šå¹´ä¼šè®ºæ–‡é›†:https://aclanthology.org/volumes/2020.acl-main/ è®¡ç®—è¯­è¨€å­¦2åä¼š2021å¹´ä¼šè®ºæ–‡æœé›†ï¼šhttps://aclanthology.org/events/acl-2021/ ä¸­æ–‡BERTå…¨è¯æ©è”½é¢„è®­ç»ƒï¼ˆä¸­æ–‡BERT-wwmç³»åˆ—æ¨¡å‹ï¼‰https://github.com/ymcui/Chinese-BERT-wwm ä¸€ä¸ªå¤§è§„æ¨¡çš„ä¸­æ–‡è·¨é¢†åŸŸé¢å‘ä»»åŠ¡çš„å¯¹è¯æ•°æ®é›†:https://github.com/thu-coai/CrossWOZ å…³äºConvLab-2ï¼šç”¨äºæ„å»ºã€è¯„ä¼°å’Œè¯Šæ–­å¯¹è¯ç³»ç»Ÿçš„å¼€æºå·¥å…·åŒ…ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰ï¼šhttps://github.com/thu-coai/ConvLab-2 è§†è§‰å’Œè¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ (VL-PTM) çš„æœ€æ–°è¿›å±•(è¯­éŸ³è§†è§‰èåˆ):https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†é˜…è¯»æ¸…å•:https://github.com/IsaacChanghau/DL-NLP-Readings è§†è§‰é—®ç­” (VQA)ï¼ˆå›¾åƒ&#x2F;è§†é¢‘é—®ç­”ï¼‰ã€è§†è§‰é—®é¢˜ç”Ÿæˆã€è§†è§‰å¯¹è¯ã€è§†è§‰å¸¸è¯†æ¨ç†å’Œç›¸å…³é¢†åŸŸçš„ç²¾é€‰åˆ—è¡¨ï¼šhttps://github.com/jokieleung/awesome-visual-question-answering æ±‡æ€»å¾—ä¸é”™çš„nlpå­¦ä¹ èµ„æ–™:https://jackkuo666.github.io/ dl4nlpè‡ªç„¶è¯­è¨€å¤„ç†æ·±åº¦å­¦ä¹ è¯¾ç¨‹ææ–™:https://github.com/liu-nlp/dl4nlp è®ºæ–‡ä¸æ•°æ®é›†ç½‘ç«™ï¼šhttps://www.ai2news.com/area/ HanLPçš„Pythonæ¥å£ï¼Œæ”¯æŒè‡ªåŠ¨ä¸‹è½½ä¸å‡çº§HanLPï¼Œå…¼å®¹py2ã€py3ã€‚å†…éƒ¨ç®—æ³•ç»è¿‡å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œè€ƒéªŒï¼Œé…å¥—ä¹¦ç±ã€Šè‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨ã€‹å·²ç»å‡ºç‰ˆï¼Œæ¬¢è¿æŸ¥é˜…éšä¹¦ä»£ç :https://github.com/jiajunhua/hankcs-pyhanlp/tree/3fc9c7d8a3f5eae00988db743c44b7708520b5f1 pyhanlpæ–‡æœ¬è®­ç»ƒä¸é¢„æµ‹APIæ¥å£from pyhanlp import *from tests.test_utility import ensure_dataIClassifier = JClass(&#x27;com.hankcs.hanlp.classification.classifiers.IClassifier&#x27;)NaiveBayesClassifier = JClass(&#x27;com.hankcs.hanlp.classification.classifiers.NaiveBayesClassifier&#x27;)# ä¸­æ–‡æƒ…æ„ŸæŒ–æ˜è¯­æ–™-ChnSentiCorp æ•°æ®æ¥è‡ªï¼šchn_senti_corp = ensure_data(&quot;ChnSentiCorpæƒ…æ„Ÿåˆ†æé…’åº—è¯„è®º&quot;, &quot;http://file.hankcs.com/corpus/ChnSentiCorp.zip&quot;)def predict(classifier, text): print(&quot;ã€Š%sã€‹ æƒ…æ„Ÿææ€§æ˜¯ ã€%sã€‘&quot; % (text, classifier.classify(text)))if __name__ == &#x27;__main__&#x27;: classifier = NaiveBayesClassifier() # åˆ›å»ºåˆ†ç±»å™¨ï¼Œæ›´é«˜çº§çš„åŠŸèƒ½è¯·å‚è€ƒIClassifierçš„æ¥å£å®šä¹‰ classifier.train(chn_senti_corp) # è®­ç»ƒåçš„æ¨¡å‹æ”¯æŒæŒä¹…åŒ–ï¼Œä¸‹æ¬¡å°±ä¸å¿…è®­ç»ƒäº† predict(classifier, &quot;å‰å°å®¢æˆ¿æœåŠ¡æ€åº¦éå¸¸å¥½ï¼æ—©é¤å¾ˆä¸°å¯Œï¼Œæˆ¿ä»·å¾ˆå¹²å‡€ã€‚å†æ¥å†å‰ï¼&quot;) predict(classifier, &quot;ç»“æœå¤§å¤±æ‰€æœ›ï¼Œç¯å…‰æ˜æš—ï¼Œç©ºé—´æå…¶ç‹­å°ï¼ŒåºŠå«è´¨é‡æ¶åŠ£ï¼Œæˆ¿é—´è¿˜ä¼´ç€ä¸€è‚¡éœ‰å‘³ã€‚&quot;) predict(classifier, &quot;å¯åˆ©ç”¨æ–‡æœ¬åˆ†ç±»å®ç°æƒ…æ„Ÿåˆ†æï¼Œæ•ˆæœä¸æ˜¯ä¸è¡Œ&quot;) åŸåˆ›æ¥è‡ªè¿™é‡Œ:https://www.jianshu.com/p/0a131e042238 å¥½ä¸œè¥¿ï¼šhttps://github.com/Kyubyong/nlp_tasks https://github.com/songyingxin/NLPer-Interview æ€»ç»“æ¢³ç†è‡ªç„¶è¯­è¨€å¤„ç†å·¥ç¨‹å¸ˆ(NLP)éœ€è¦ç§¯ç´¯çš„å„æ–¹é¢çŸ¥è¯†ï¼ŒåŒ…æ‹¬é¢è¯•é¢˜ï¼Œå„ç§åŸºç¡€çŸ¥è¯†ï¼Œå·¥ç¨‹èƒ½åŠ›ç­‰ç­‰ï¼Œæå‡æ ¸å¿ƒç«äº‰åŠ› https://github.com/DA-southampton/NLP_ability å²ä¸Šæœ€å…¨Transformeré¢è¯•é¢˜ç­”æ¡ˆè§£æ(1)-å²ä¸Šæœ€å…¨Transformeré¢è¯•é¢˜Pytorchä»£ç åˆ†æâ€“å¦‚ä½•è®©Bertåœ¨finetuneå°æ•°æ®é›†æ—¶æ›´â€œç¨³â€ä¸€ç‚¹è§£å†³è€å¤§éš¾é—®é¢˜-å¦‚ä½•ä¸€è¡Œä»£ç å¸¦ä½ éšå¿ƒæ‰€æ¬²é‡æ–°åˆå§‹åŒ–bertçš„æŸäº›å‚æ•°(é™„Pytorchä»£ç è¯¦ç»†è§£è¯»)3åˆ†é’Ÿä»é›¶è§£è¯»Transformerçš„EncoderåŸç‰ˆTransformerçš„ä½ç½®ç¼–ç ç©¶ç«Ÿæœ‰æ²¡æœ‰åŒ…å«ç›¸å¯¹ä½ç½®ä¿¡æ¯BNè¸©å‘è®°â€“è°ˆä¸€ä¸‹Batch Normalizationçš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯è°ˆä¸€ä¸‹ç›¸å¯¹ä½ç½®ç¼–ç NLPä»»åŠ¡ä¸­-layer-normæ¯”BatchNormå¥½åœ¨å“ªé‡Œè°ˆä¸€è°ˆDecoderæ¨¡å—Transformerçš„å¹¶è¡ŒåŒ–Transformerå…¨éƒ¨æ–‡ç« åˆè¾‘RNNçš„æ¢¯åº¦æ¶ˆå¤±æœ‰ä»€ä¹ˆä¸ä¼—ä¸åŒçš„åœ°æ–¹.mdVIT-å¦‚ä½•å°†Transformeræ›´å¥½çš„åº”ç”¨åˆ°CVé¢†åŸŸ å¥½ä¹¦ï¼šhttps://github.com/FudanNLP/nlp-beginner è®ºæ–‡ä¸code:https://github.com/keon/awesome-nlp è·Ÿè¸ªè‡ªç„¶è¯­è¨€å¤„ç†çš„è¿›å±•:https://github.com/sebastianruder/NLP-progress å…ƒç ”ç©¶ï¼šhttps://research.facebook.com/research-areas/ æ­¤é¡¹ç›®æ˜¯æœºå™¨å­¦ä¹ (Machine Learning)ã€æ·±åº¦å­¦ä¹ (Deep Learning)ã€NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚https://github.com/NLP-LOVE/ML-NLP https://github.com/graykode/nlp-tutorial/blob/master/5-2.BERT/BERT.ipynb NLP-Models-Tensorflow https://github.com/huseinzol05/NLP-Models-Tensorflow ç›¸ä¼¼åº¦ https://github.com/duoergun0729/nlp/blob/master/%E6%96%87%E6%A1%A3%E7%9B%B8%E4%BC%BC%E5%BA%A6.md https://github.com/duoergun0729/nlp https://github.com/fighting41love/funNLP https://github.com/keon/awesome-nlp https://github.com/duoergun0729/nlp https://github.com/sebastianruder/NLP-progress https://github.com/graykode/nlp-tutorial https://github.com/DA-southampton/NLP_ability NLP é¢†åŸŸç»å…¸ä¹¦ç±ã€ŠSpeech and Language Processingã€‹ç¬¬ä¸‰ç‰ˆ https://web.stanford.edu/~jurafsky/slp3/ é¡¹ç›®æ˜¯æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰ã€æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰ã€NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆä¼šå¿…é€‰çš„ç†è®ºåŸºç¡€çŸ¥è¯† https://github.com/NLP-LOVE/ML-NLP NLPä»¥åŠç›¸å…³çš„å­¦ä¹ å®è·µ https://github.com/jarvisqi/machine_learning æœºå™¨å­¦ä¹ &amp;æ·±å…¥å­¦ä¹ èµ„æ–™ç¬”è®°&amp;åŸºæœ¬ç®—æ³•å®ç°&amp;èµ„æºæ•´ç†ï¼ˆML &#x2F; CV &#x2F; NLP &#x2F; DMâ€¦ï¼‰https://github.com/fire717/Machine-Learning Datawhaleæˆå‘˜æ•´ç†çš„é¢ç»å†…å®¹ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ï¼ŒCVï¼ŒNLPï¼Œæ¨è https://github.com/datawhalechina/daily-interview äººå·¥æ™ºèƒ½å®æˆ˜å¤§å­¦ï¼ˆé¢è¯•ï¼‰å­¦ä¹ è·¯çº¿å›¾ https://github.com/tangyudi/Ai-Learn 2018&#x2F;2019&#x2F;æ ¡æ‹›ç¬”è®°&#x2F;æ˜¥æ‹›&#x2F;ç§‹æ‹›&#x2F;è‡ªç„¶è€…è¯­è¨€å¤„ç†(NLP)&#x2F;æ·±åº¦æœºå™¨å­¦ä¹ (æ·±åº¦å­¦ä¹ )&#x2F;å­¦ä¹ (æœºå™¨å­¦ä¹ ) https://github.com/DarLiner/Algorithm_Interview_Notes-Chinese æ·±åº¦å­¦ä¹ ç®—æ³•æ•™ç¨‹ https://github.com/KeKe-Li/tutorial/tree/master https://github.com/KeKe-Li/tutorial æ·±åº¦å­¦ä¹ 100ä¾‹ã€æ·±åº¦è¯†åˆ«å­¦ä¹ ã€å›¾ç‰‡åˆ†ç±»ã€ç›®æ ‡ã€ç›®æ ‡æ£€æµ‹ã€è‡ªç„¶è¯­è¨€å¤„ç†nlpã€æ–‡æœ¬åˆ†ç±»ã€TensorFlowã€PyTorch https://github.com/kzbkzb/Python-AI pyhanlpå¥æ³•è®­ç»ƒ python train.py ä¸‹è½½ http://file.hankcs.com/corpus/ctb8.0-dep.zip åˆ° /opt/conda/lib/python3.6/site-packages/pyhanlp/static/data/test/ctb8.0-dep.zip100% 3.5 MiB 114.3 KiB/s ETA: 0 s [=============================================================]ä¸‹è½½ http://file.hankcs.com/corpus/wiki-cn-cluster.zip åˆ° /opt/conda/lib/python3.6/site-packages/pyhanlp/static/data/test/wiki-cn-cluster.txt.zip100% 763.9 KiB 353.9 KiB/s ETA: 0 s [=============================================================]è®­ç»ƒé›†å¥å­æ•°é‡: 14863 è¿­ä»£ 1/20 100.00% è€—æ—¶ 544 ç§’ã€‚UAS=83.23 LAS=80.84 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 2/20 100.00% è€—æ—¶ 569 ç§’ã€‚UAS=84.06 LAS=81.97 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 3/20 100.00% è€—æ—¶ 557 ç§’ã€‚UAS=84.55 LAS=82.48 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 4/20 100.00% è€—æ—¶ 556 ç§’ã€‚UAS=84.82 LAS=82.74 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 5/20 100.00% è€—æ—¶ 553 ç§’ã€‚UAS=84.95 LAS=82.89 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 6/20 100.00% è€—æ—¶ 549 ç§’ã€‚UAS=85.18 LAS=83.15 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 7/20 100.00% è€—æ—¶ 560 ç§’ã€‚UAS=85.25 LAS=83.26 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 8/20 100.00% è€—æ—¶ 562 ç§’ã€‚UAS=85.12 LAS=83.11è¿­ä»£ 9/20 100.00% è€—æ—¶ 569 ç§’ã€‚UAS=85.23 LAS=83.24è¿­ä»£ 10/20 100.00% è€—æ—¶ 571 ç§’ã€‚UAS=85.17 LAS=83.23è¿­ä»£ 11/20 100.00% è€—æ—¶ 571 ç§’ã€‚UAS=85.20 LAS=83.22è¿­ä»£ 12/20 100.00% è€—æ—¶ 581 ç§’ã€‚UAS=85.09 LAS=83.16è¿­ä»£ 13/20 100.00% è€—æ—¶ 652 ç§’ã€‚UAS=85.16 LAS=83.24è¿­ä»£ 14/20 100.00% è€—æ—¶ 677 ç§’ã€‚UAS=85.21 LAS=83.26è¿­ä»£ 15/20 100.00% è€—æ—¶ 586 ç§’ã€‚UAS=85.24 LAS=83.31è¿­ä»£ 16/20 100.00% è€—æ—¶ 554 ç§’ã€‚UAS=85.26 LAS=83.33 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 17/20 100.00% è€—æ—¶ 537 ç§’ã€‚UAS=85.38 LAS=83.46 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 18/20 100.00% è€—æ—¶ 548 ç§’ã€‚UAS=85.43 LAS=83.49 æœ€é«˜åˆ†ï¼ä¿å­˜ä¸­...è¿­ä»£ 19/20 100.00% è€—æ—¶ 553 ç§’ã€‚UAS=85.39 LAS=83.43è¿­ä»£ 20/20 100.00% è€—æ—¶ 554 ç§’ã€‚UAS=85.41 LAS=83.461 äºº äºº N NN _ 2 nsubj _ _2 åƒ åƒ V VV _ 0 ROOT _ _3 é±¼ é±¼ N NN _ 2 dobj _ _100 ... 200 ... 300 ... 400 ... 500 ... 600 ... 700 ... 800 ... 900 ... 1000 ... 1100 ... 1200 ... 1300 ... 1400 ... 1500 ... 1600 ... 1700 ... 1800 ... 1900 ... UAS=85.4 LAS=83.5 spacyå¥æ³•å¥æ³•æ˜¯æŒ‡å¥å­çš„å„ä¸ªç»„æˆéƒ¨åˆ†çš„ç›¸äº’å…³ç³»ï¼Œå¥æ³•åˆ†æåˆ†ä¸ºå¥æ³•ç»“æ„åˆ†æï¼ˆsyntactic structure parsingï¼‰å’Œä¾å­˜å…³ç³»åˆ†æ(dependency parsing)ã€‚å¥æ³•ç»“æ„åˆ†æç”¨äºè·å–æ•´ä¸ªå¥å­çš„å¥æ³•ç»“æ„ï¼Œä¾å­˜åˆ†æç”¨äºè·å–è¯æ±‡ä¹‹é—´çš„ä¾å­˜å…³ç³»ï¼Œç›®å‰çš„å¥æ³•åˆ†æå·²ç»ä»å¥æ³•ç»“æ„åˆ†æè½¬å‘ä¾å­˜å¥æ³•åˆ†æã€‚ ä¾å­˜è¯­æ³•é€šè¿‡åˆ†æè¯­è¨€å•ä½å†…æˆåˆ†ä¹‹é—´çš„ä¾å­˜å…³ç³»æ­ç¤ºå…¶å¥æ³•ç»“æ„ï¼Œä¸»å¼ å¥å­ä¸­æ ¸å¿ƒåŠ¨è¯æ˜¯æ”¯é…å…¶å®ƒæˆåˆ†çš„ä¸­å¿ƒæˆåˆ†ï¼Œè€Œå®ƒæœ¬èº«å´ä¸å—å…¶å®ƒä»»ä½•æˆåˆ†çš„æ”¯é…ï¼Œæ‰€æœ‰å—æ”¯é…æˆåˆ†éƒ½ä»¥æŸç§ä¾å­˜å…³ç³»ä»å±äºæ”¯é…è€…ã€‚ åœ¨20ä¸–çºª70å¹´ä»£ï¼ŒRobinsonæå‡ºä¾å­˜è¯­æ³•ä¸­å…³äºä¾å­˜å…³ç³»çš„å››æ¡å…¬ç†ï¼š ä¸€ä¸ªå¥å­ä¸­åªæœ‰ä¸€ä¸ªæˆåˆ†æ˜¯ç‹¬ç«‹çš„ï¼› å…¶å®ƒæˆåˆ†ç›´æ¥ä¾å­˜äºæŸä¸€æˆåˆ†ï¼› ä»»ä½•ä¸€ä¸ªæˆåˆ†éƒ½ä¸èƒ½ä¾å­˜ä¸ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„æˆåˆ†ï¼› å¦‚æœAæˆåˆ†ç›´æ¥ä¾å­˜äºBæˆåˆ†ï¼Œè€ŒCæˆåˆ†åœ¨å¥ä¸­ä½äºAå’ŒBä¹‹é—´ï¼Œé‚£ä¹ˆCæˆ–è€…ç›´æ¥ä¾å­˜äºBï¼Œæˆ–è€…ç›´æ¥ä¾å­˜äºAå’ŒBä¹‹é—´çš„æŸä¸€æˆåˆ†ï¼› SpaCy ä¸­æ–‡æ¨¡å‹:https://github.com/howl-anderson/Chinese_models_for_SpaCyhttps://blog.csdn.net/lllhhhv/article/details/123335675zh_core_web_trfã€zh_core_web_md ç­‰,å®ƒä»¬çš„åŒºåˆ«åœ¨äºå‡†ç¡®åº¦å’Œä½“ç§¯å¤§å°, zh_core_web_sm ä½“ç§¯å°,å‡†ç¡®åº¦ç›¸æ¯”zh_core_web_trfå·®,zh_core_web_trfç›¸å¯¹å°±ä½“ç§¯å¤§ã€‚è¿™æ ·å¯ä»¥é€‚åº”ä¸åŒåœºæ™¯. æ•°æ®å‚è€ƒhanlp.pretrained.depã€‚CTB5_BIAFFINE_DEP_ZH&#x3D; â€˜https://file.hankcs.com/hanlp/dep/biaffine_ctb5_20191229_025833.zip&#39;åœ¨ CTB5 ä¸Šè®­ç»ƒçš„Biaffine LSTM æ¨¡å‹ï¼ˆDozat &amp; Manning 2017ï¼‰ã€‚ hanlp.pretrained.depã€‚CTB7_BIAFFINE_DEP_ZH&#x3D; â€˜https://file.hankcs.com/hanlp/dep/biaffine_ctb7_20200109_022431.zip&#39;åœ¨ CTB7 ä¸Šè®­ç»ƒçš„Biaffine LSTM æ¨¡å‹ï¼ˆDozat &amp; Manning 2017ï¼‰ã€‚ hanlp.pretrained.depã€‚CTB9_DEP_ELECTRA_SMALL&#x3D; â€˜https://file.hankcs.com/hanlp/dep/ctb9_dep_electra_small_20220216_100306.zip&#39;Electra å°å‹ç¼–ç å™¨ ( Clark et al. 2020 ) å’Œ Biaffine è§£ç å™¨ ( Dozat &amp; Manning 2017 ) åœ¨ CTB9-SD330 ä¸Šè®­ç»ƒã€‚æ€§èƒ½ä¸º UAS&#x3D;87.68% LAS&#x3D;83.54%ã€‚ hanlp.pretrained.depã€‚CTB9_UDC_ELECTRA_SMALL&#x3D; â€˜https://file.hankcs.com/hanlp/dep/udc_dep_electra_small_20220218_095452.zip&#39;Electra å°å‹ç¼–ç å™¨ ( Clark et al. 2020 ) å’Œ Biaffine è§£ç å™¨ ( Dozat &amp; Manning 2017 ) åœ¨ CTB9-UD420 ä¸Šè®­ç»ƒã€‚æ€§èƒ½æ˜¯ UAS&#x3D;85.92% LAS&#x3D;81.13% ã€‚ hanlp.pretrained.depã€‚PMT1_DEP_ELECTRA_SMALL&#x3D; â€˜https://file.hankcs.com/hanlp/dep/pmt_dep_electra_small_20220218_134518.zip&#39;Electra å°å‹ç¼–ç å™¨ ( Clark et al. 2020 ) å’Œ Biaffine è§£ç å™¨ ( Dozat &amp; Manning 2017 ) åœ¨ PKU Multi-view Chinese Treebank (PMT) 1.0 ( Qiu et al. 2014 ) ä¸Šè®­ç»ƒã€‚æ€§èƒ½æ˜¯ UAS&#x3D;91.21% LAS&#x3D;88.65%ã€‚ hanlp.pretrained.depã€‚PTB_BIAFFINE_DEP_EN&#x3D; â€˜https://file.hankcs.com/hanlp/dep/ptb_dep_biaffine_20200101_174624.zip&#39;åœ¨ PTB ä¸Šè®­ç»ƒçš„Biaffine LSTM æ¨¡å‹ï¼ˆDozat &amp; Manning 2017 ï¼‰ã€‚ å‚è€ƒæ¥è‡ªï¼šhttps://hanlp.hankcs.com/docs/api/hanlp/index.html ctbæ•°æ®é›†ç›¸å…³è®ºæ–‡DPCN&#x2F;dataset_paper.json hanlpå¥æ³•åˆ†æè®­ç»ƒé—®é¢˜è§£å†³ï¼šhttps://bbs.hankcs.com/t/topic/2868 å‘½åå®ä½“è¯†åˆ«:å‘½åå®ä½“è¯†åˆ«ä»æ—©æœŸåŸºäºè¯å…¸å’Œè§„åˆ™çš„æ–¹æ³•ï¼Œåˆ°ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œ åæ¥é‡‡ç”¨åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œä¸€ç›´åˆ°å½“ä¸‹çƒ­é—¨çš„æ³¨æ„åŠ›æœºåˆ¶ã€å›¾ç¥ç»ç½‘ç»œç­‰ç ”ç©¶æ–¹æ³•ï¼Œ å‘½åå®ä½“è¯†åˆ«æŠ€æœ¯è·¯çº¿éšç€æ—¶é—´åœ¨ä¸æ–­å‘å±•ã€‚ https://github.com/TianRanPig/chinese_ner https://github.com/CLUEbenchmark/CLUENER2020 https://github.com/hemingkx/CLUENER2020 https://github.com/lonePatient/BERT-NER-Pytorch https://github.com/lemonhu/NER-BERT-pytorch https://github.com/google-research/bert https://github.com/TobiasLee/ChineseNER https://github.com/PottermoreIron/BERT-BiLSTM-CRF-For-Practice https://github.com/luopeixiang/named_entity_recognition https://github.com/F-debug/Medical-named-entity-recognition https://github.com/kyzhouhzau/BERT-NER https://github.com/macanv/BERT-BiLSTM-CRF-NER https://github.com/xuanzebi/BERT-CH-NER https://github.com/huggingface/transformers ä½¿ç”¨bertåšé¢†åŸŸåˆ†ç±»ã€æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……ä»»åŠ¡ https://github.com/xiaopp123/bert-joint-NLU åŸºäºpytorchçš„ä¸­æ–‡æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å…… https://github.com/taishan1994/pytorch_bert_intent_classification_and_slot_filling åŸºäºBERT+Tensorflow-1.15+Horovod-0.22çš„NLUï¼ˆæ„å›¾è¯†åˆ«+æ§½ä½å¡«å……ï¼‰åˆ†å¸ƒå¼GPUè®­ç»ƒæ¨¡å— https://github.com/jx1100370217/JointBERT_nlu_tf ä½¿ç”¨bertåšé¢†åŸŸåˆ†ç±»ã€é…ç½®è¯†åˆ«å’Œä½ç½®å¡«å……ä»»åŠ¡ https://github.com/xiaopp123/bert-joint-NLU ä¸­æ–‡è¯­è¨€ç†è§£åŸºå‡†ã€åŸºå‡†ä¸­æ–‡è¯­è¨€ç†è§£è¯„ä¼°åŸºå‡†ï¼šæ•°æ®é›†ã€é¢„è®­ç»ƒæ¨¡å‹ã€è¯­æ–™åº“ https://github.com/CLUEbenchmark/CLUE ç”¨äºè”åˆæ„å›¾åˆ†ç±»å’Œæ’æ§½å¡«å……çš„ BERT https://github.com/monologg/JointBERT https://github.com/yuanxiaosc/BERT-for-Sequence-Labeling-and-Text-Classification https://github.com/pymacbit/BERT-Intent-Classification https://github.com/ensembles4612/medical_intent_detector_using_BERT https://github.com/AdamLouly/Intent-Classifier-using-BERT-and-TF2/blob/master/BERT2INTENT.ipynb https://github.com/sz128/slot_filling_and_intent_detection_of_SLU https://github.com/471417367/bert_intention_zh æ•°æ®é›†è‡ªåŠ¨æ ‡æ³¨å·¥å…·â€“é‡Šæ”¾AIæ½œåŠ›ï¼https://www.modelfun.cn/home å®ä½“è¯†åˆ«æ•°æ®é›† https://github.com/juand-r/entity-recognition-datasets nerç»¼è¿°ï¼š https://blog.csdn.net/weixin_45884316/article/details/118684681 ä½¿ç”¨ CLIP å°†å›¾åƒå’Œå¥å­åµŒå…¥åˆ°å›ºå®šé•¿åº¦çš„å‘é‡ä¸­ https://github.com/jina-ai/clip-as-service other: https://github.com/Rhine97/NLP-NER-models/tree/master/JupyterNotebook_Version/dataset https://github.com/Hyfred/Pytroch_NER_tutorial https://github.com/cs230-stanford/cs230-code-examples/tree/master/pytorch/nlp https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html#sphx-glr-beginner-nlp-advanced-tutorial-py https://github.com/kamalkraj/BERT-NER å‚è€ƒï¼šhttps://github.com/kyzhouhzau/NLPGNN [1] BERTï¼šç”¨äºè¯­è¨€ç†è§£çš„æ·±åº¦åŒå‘è½¬æ¢å™¨çš„é¢„è®­ç»ƒ[2] ALBERTï¼šç”¨äºè¯­è¨€è¡¨ç¤ºçš„è‡ªç›‘ç£å­¦ä¹ çš„ Lite BERT[3]è¯­è¨€æ¨¡å‹æ˜¯æ— ç›‘ç£çš„å¤šä»»åŠ¡å­¦ä¹ è€…[4]ç”¨äºé‡å­åŒ–å­¦çš„ç¥ç»æ¶ˆæ¯ä¼ é€’[ 5]ä½¿ç”¨å›¾å·ç§¯ç½‘ç»œè¿›è¡ŒåŠç›‘ç£åˆ†ç±»[6]å›¾æ³¨æ„ç½‘ç»œ[7]å›¾ç¥ç»ç½‘ç»œæœ‰å¤šå¼ºå¤§ï¼Ÿ[8] GraphSAGEï¼šå¤§å›¾ä¸Šçš„å½’çº³è¡¨ç¤ºå­¦ä¹ [9]æ‰©æ•£æ”¹è¿›äº†å›¾å­¦ä¹ [10]åŸºå‡†å›¾ç¥ç»ç½‘ç»œ[11]ç”¨äºæ–‡æœ¬åˆ†ç±»çš„æ–‡æœ¬çº§å›¾ç¥ç»ç½‘ç»œ[12]ç”¨äºæ–‡æœ¬åˆ†ç±»çš„å›¾å·ç§¯ç½‘ç»œ[13]ç”¨äºæ–‡æœ¬åˆ†ç±»çš„å¼ é‡å›¾å·ç§¯ç½‘ç»œ[14]æ·±å…¥äº†è§£ç”¨äºåŠç›‘ç£å­¦ä¹ çš„å›¾å·ç§¯ç½‘ç»œ å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ ‡æ³¨ç¥å™¨: https://blog.csdn.net/qq_44193969/article/details/123298406 å®è·µï¼šhttps://blog.csdn.net/qq_44193969/article/details/116008734 https://github.com/seanzhang-zhichen/PytorchBilstmCRF-Information-Extraction https://blog.csdn.net/weixin_40846933/article/details/106384566","raw":null,"content":null,"categories":[{"name":"äººå·¥æ™ºèƒ½è®ºæ–‡","slug":"äººå·¥æ™ºèƒ½è®ºæ–‡","permalink":"https://www.coomatrix.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"AIè®ºæ–‡","slug":"AIè®ºæ–‡","permalink":"https://www.coomatrix.com/tags/AI%E8%AE%BA%E6%96%87/"}]},{"title":"å­¦æœ¯è®ºæ–‡æ’ç‰ˆå·¥å…·LaTeX","slug":"latex","date":"2018-04-05T12:57:06.000Z","updated":"2022-11-20T13:22:23.279Z","comments":true,"path":"2018/04/05/latex/","link":"","permalink":"https://www.coomatrix.com/2018/04/05/latex/","excerpt":"","keywords":null,"text":"1ã€latexå®‰è£…æ–¹æ³•å®˜æ–¹çš„åœ°å€æ˜¯http:&#x2F;&#x2F;mirror.ctan.org&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼Œä½†æ˜¯å¯èƒ½é€Ÿåº¦è¾ƒæ…¢ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å›½å†…çš„é•œåƒåœ°å€ï¼šå›½å†…çš„é•œåƒåœ°å€ï¼š æ¸…åå¤§å­¦ï¼šhttps:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;CTAN&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼› åŒ—äº¬äº¤é€šå¤§å­¦ï¼šhttps:&#x2F;&#x2F;mirror.bjtu.edu.cn&#x2F;ctan&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼› ä¸Šæµ·äº¤é€šå¤§å­¦ï¼šhttps:&#x2F;&#x2F;mirrors.sjtug.sjtu.edu.cn&#x2F;ctan&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼› ä¸­å›½ç§‘æŠ€å¤§å­¦ï¼šhttps:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;CTAN&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼› é‡åº†å¤§å­¦ï¼šhttps:&#x2F;&#x2F;mirrors.cqu.edu.cn&#x2F;CTAN&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.isoï¼› è…¾è®¯äº‘ï¼šhttps:&#x2F;&#x2F;mirrors.cloud.tencent.com&#x2F;CTAN&#x2F;systems&#x2F;texlive&#x2F;Images&#x2F;texlive2021.iso ä¸‹è½½ä¸å®‰è£…å‚è€ƒåœ°å€1ï¼šhttps://mirror-hk.koddos.net/CTAN/systems/texlive/Images/ ä¸‹è½½ä¸å®‰è£…å‚è€ƒåœ°å€2ï¼šhttps://www.jianshu.com/p/a8d46d00b833 æ¨èè¿…é›·ä¸‹è½½è¾ƒå¿«ï¼š åœ¨çº¿LaTeXç¼–è¾‘å™¨ï¼šhttps://www.overleaf.comTeX Liveä¸‹è½½ï¼šhttps://www.tug.org/texlive/acquire-iso.htmlMikTeXä¸‹è½½ï¼šhttps://miktex.org/downloadLaTeX å…¬å¼ç¼–è¾‘å™¨ï¼šhttps://latex.codecogs.com/eqneditor/editor.phpLaTeXä»‹ç»ï¼šhttps://github.com/CTeX-org/lshort-zh-cn å®‰è£…æ­¥éª¤ï¼šæˆ‘å®‰è£…åœ¨Dç›˜ æ­¥éª¤1ï¼šé€‰æ‹©isoæ–‡ä»¶é¼ æ ‡å³é”®ç‚¹å‡»è£…è½½ æ­¥éª¤2ï¼šé€‰æ‹©å®‰è£…è·¯å¾„ æ­¥éª¤3ï¼šç¡®å®šå®‰è£…è·¯å¾„ä¹‹åç‚¹å‡»å®‰è£… 2ã€å­¦ä¹ ç½‘ç«™https://www.latexstudio.net/ https://www.jianshu.com/nb/34744106","raw":null,"content":null,"categories":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://www.coomatrix.com/categories/LaTeX/"}],"tags":[{"name":"æ’ç‰ˆå·¥å…·","slug":"æ’ç‰ˆå·¥å…·","permalink":"https://www.coomatrix.com/tags/%E6%8E%92%E7%89%88%E5%B7%A5%E5%85%B7/"}]}]}